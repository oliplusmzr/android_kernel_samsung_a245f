// SPDX-License-Identifier: GPL-2.0
/*
 * Copyright (c) 2022 MediaTek Inc.
 */

#include <linux/clk.h>
#include <linux/component.h>
#include <linux/of_device.h>
#include <linux/of_irq.h>
#include <linux/of_address.h>
#include <linux/platform_device.h>
#include <linux/module.h>
#include <linux/vmalloc.h>
#include <linux/workqueue.h>
#include <linux/delay.h>
#include <linux/time.h>
#include <linux/sched.h>
#include <uapi/linux/sched/types.h>
#include <linux/ratelimit.h>
#include <linux/soc/mediatek/mtk-cmdq-ext.h>
#include <linux/uaccess.h>
#include <uapi/drm/mediatek_drm.h>

#include "../mtk_drm_crtc.h"
#include "../mtk_drm_ddp_comp.h"
#include "../mtk_drm_drv.h"
#include "../mtk_drm_lowpower.h"
#include "../mtk_log.h"
#include "../mtk_dump.h"
#include "../mtk_drm_mmp.h"
#include "../mtk_drm_gem.h"
#include "../mtk_drm_fb.h"
#include "../mtk_disp_dbi_count.h"
#include "mtk_disp_oddmr.h"
#include "mtk_disp_oddmr_tuning.h"

#include "scp.h"
#include <linux/iommu.h>
#include <mtk-smmu-v3.h>

/* ODDMR TOP */
#define DISP_ODDMR_TOP_CTR_1 0x0004
#define DISP_ODDMR_TOP_CTR_2 0x0008
#define REG_VS_RE_GEN REG_FLD_MSB_LSB(1, 1)
#define DISP_ODDMR_TOP_CTR_3 0x000C
#define REG_ODDMR_TOP_CLK_FORCE_EN REG_FLD_MSB_LSB(15, 15)
#define REG_FORCE_COMMIT REG_FLD_MSB_LSB(4, 4)
#define REG_BYPASS_SHADOW REG_FLD_MSB_LSB(5, 5)
#define REG_ODDMR_BYPASS REG_FLD_MSB_LSB(0, 0)
#define DISP_ODDMR_TOP_CTR_4 0x001C//rst
#define REG_DMR_SMI_BRG_SW_RST REG_FLD_MSB_LSB(2, 2)
#define REG_ODR_SMI_BRG_SW_RST REG_FLD_MSB_LSB(3, 3)
#define REG_ODW_SMI_BRG_SW_RST REG_FLD_MSB_LSB(4, 4)
#define DISP_ODDMR_IRQ_FORCE 0x0020
#define DISP_ODDMR_IRQ_CLEAR 0x0024
#define DISP_ODDMR_IRQ_MASK 0x0028
#define DISP_ODDMR_IRQ_STATUS 0x002C
#define DISP_ODDMR_IRQ_FRAME_DONE BIT(0)
#define DISP_ODDMR_IRQ_ODW_DONE BIT(1)
#define DISP_ODDMR_IRQ_I_FRM_DNE BIT(2)
#define DISP_ODDMR_IRQ_O_FRM_DNE BIT(3)
#define DISP_ODDMR_IRQ_SOF BIT(5)
#define DISP_ODDMR_IRQ_RAW_STATUS 0x0030
#define DISP_ODDMR_DITHER_CTR_1 0x0044//11bit
#define DISP_ODDMR_DITHER_CTR_2 0x0048//10bit
#define DISP_ODDMR_DMR_UDMA_CTR_4 0x00D0
#define REG_DMR_BASE_ADDR_L REG_FLD_MSB_LSB(15, 0)
#define DISP_ODDMR_DMR_UDMA_CTR_5 0x00D4
#define REG_DMR_BASE_ADDR_H REG_FLD_MSB_LSB(15, 0)

#define DISP_ODDMR_DMR_UDMA_CTR_6 0x00D8
#define DISP_ODDMR_DMR_UDMA_CTR_7 0x00DC


#define DISP_ODDMR_OD_UDMA_CTR_0 0x0100
#define REG_OD_RD_REG_EN REG_FLD_MSB_LSB(7, 7)
#define REG_OD_CLK_EN REG_FLD_MSB_LSB(11, 11)

#define DISP_ODDMR_FMT_CTR_0 0x0140
#define DISP_ODDMR_FMT_CTR_1 0x0144


#define DISP_ODDMR_OD_HSK_0 0x0180
#define DISP_ODDMR_OD_HSK_1 0x0184
#define DISP_ODDMR_OD_HSK_2 0x0188
#define DISP_ODDMR_OD_HSK_3 0x018C
#define DISP_ODDMR_OD_HSK_4 0x0190
#define DISP_ODDMR_CRP_CTR_0 0x0194
#define DISP_ODDMR_CRP_CTR_1 0x0198
#define DISP_ODDMR_CRP_CTR_2 0x019C
#define REG_WINDOW_LR REG_FLD_MSB_LSB(0, 0)
#define REG_GUARD_BAND_PIXEL REG_FLD_MSB_LSB(14, 8)
#define DISP_ODDMR_TOP_RESERVE_1 0x01A4
#define DISP_ODDMR_ODR_H DISP_ODDMR_TOP_RESERVE_1
#define DISP_ODDMR_TOP_RESERVE_2 0x01A8
#define DISP_ODDMR_ODR_V DISP_ODDMR_TOP_RESERVE_2
#define DISP_ODDMR_TOP_RESERVE_3 0x01AC
#define DISP_ODDMR_TOP_OD_BYASS 0x01C0
#define DISP_ODDMR_TOP_DMR_BYASS 0x01C4
#define DISP_ODDMR_TOP_S2R_BYPASS 0x01C8
#define DISP_ODDMR_TOP_HRT0_BYPASS 0x01CC
#define DISP_ODDMR_TOP_HRT1_BYPASS 0x01D0
#define DISP_ODDMR_TOP_DITHER_BYPASS 0x01D4
#define DISP_ODDMR_TOP_CRP_BYPSS 0x01D8
#define DISP_ODDMR_TOP_CLK_GATING 0x01E0
#define DISP_ODDMR_DMR_UDMA_ENABLE 0x01E4
#define DISP_ODDMR_DITHER_12TO11_BYPASS 0x01E8
#define DISP_ODDMR_DITHER_12TO10_BYPASS 0x01EC
#define DISP_ODDMR_DMR_SECURITY 0x01FC

/* DMR */
#define DISP_ODDMR_REG_DMR_EN 0x020c
#define DISP_ODDMR_REG_DMR_CLK_EN 0x0f00

/* OD */
#define DISP_ODDMR_REG_OD_BASE 0x1000
#define DISP_ODDMR_OD_SRAM_CTRL_0 (0x0004 + DISP_ODDMR_REG_OD_BASE)
#define REG_WBGR_OD_SRAM_IO_EN REG_FLD_MSB_LSB(3, 0)
#define REG_OD_SRAM_WRITE_SEL REG_FLD_MSB_LSB(4, 4)
#define REG_OD_SRAM_READ_SEL REG_FLD_MSB_LSB(5, 5)
#define REG_OD_SRAM_READ_BACK_SEL REG_FLD_MSB_LSB(6, 6)
#define REG_OD_TABLE_DB_EFF_EN REG_FLD_MSB_LSB(7, 7)
#define REG_AUTO_SRAM_ADR_INC_EN REG_FLD_MSB_LSB(11, 11)
#define DISP_ODDMR_OD_SRAM_CTRL_1 (0x0008 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_SRAM_CTRL_2 (0x000C + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_SRAM_CTRL_3 (0x0010 + DISP_ODDMR_REG_OD_BASE)

#define DISP_ODDMR_OD_CTRL_EN (0x0040 + DISP_ODDMR_REG_OD_BASE)
#define REG_OD_EN REG_FLD_MSB_LSB(0, 0)
#define REG_OD_MODE REG_FLD_MSB_LSB(3, 1)
#define REG_OD_FORCE_EN REG_FLD_MSB_LSB(13, 13)
#define DISP_ODDMR_OD_PQ_0 (0x0044 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_BASE_ADDR_R_LSB (0x0054 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_BASE_ADDR_R_MSB (0x0058 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_BASE_ADDR_G_LSB (0x005C + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_BASE_ADDR_G_MSB (0x0060 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_BASE_ADDR_B_LSB (0x0064 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_BASE_ADDR_B_MSB (0x0068 + DISP_ODDMR_REG_OD_BASE)
#define REG_OD_BASE_ADDR REG_FLD_MSB_LSB(15, 0)
#define DISP_ODDMR_OD_SW_RESET (0x0094 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_UMDA_CTRL_0 (0x00B0 + DISP_ODDMR_REG_OD_BASE)//all 0
#define DISP_ODDMR_OD_UMDA_CTRL_1 (0x00B4 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_UMDA_CTRL_2 (0x00B8 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_UMDA_CTRL_3 (0x00BC + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_SCALING_6 (0x01B0 + DISP_ODDMR_REG_OD_BASE)
#define REG_ENABLE_HSCALING REG_FLD_MSB_LSB(0, 0)
#define REG_ENABLE_VSCALING REG_FLD_MSB_LSB(1, 1)
#define REG_DE_ALIGN8_EN REG_FLD_MSB_LSB(6, 6)
#define REG_HSD_2X4X_SEL REG_FLD_MSB_LSB(7, 7)
#define DISP_ODDMR_OD_DUMMY_0 (0x01C4 + DISP_ODDMR_REG_OD_BASE)
#define REG_CUR_LINE_BUFFER_DE_2P_ALIGN REG_FLD_MSB_LSB(0, 0)
#define REG_UDMA_HSIZE_USER_MODE REG_FLD_MSB_LSB(1, 1)
#define REG_UDMA_VSIZE_USER_MODE REG_FLD_MSB_LSB(2, 2)
#define REG_HVSP2UDMA_W_LAST_MASK REG_FLD_MSB_LSB(3, 3)
#define REG_BUF_LV_INVERSE REG_FLD_MSB_LSB(4, 4)
#define REG_BYPASS_MIU2SMI_W_BRIDGE REG_FLD_MSB_LSB(7, 7)
#define DISP_ODDMR_OD_DUMMY_1 (0x01C8 + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_DUMMY_2 (0x01CC + DISP_ODDMR_REG_OD_BASE)
#define DISP_ODDMR_OD_DUMMY_3 (0x01D0 + DISP_ODDMR_REG_OD_BASE)

/* MT6991 OD_BASE */
#define MT6991_DISP_ODDMR_REG_OD_BASE 0x0200
#define MT6991_DISP_ODDMR_OD_SRAM_CTRL_0 (0x0004 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_SRAM_CTRL_1 (0x0008 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_SRAM_CTRL_2 (0x000C + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_SRAM_CTRL_3 (0x0010 + MT6991_DISP_ODDMR_REG_OD_BASE)

#define MT6991_DISP_ODDMR_OD_CTRL_EN (0x0040 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_PQ_0 (0x0044 + MT6991_DISP_ODDMR_REG_OD_BASE)

// MT6991 single base
#define MT6991_DISP_ODDMR_OD_BASE_ADDR_LSB (0x0054 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_BASE_ADDR_MSB (0x0058 + MT6991_DISP_ODDMR_REG_OD_BASE)

#define MT6991_DISP_ODDMR_OD_SW_RESET (0x0094 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_UMDA_CTRL_0 (0x00B0 + MT6991_DISP_ODDMR_REG_OD_BASE)//all 0
#define MT6991_DISP_ODDMR_OD_UMDA_CTRL_1 (0x00B4 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_UMDA_CTRL_2 (0x00B8 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_UMDA_CTRL_3 (0x00BC + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_DISP_ODDMR_OD_SCALING_6 (0x01B0 + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6991_REG_SPR_RGBG_MODE REG_FLD_MSB_LSB(3, 3)

/* SPR2RGB */
#define DISP_ODDMR_REG_SPR2RGB_BASE 0x800
#define DISP_ODDMR_REG_SPR_COMP_EN (0x0004 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_MASK_0 (0x0008 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_MASK_1 (0x000C + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_MASK_2 (0x0010 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_MASK_3 (0x0014 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_MASK_4 (0x0018 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_MASK_5 (0x001C + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_MASK_2X2 (0x0020 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_PANEL_WIDTH (0x0024 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_X_INIT (0x0028 + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_REMAP_EN (0x002C + DISP_ODDMR_REG_SPR2RGB_BASE)
#define DISP_ODDMR_REG_SPR_REMAP_GAIN (0x0030 + DISP_ODDMR_REG_SPR2RGB_BASE)



/* SMI SB */
#define DISP_ODDMR_REG_SMI_BASE 0x000
#define DISP_ODDMR_HRT_CTR (0x003C + DISP_ODDMR_REG_SMI_BASE)
#define REG_HR0_RE_ULTRA_MODE REG_FLD_MSB_LSB(3, 0)
#define REG_HR0_POACH_CFG_OFF REG_FLD_MSB_LSB(4, 4)
#define REG_HR0_PREULTRA_RE_ULTRA_MASK REG_FLD_MSB_LSB(6, 6)
#define REG_HR0_ULTRA_RE_MASK REG_FLD_MSB_LSB(7, 7)
#define REG_HR1_RE_ULTRA_MODE REG_FLD_MSB_LSB(11, 8)
#define REG_HR1_POACH_CFG_OFF REG_FLD_MSB_LSB(12, 12)
#define REG_HR1_PREULTRA_RE_ULTRA_MASK REG_FLD_MSB_LSB(14, 14)
#define REG_HR1_ULTRA_RE_MASK REG_FLD_MSB_LSB(15, 15)
#define DISP_ODDMR_REG_HR0_PREULTRA_RE_IN_THR_0 (0x0040 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR0_PREULTRA_RE_IN_THR_1 (0x0044 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR0_PREULTRA_RE_OUT_THR_0 (0x0048 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR0_PREULTRA_RE_OUT_THR_1 (0x004C + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR0_ULTRA_RE_IN_THR_0 (0x0050 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR0_ULTRA_RE_IN_THR_1 (0x0054 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR0_ULTRA_RE_OUT_THR_0 (0x0058 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR0_ULTRA_RE_OUT_THR_1 (0x005C + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_PREULTRA_RE_IN_THR_0 (0x0060 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_PREULTRA_RE_IN_THR_1 (0x0064 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_PREULTRA_RE_OUT_THR_0 (0x0068 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_PREULTRA_RE_OUT_THR_1 (0x006C + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_ULTRA_RE_IN_THR_0 (0x0070 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_ULTRA_RE_IN_THR_1 (0x0074 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_ULTRA_RE_OUT_THR_0 (0x0078 + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_REG_HR1_ULTRA_RE_OUT_THR_1 (0x007C + DISP_ODDMR_REG_SMI_BASE)//12 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_0 (0x0060 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_1 (0x0074 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_2 (0x0068 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_3 (0x006C + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_4 (0x0070 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_5 (0x0074 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_6 (0x0078 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_7 (0x007C + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODR_8 (0x0054 + DISP_ODDMR_REG_SMI_BASE)
#define REG_ODR_POACH_CFG_OFF REG_FLD_MSB_LSB(1, 1)
#define REG_ODR_RE_ULTRA_MODE REG_FLD_MSB_LSB(11, 8)
#define DISP_ODDMR_SMI_SB_FLG_ODW_0  (0x0080 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_1  (0x0084 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_2  (0x0088 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_3  (0x008C + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_4  (0x0090 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_5  (0x0094 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_6  (0x0098 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_7  (0x009C + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_ODW_8 (0x0058 + DISP_ODDMR_REG_SMI_BASE)
#define REG_ODW_POACH_CFG_OFF REG_FLD_MSB_LSB(1, 1)
#define REG_ODW_WR_ULTRA_MODE REG_FLD_MSB_LSB(11, 8)
#define DISP_ODDMR_REG_DMR_PREULTRA_RE_IN_THR_0  (0x00A0 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_REG_DMR_PREULTRA_RE_IN_THR_1  (0x00A4 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_REG_DMR_PREULTRA_RE_OUT_THR_0  (0x00A8 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_REG_DMR_PREULTRA_RE_OUT_THR_1  (0x00AC + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_REG_DMR_ULTRA_RE_IN_THR_0  (0x00B0 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_REG_DMR_ULTRA_RE_IN_THR_1  (0x00B4 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_REG_DMR_ULTRA_RE_OUT_THR_0  (0x00B8 + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_REG_DMR_ULTRA_RE_OUT_THR_1  (0x00BC + DISP_ODDMR_REG_SMI_BASE)//15 0
#define DISP_ODDMR_SMI_SB_FLG_DMR_8 (0x005c + DISP_ODDMR_REG_SMI_BASE)
#define REG_DMR_RE_ULTRA_MODE REG_FLD_MSB_LSB(11, 8)

#define MT6991_DISP_ODDMR_SMI_SB_FLG_ODR_1 (0x0068)
	#define MT6991_REG_DBI_GUSER_CTRL_1		REG_FLD_MSB_LSB(15, 0)

// MT6991 OD DDREN
#define MT6991_DISP_ODDMR_REG_ODW_DDREN_CTRL 0x008C //CODA: DISP_ODDMR_SMI_SB_FLG_ODW_2
#define MT6991_DISP_ODDMR_REG_ODR_DDREN_CTRL 0x0090 //CODA: DISP_ODDMR_SMI_SB_FLG_ODW_3

/* OD UDMA R*/
#define DISP_ODDMR_REG_UDMA_R_BASE 0x1600
#define DISP_ODDMR_UDMA_R_CTRL84_0	(0x0160 + DISP_ODDMR_REG_UDMA_R_BASE)//R
#define DISP_ODDMR_UDMA_R_CTRL86_0	(0x01A0 + DISP_ODDMR_REG_UDMA_R_BASE)//R
#define DISP_ODDMR_UDMA_R_CTRL88	(0x01C0 + DISP_ODDMR_REG_UDMA_R_BASE)//W 1

/* MT6991 OD UDMA R*/
#define MT6991_DISP_ODDMR_REG_UDMA_R_BASE 0x0800
#define MT6991_DISP_ODDMR_UDMA_R_CTRL84_0  (0x0160 + MT6991_DISP_ODDMR_REG_UDMA_R_BASE)//R
#define MT6991_DISP_ODDMR_UDMA_R_CTRL86_0  (0x01A0 + MT6991_DISP_ODDMR_REG_UDMA_R_BASE)//R
#define MT6991_DISP_ODDMR_UDMA_R_CTRL88    (0x01C0 + MT6991_DISP_ODDMR_REG_UDMA_R_BASE)//W 1
#define MT6991_DISP_ODDMR_UDMA_R_CTRL70    (0x0100 + MT6991_DISP_ODDMR_REG_UDMA_R_BASE)

#define MT6991_OD_DISP_ODDMR_SMI_SB_FLG_ODR_8 (0x0054)
#define MT6991_OD_REG_ODR_POACH_CFG_OFF REG_FLD_MSB_LSB(4, 4)
#define MT6991_OD_DISP_ODDMR_UDMA_R_CTRL21 (0x0054 + MT6991_DISP_ODDMR_REG_UDMA_R_BASE)
#define MT6991_OD_REG_REQ_PREULTRA_RISE_LV REG_FLD_MSB_LSB(6, 0)
#define MT6991_OD_REG_REQ_PREULTRA_FALL_LV REG_FLD_MSB_LSB(14, 8)
#define MT6991_OD_DISP_ODDMR_UDMA_R_CTRL22 (0x0058 + MT6991_DISP_ODDMR_REG_UDMA_R_BASE)
#define MT6991_OD_REG_REQ_ULTRA_RISE_LV REG_FLD_MSB_LSB(6, 0)
#define MT6991_OD_REG_REQ_ULTRA_FALL_LV REG_FLD_MSB_LSB(14, 8)


/* OD UDMA W*/
#define DISP_ODDMR_REG_UDMA_W_BASE 0x1800
#define DISP_ODDMR_UDMA_W_CTR_16	(0x005C + DISP_ODDMR_REG_UDMA_W_BASE)//0x01
#define DISP_ODDMR_UDMA_W_CTR_23	(0x0084 + DISP_ODDMR_REG_UDMA_W_BASE)//0xFF

/* MT6991 OD UDMA W*/
#define MT6991_DISP_ODDMR_REG_UDMA_W_BASE 0xA00
#define MT6991_DISP_ODDMR_UDMA_W_CTR_1D    (0x0074 + MT6991_DISP_ODDMR_REG_UDMA_W_BASE)//6991
#define MT6991_DISP_ODDMR_UDMA_W_CTR_23    (0x0084 + MT6991_DISP_ODDMR_REG_UDMA_W_BASE)//0xFF
#define MT6991_DISP_ODDMR_UDMA_W_CTR_47    (0x0100 + MT6991_DISP_ODDMR_REG_UDMA_W_BASE)

#define MT6991_OD_DISP_ODDMR_SMI_SB_FLG_ODW_8 (0x0058)
#define MT6991_OD_REG_ODW_POACH_CFG_OFF REG_FLD_MSB_LSB(4, 4)
#define MT6991_OD_DISP_ODDMR_UDMA_W_CTR_15 (0x0054 + MT6991_DISP_ODDMR_REG_UDMA_W_BASE)
#define MT6991_OD_DISP_ODDMR_UDMA_W_CTR_16 (0x0058 + MT6991_DISP_ODDMR_REG_UDMA_W_BASE)


#define OD_H_ALIGN_BITS 128

#define ODDMR_READ_IN_PRE_ULTRA(size)     (size * 2 / 3 + 3135)
#define ODDMR_READ_IN_ULTRA(size)         (size * 1 / 3 + 3135)
#define ODDMR_READ_OUT_PRE_ULTRA(size)    (size * 3 / 4 + 3135)
#define ODDMR_READ_OUT_ULTRA(size)        (size * 2 / 4 + 3135)
#define ODDMR_WRITE_IN_PRE_ULTRA(size)    (size * 1 / 3)
#define ODDMR_WRITE_IN_ULTRA(size)        (size * 2 / 3)
#define ODDMR_WRITE_OUT_PRE_ULTRA(size)   (size * 1 / 4)
#define ODDMR_WRITE_OUT_ULTRA(size)       (size * 2 / 4)


/* MT6991 OD ultra&preultra */
#define MT6991_OD_ODDMR_READ_IN_PRE_ULTRA     (120 - 120 * 2 / 3)
#define MT6991_OD_ODDMR_READ_IN_ULTRA         (120 - 120 * 1 / 3)
#define MT6991_OD_ODDMR_READ_OUT_PRE_ULTRA    (120 - 120 * 3 / 4)
#define MT6991_OD_ODDMR_READ_OUT_ULTRA        (120 - 120 * 2 / 4)
#define MT6991_OD_ODDMR_WRITE_IN_PRE_ULTRA    (120 * 1 / 3)
#define MT6991_OD_ODDMR_WRITE_IN_ULTRA        (120 * 2 / 3)
#define MT6991_OD_ODDMR_WRITE_OUT_PRE_ULTRA   (120 * 1 / 4)
#define MT6991_OD_ODDMR_WRITE_OUT_ULTRA       (120 * 2 / 4)

/* DMR ultra&preultra in mt6991 */
#define MT6991_ODDMR_DMR_PRE_ULTRA_RISE_LV(size)    (size * 1 / 3) //67%
#define MT6991_ODDMR_DMR_PRE_ULTRA_FAIL_LV(size)    (size * 1 / 4) //75%
#define MT6991_ODDMR_DMR_ULTRA_RISE_LV(size)        (size * 2 / 3) //33%
#define MT6991_ODDMR_DMR_ULTRA_FAIL_LV(size)        (size * 2 / 4) //50%

/* ultra&preultra in mt6991 */
#define MT6991_ODDMR_PRE_ULTRA_RISE_LV(size)    (size * 1 / 3)
#define MT6991_ODDMR_PRE_ULTRA_FAIL_LV(size)    (size * 1 / 4)
#define MT6991_ODDMR_ULTRA_RISE_LV(size)        (size * 2 / 3)
#define MT6991_ODDMR_ULTRA_FAIL_LV(size)        (size * 2 / 4)


#define ODDMR_ENABLE_IRQ
#define ODDMR_IRQ_MASK_VAL 0x2F

/* DBI: deburn in mt6989 */
#define DISP_ODDMR_REG_DMR_DBI_EN (0x210)//bit 0
#define DISP_ODDMR_REG_DMR_DBI_OUT_CUP_EN (0x214)//bit 0
#define DISP_ODDMR_REG_DMR_DBI_DITHER_EN (0x234)//bit 0
#define DISP_ODDMR_REG_DMR_FRAME_SCALER_FOR_DBI_R (0x24C)//bit 0-15
#define DISP_ODDMR_REG_DMR_FRAME_SCALER_FOR_DBI_G (0x268)//bit 0-15
#define DISP_ODDMR_REG_DMR_FRAME_SCALER_FOR_DBI_B (0x284)//bit 0-15
#define DISP_ODDMR_REG_DMR_DBI_RANGE_SEL_R (0x2B0)//bit 0-2
#define DISP_ODDMR_REG_DMR_DBI_RANGE_SEL_G (0x2C4)//bit 0-2
#define DISP_ODDMR_REG_DMR_DBI_RANGE_SEL_B (0x2D8)//bit 0-2
/* 0 ~ 20 */
#define DISP_ODDMR_REG_DMR_GLOBAL_DBI_GAIN_R_0 (0xD00)//bit 0-11
/* 0 ~ 20 */
#define DISP_ODDMR_REG_DMR_GLOBAL_DBI_GAIN_G_0 (0xD54)//bit 0-11
/* 0 ~ 20 */
#define DISP_ODDMR_REG_DMR_GLOBAL_DBI_GAIN_B_0 (0xDA8)//bit 0-11
#define DISP_ODDMR_REG_DMR_DBI_LAYER_NUM (0xE40)//bit 0-3
#define DISP_ODDMR_REG_DMR_DBI_PIXEL_SHIFT_EN (0xED8)//bit 0
#define DISP_ODDMR_REG_DMR_DBI_OVERFLOW_R (0xF04)//bit 0
#define DISP_ODDMR_REG_DMR_DBI_OVERFLOW_G (0xF08)//bit 0
#define DISP_ODDMR_REG_DMR_DBI_OVERFLOW_B (0xF0C)//bit 0
#define DISP_ODDMR_REG_DMR_DBI_OVERFLOW_CLEAR (0xF10)//bit 0
#define DISP_ODDMR_REG_DMR_DBI_H_NUM_R (0xF4C)//bit 0-1
#define DISP_ODDMR_REG_DMR_DBI_V_NUM_R (0xF50)//bit 0-1
#define DISP_ODDMR_REG_DMR_DBI_H_NUM_G (0xF54)//bit 0-1
#define DISP_ODDMR_REG_DMR_DBI_V_NUM_G (0xF58)//bit 0-1
#define DISP_ODDMR_REG_DMR_DBI_H_NUM_B (0xF5C)//bit 0-1
#define DISP_ODDMR_REG_DMR_DBI_V_NUM_B (0xF60)//bit 0-1
#define DISP_ODDMR_REG_DMR_AREAL_DBI_INDIV (0x1F20)//bit 0
#define DISP_ODDMR_REG_DMR_AREAL_DBI_COMP_R (0x1FA8)//bit 0-7
#define DISP_ODDMR_REG_DMR_AREAL_DBI_COMP_G (0x1FAC)//bit 0-7
#define DISP_ODDMR_REG_DMR_AREAL_DBI_COMP_B (0x1FB0)//bit 0-7

/* ODDMR Reg for Partial Update */
#define DISP_ODDMR_REG_DMR_Y_INI			(0xE30)//bit 0-12
#define DISP_ODDMR_REG_Y_IDX2_INI			(0x3D0)//bit 0-12
#define DISP_ODDMR_REG_Y_REMAIN2_INI		(0x3D4)//bit 0-12
//#define DISP_ODDMR_TOP_CRP_BYPASS			(0x1DB)//bit 0


/* DBI&DMR in mt6991 */
// mt6991 DBI&DMR TOP CTL
#define MT6991_DISP_ODDMR_TOP_CTR_1					0x004
#define MT6991_DISP_ODDMR_TOP_CTR_2					0x008
#define MT6991_DISP_ODDMR_TOP_CTR_3					0x00C
	#define MT6991_REG_ODDMR_BYPASS					REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_BYPASS_SHADOW				REG_FLD_MSB_LSB(5, 5)
	#define MT6991_REG_ODDMR_TOP_CLK_GATING_DB_EN	REG_FLD_MSB_LSB(14, 14)
	#define MT6991_REG_ODDMR_TOP_CLK_FORCE_EN		REG_FLD_MSB_LSB(15, 15)
#define MT6991_DISP_ODDMR_TOP_CTR_4					0x01C
	#define MT6991_REG_DMR_SW_RST					REG_FLD_MSB_LSB(1, 1)
#define MT6991_DISP_ODDMR_TOP_DMR_BYPASS			0x1C4
#define MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS			0x1C8
	#define MT6991_REG_OD_SPR2RGB_BYPASS			REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_SPR2RGB_BYPASS				REG_FLD_MSB_LSB(1, 1)
#define MT6991_DISP_ODDMR_TOP_CLK_GATING			0x1E0
#define MT6991_DISP_ODDMR_REG_DMR_UDMA_EN			0x1E4
	#define MT6991_REG_DMR_UDMA_EN					REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_DBI_UDMA_EN					REG_FLD_MSB_LSB(4, 4)
#define MT6991_DISP_ODDMR_REG_DMR_CLK_EN			0x10140
#define MT6991_DISP_ODDMR_REG_DMR_EN				0x10144
	#define MT6991_REG_DMR_EN						REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_DMR_DBI_EN					REG_FLD_MSB_LSB(1, 1)
	#define MT6991_REG_DMR_DBI_OUT_CUP_EN			REG_FLD_MSB_LSB(2, 2)

// mt6991 SMI SB
#define MT6991_DISP_ODDMR_SMI_SB_FLG_DBI				0x05C
	#define MT6991_REG_DBI_PREULTRA_RE_ULTRA_MASK		REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_DBI_PREULTRA_RE_ULTRA_FRCE		REG_FLD_MSB_LSB(1, 1)
	#define MT6991_REG_DBI_ULTRA_RE_MASK				REG_FLD_MSB_LSB(2, 2)
	#define MT6991_REG_DBI_ULTRA_RE_FRCE				REG_FLD_MSB_LSB(3, 3)
	#define MT6991_REG_DBI_POACH_CFG_OFF				REG_FLD_MSB_LSB(4, 4)
	#define MT6991_REG_DBI_RE_ULTRA_MODE				REG_FLD_MSB_LSB(11, 8)
#define MT6991_DISP_ODDMR_SMI_SB_FLG_DMR				0x060
	#define MT6991_REG_DMR_PREULTRA_RE_ULTRA_MASK		REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_DMR_PREULTRA_RE_ULTRA_FRCE		REG_FLD_MSB_LSB(1, 1)
	#define MT6991_REG_DMR_ULTRA_RE_MASK				REG_FLD_MSB_LSB(2, 2)
	#define MT6991_REG_DMR_ULTRA_RE_FRCE				REG_FLD_MSB_LSB(3, 3)
	#define MT6991_REG_DMR_POACH_CFG_OFF				REG_FLD_MSB_LSB(4, 4)
	#define MT6991_REG_DMR_RE_ULTRA_MODE				REG_FLD_MSB_LSB(11, 8)
#define MT6991_ODDMR_SMI_SB_FLG_ODR_3					0x070
	#define MT6991_REG_DMR_GUSER_CTRL_1					REG_FLD_MSB_LSB(15, 0)
#define MT6991_DISP_ODDMR_UDMA_DMR_CTRL21				0xC54
	#define MT6991_REG_DMR_REQ_PREULTRA_RISE_LV			REG_FLD_MSB_LSB(6, 0)
	#define MT6991_REG_DMR_REQ_PREULTRA_FORCE_HIGH		REG_FLD_MSB_LSB(7, 7)
	#define MT6991_REG_DMR_REQ_PREULTRA_FAIL_LV			REG_FLD_MSB_LSB(14, 8)
	#define MT6991_REG_DMR_REQ_PREULTRA_MASK			REG_FLD_MSB_LSB(15, 15)
#define MT6991_DISP_ODDMR_UDMA_DMR_CTRL22				0xC58
	#define MT6991_REG_DMR_REQ_ULTRA_RISE_LV			REG_FLD_MSB_LSB(6, 0)
	#define MT6991_REG_DMR_REQ_ULTRA_FORCE_HIGH			REG_FLD_MSB_LSB(7, 7)
	#define MT6991_REG_DMR_REQ_ULTRA_FAIL_LV			REG_FLD_MSB_LSB(14, 8)
	#define MT6991_REG_DMR_REQ_ULTRA_MASK				REG_FLD_MSB_LSB(15, 15)
#define MT6991_DISP_ODDMR_UDMA_DMR_CTRL23				0xC5C
	#define MT6991_REG_DMR_REQ_URGENT_RISE_LV			REG_FLD_MSB_LSB(6, 0)
	#define MT6991_REG_DMR_REQ_URGENT_FORCE_HIGH		REG_FLD_MSB_LSB(7, 7)
	#define MT6991_REG_DMR_REQ_URGENT_FAIL_LV			REG_FLD_MSB_LSB(14, 8)
	#define MT6991_REG_DMR_REQ_URGENT_MASK				REG_FLD_MSB_LSB(15, 15)
#define MT6991_DISP_ODDMR_UDMA_DMR_CTRL30				0xC6C
	#define MT6991_REG_DMR_REQ_STASH_LEAD_CNT			REG_FLD_MSB_LSB(3, 0)
	#define MT6991_REG_DMR_REQ_STASH_EN					REG_FLD_MSB_LSB(8, 8)
#define MT6991_DISP_ODDMR_UDMA_DMR_CTRL70				0xD00
	#define MT6991_REG_DMR_UDMA_SW_RST					REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_DMR_SW_RST_PRTCL_PROT			REG_FLD_MSB_LSB(6, 6)
	#define MT6991_REG_DMR_PRTCL_PROT_OFF				REG_FLD_MSB_LSB(7, 7)
	#define MT6991_REG_DMR_PRTCL_PROT_MASK_MODE			REG_FLD_MSB_LSB(8, 8)
#define MT6991_DISP_ODDMR_UDMA_DMR_CTRL88				0xDC0
	#define MT6991_REG_DMR_RB_EN						REG_FLD_MSB_LSB(0, 0)
#define MT6991_DISP_ODDMR_UDMA_DBI_CTRL21				0xE54
	#define MT6991_REG_DBI_REQ_PREULTRA_RISE_LV			REG_FLD_MSB_LSB(6, 0)
	#define MT6991_REG_DBI_REQ_PREULTRA_FORCE_HIGH		REG_FLD_MSB_LSB(7, 7)
	#define MT6991_REG_DBI_REQ_PREULTRA_FAIL_LV			REG_FLD_MSB_LSB(14, 8)
	#define MT6991_REG_DBI_REQ_PREULTRA_MASK			REG_FLD_MSB_LSB(15, 15)
#define MT6991_DISP_ODDMR_UDMA_DBI_CTRL22				0xE58
	#define MT6991_REG_DBI_REQ_ULTRA_RISE_LV			REG_FLD_MSB_LSB(6, 0)
	#define MT6991_REG_DBI_REQ_ULTRA_FORCE_HIGH			REG_FLD_MSB_LSB(7, 7)
	#define MT6991_REG_DBI_REQ_ULTRA_FAIL_LV			REG_FLD_MSB_LSB(14, 8)
	#define MT6991_REG_DBI_REQ_ULTRA_MASK				REG_FLD_MSB_LSB(15, 15)
#define MT6991_DISP_ODDMR_UDMA_DBI_CTRL23				0xE5C
	#define MT6991_REG_DBI_REQ_URGENT_RISE_LV			REG_FLD_MSB_LSB(6, 0)
	#define MT6991_REG_DBI_REQ_URGENT_FORCE_HIGH		REG_FLD_MSB_LSB(7, 7)
	#define MT6991_REG_DBI_REQ_URGENT_FAIL_LV			REG_FLD_MSB_LSB(14, 8)
	#define MT6991_REG_DBI_REQ_URGENT_MASK				REG_FLD_MSB_LSB(15, 15)
#define MT6991_DISP_ODDMR_UDMA_DBI_CTRL30				0xE6C
	#define MT6991_REG_DBI_REQ_STASH_LEAD_CNT			REG_FLD_MSB_LSB(3, 0)
	#define MT6991_REG_DBI_REQ_STASH_EN					REG_FLD_MSB_LSB(8, 8)
#define MT6991_DISP_ODDMR_UDMA_DBI_CTRL70				0xF00
	#define MT6991_REG_PRTCL_PROT_OFF					REG_FLD_MSB_LSB(7, 7)
#define MT6991_DISP_ODDMR_UDMA_DBI_CTRL88				0xFC0
	#define MT6991_REG_RB_EN							REG_FLD_MSB_LSB(0, 0)


// mt6991 DBI DDREN CTL
#define MT6991_DISP_ODDMR_REG_DBI_DDREN_CTRL			0x084
#define MT6991_DISP_ODDMR_REG_DMR_DDREN_CTRL			0x088

// mt6991 DBI CTL
#define MT6991_DISP_ODDMR_REG_ODDMR_FRAME_WIDTH			0x098
#define MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT		0x09C
#define MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE		0x0A0
#define MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE		0x0A4
#define MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_HSIZE		0x0A8
#define MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE		0x0AC
#define MT6991_DISP_ODDMR_REG_DBI_UDMA_WIDTH			0x118
#define MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT			0x11C
#define MT6991_DISP_ODDMR_REG_DBI_UDMA_LN_OFFSET		0x120
#define MT6991_DISP_ODDMR_REG_DBI_UDMA_BASE_ADDR_0		0x124
#define MT6991_DISP_ODDMR_REG_DBI_UDMA_BASE_ADDR_1		0x128
#define MT6991_DISP_ODDMR_REG_DBI_UDMA_X_INI			0x12C
#define MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI			0x130
#define MT6991_DISP_ODDMR_REG_DMR_UDMA_HEIGHT_OUT		0x13C
#define MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_0		0x144
#define MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_1		0x148
#define MT6991_DISP_ODDMR_REG_DMR_UDMA_Y_INI			0x150
#define MT6991_DISP_ODDMR_REG_DMR_SPR_MODE				0x154
	#define MT6991_REG_DMR_SPR_MODE						REG_FLD_MSB_LSB(1, 0)
	#define MT6991_REG_DMR_DELTA_MODE_EVEN				REG_FLD_MSB_LSB(4, 2)
	#define MT6991_REG_DMR_DELTA_MODE_ODD				REG_FLD_MSB_LSB(7, 5)
	#define MT6991_REG_OD_SPR_MODE						REG_FLD_MSB_LSB(9, 8) //MT6991 OD mode
	#define MT6991_REG_OD_DELTA_MODE_EVEN				REG_FLD_MSB_LSB(12, 10) //MT6991 OD mode
	#define MT6991_REG_OD_DELTA_MODE_ODD				REG_FLD_MSB_LSB(15, 13) //MT6991 OD mode
#define MT6991_DISP_ODDMR_REG_ODDMR_OUTP_EN				0x158
	#define MT6991_REG_ODDMR_OUTP_EN					REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_ODDMR_OUTP_RST					REG_FLD_MSB_LSB(1, 1)
	#define MT6991_REG_ODDMR_OUTP_1TNP					REG_FLD_MSB_LSB(3, 2)
	#define MT6991_REG_ODDMR_INP_EN						REG_FLD_MSB_LSB(4, 4)
	#define MT6991_REG_ODDMR_INP_RST					REG_FLD_MSB_LSB(5, 5)
	#define MT6991_REG_ODDMR_INP_1TNP					REG_FLD_MSB_LSB(7, 6)
#define MT6991_DISP_ODDMR_REG_DMR_FRAME_WIDTH			0x10100
#define MT6991_DISP_ODDMR_REG_DMR_FRAME_HEIGHT			0x10104
#define MT6991_DISP_ODDMR_REG_DMR_REAL_FRAME_WIDTH		0x10108
#define MT6991_DISP_ODDMR_REG_DMR_REAL_FRAME_HEIGHT		0x1010C
#define MT6991_DISP_ODDMR_REG_DMR_REMAP					0x10158
	#define MT6991_REG_DMR_REMAP_EN						REG_FLD_MSB_LSB(0, 0)
	#define MT6991_REG_DMR_REMAP_GAIN					REG_FLD_MSB_LSB(20, 8)
	#define MT6991_REG_DMR_BIAS_EN						REG_FLD_MSB_LSB(24, 24)
#define MT6991_DISP_ODDMR_DMR_SHADOW_CTRL				0x106C8
	#define MT6991_DMR_BYPASS_SHADOW					REG_FLD_MSB_LSB(0, 0)
	#define MT6991_DMR_FORCE_COMMIT						REG_FLD_MSB_LSB(1, 1)
	#define MT6991_DMR_READ_WRK_REG						REG_FLD_MSB_LSB(2, 2)
#define MT6991_DISP_ODDMR_REG_DBI_SCL_HSIZE				0x10708
#define MT6991_DISP_ODDMR_REG_DBI_SCL_VSIZE				0x1070C
#define MT6991_DISP_ODDMR_DBI_SHADOW_CTRL				0x10734
	#define MT6991_DBI_BYPASS_SHADOW					REG_FLD_MSB_LSB(0, 0)
	#define MT6991_DBI_FORCE_COMMIT						REG_FLD_MSB_LSB(1, 1)
	#define MT6991_DBI_READ_WRK_REG						REG_FLD_MSB_LSB(2, 2)
#define MT6991_DISP_ODDMR_MURA_SHADOW_CTRL				0x108B8
	#define MT6991_DMR_DECODER_BYPASS_SHADWO			REG_FLD_MSB_LSB(0, 0)
	#define MT6991_DMR_DECODER_FORCE_COMMIT				REG_FLD_MSB_LSB(1, 1)
	#define MT6991_DMR_DECODER_READ_WRK_REG				REG_FLD_MSB_LSB(2, 2)

/* mt6991 SPR2RGB */
#define MT6991_DISP_ODDMR_REG_SPR_COMP_EN			0x10900
#define MT6991_DISP_ODDMR_REG_SPR_MASK_0			0x10904
#define MT6991_DISP_ODDMR_REG_SPR_MASK_1			0x10908
#define MT6991_DISP_ODDMR_REG_SPR_MASK_2			0x1090C
#define MT6991_DISP_ODDMR_REG_SPR_MASK_3			0x10910
#define MT6991_DISP_ODDMR_REG_SPR_MASK_4			0x10914
#define MT6991_DISP_ODDMR_REG_SPR_MASK_5			0x10918
#define MT6991_DISP_ODDMR_REG_SPR_MASK_2X2			0x1091C
#define MT6991_DISP_ODDMR_REG_SPR_PANEL_WIDTH		0x10920
#define MT6991_DISP_ODDMR_REG_SPR_X_INIT			0x10924
#define MT6991_DISP_ODDMR_REG_SPR_REMAP_EN			0x10928
#define MT6991_DISP_ODDMR_REG_SPR_REMAP_GAIN		0x1092C
#define MT6991_DISP_ODDMR_SPR_SHADOW_CTRL			0x10934
	#define MT6991_SPR_BYPASS_SHADOW				REG_FLD_MSB_LSB(0, 0)
	#define MT6991_SPR_FORCE_COMMIT					REG_FLD_MSB_LSB(1, 1)
	#define MT6991_SPR_READ_WRK_REG					REG_FLD_MSB_LSB(2, 2)

/* mt6991 partial update */
#define MT6991_DISP_ODDMR_REG_DBI_ROI_H_START		0x106E4
#define MT6991_DISP_ODDMR_REG_DBI_ROI_H_END			0x106E8
#define MT6991_DISP_ODDMR_REG_DBI_ROI_V_START		0x106EC
#define MT6991_DISP_ODDMR_REG_DBI_ROI_V_END			0x106F0
#define MT6991_DISP_ODDMR_REG_DBI_ROI_EN			0x106F4
	#define MT6991_REG_DBI_ROI_EN					BIT(0)
	#define MT6991_REG_DBI_ROI_BYPASS				BIT(8)
#define MT6991_DISP_ODDMR_REG_DBI_HSIZE				0x10700
#define MT6991_DISP_ODDMR_REG_DBI_VSIZE				0x10704

/* dbi table crop */
#define MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R			(0x1073C)
	#define MT6991_REG_DBI_V_LENGTH_R				REG_FLD_MSB_LSB(13, 0)
	#define MT6991_REG_DBI_V_ST_R					REG_FLD_MSB_LSB(29, 16)
	#define MT6991_REG_DBI_V_CROP_EN_R				REG_FLD_MSB_LSB(31, 31)
#define MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G			(0x10744)
	#define MT6991_REG_DBI_V_LENGTH_G				REG_FLD_MSB_LSB(13, 0)
	#define MT6991_REG_DBI_V_ST_G					REG_FLD_MSB_LSB(29, 16)
	#define MT6991_REG_DBI_V_CROP_EN_G				REG_FLD_MSB_LSB(31, 31)
#define MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B			(0x1074C)
	#define MT6991_REG_DBI_V_LENGTH_B				REG_FLD_MSB_LSB(13, 0)
	#define MT6991_REG_DBI_V_ST_B					REG_FLD_MSB_LSB(29, 16)
	#define MT6991_REG_DBI_V_CROP_EN_B				REG_FLD_MSB_LSB(31, 31)

#define MT6991_DISP_ODDMR_REG_DMR_X_INI				0x10830
#define MT6991_DISP_ODDMR_REG_DMR_Y_INI				0x10834
#define MT6991_DISP_ODDMR_REG_V_CROP_EN_R			0x10A04
	#define MT6991_REG_DMR_V_LENGTH_R				REG_FLD_MSB_LSB(13, 0)
	#define MT6991_REG_DMR_V_ST_R					REG_FLD_MSB_LSB(29, 16)
	#define MT6991_REG_DMR_V_CROP_EN_R				REG_FLD_MSB_LSB(31, 31)
#define MT6991_DISP_ODDMR_REG_V_CROP_EN_G			0x10A0C
	#define MT6991_REG_DMR_V_LENGTH_G				REG_FLD_MSB_LSB(13, 0)
	#define MT6991_REG_DMR_V_ST_G					REG_FLD_MSB_LSB(29, 16)
	#define MT6991_REG_DMR_V_CROP_EN_G				REG_FLD_MSB_LSB(31, 31)
#define MT6991_DISP_ODDMR_REG_V_CROP_EN_B			0x10A14
	#define MT6991_REG_DMR_V_LENGTH_B				REG_FLD_MSB_LSB(13, 0)
	#define MT6991_REG_DMR_V_ST_B					REG_FLD_MSB_LSB(29, 16)
	#define MT6991_REG_DMR_V_CROP_EN_B				REG_FLD_MSB_LSB(31, 31)

/* ODDMR in mt6993 */
//ODDMR TOP
#define MT6993_DISP_ODDMR_TOP_CTR_4					0x10
	#define MT6993_REG_DBI_SW_RST					REG_FLD_MSB_LSB(2, 2)
	#define MT6993_REG_DMR_SW_RST					REG_FLD_MSB_LSB(1, 1)

#define DISP_ODDMR_TOP_SHADOW_CTRL					0x14
	#define BYPASS_SHADOW							REG_FLD_MSB_LSB(0, 0)
	#define SR2WRK_CG_ON							REG_FLD_MSB_LSB(3, 3)
#define MT6993_DISP_ODDMR_REG_ODDMR_OUTP_EN			0x158
	#define MT6993_REG_ODDMR_OUTP_EN				REG_FLD_MSB_LSB(0, 0)
	#define MT6993_REG_ODDMR_OUTP_SUB_EN			REG_FLD_MSB_LSB(4, 4)
	#define MT6993_REG_ODDMR_INP_EN					REG_FLD_MSB_LSB(8, 8)
#define DISP_ODDMR_TOP_DBI_BYPASS					0x1CC
//OD ctrl
#define DISP_ODDMR_OD_SHADOW_CTRL					0x18
	#define OD_BYPASS_SHADOW						REG_FLD_MSB_LSB(0, 0)
#define DISP_ODDMR_DDREN_CTRL_ODW					0x7C
#define DISP_ODDMR_DDREN_CTRL_ODR					0x80
	#define REG_OD_DDREN_REQ_DISABLE				REG_FLD_MSB_LSB(0, 0)
	#define REG_OD_USE_HRT_DDREN_REQ				REG_FLD_MSB_LSB(1, 1)
	#define REG_OD_STASH_DDREN_REQ_DISABLE			REG_FLD_MSB_LSB(16, 16)
	#define REG_OD_STASH_USE_HRT_DDREN_REQ			REG_FLD_MSB_LSB(17, 17)
#define MT6993_DISP_ODDMR_SMI_SB_FLG_ODR			0x54
	#define REG_ODR_STASH_ULTRA_RE_FRCE				REG_FLD_MSB_LSB(19, 19)
#define MT6993_DISP_ODDMR_SMI_SB_FLG_ODW			0x58
	#define REG_ODW_STASH_ULTRA_WR_FRCE				REG_FLD_MSB_LSB(19, 19)
#define MT6993_DISP_ODDMR_UDMA_R_CTRL30				(0x006C + MT6991_DISP_ODDMR_REG_UDMA_R_BASE)
#define MT6993_DISP_ODDMR_UDMA_W_CTR_1B				(0x006C + MT6991_DISP_ODDMR_REG_UDMA_W_BASE)
#define MT6993_DISP_ODDMR_OD_USER_WEIGHT_R (0x004C + MT6991_DISP_ODDMR_REG_OD_BASE)
#define MT6993_DISP_ODDMR_OD_USER_WEIGHT_B (0x0050 + MT6991_DISP_ODDMR_REG_OD_BASE)
//DMR ctrl
#define DISP_ODDMR_MURA_SHADOW_CTRL					0x108B8
	#define MURA_BYPASS_SHADOW						REG_FLD_MSB_LSB(0, 0)
	#define MURA_SR2WRK_CG_ON						REG_FLD_MSB_LSB(3, 3)
#define DISP_ODDMR_AREAL_SHADOW_CTRL				0x108BC
	#define AREAL_BYPASS_SHADOW						REG_FLD_MSB_LSB(0, 0)
	#define AREAL_SR2WRK_CG_ON						REG_FLD_MSB_LSB(3, 3)
#define DISP_ODDMR_DMR_SHADOW_CTRL					0x106C8
	#define DMR_BYPASS_SHADOW						REG_FLD_MSB_LSB(0, 0)
	#define DMR_SR2WRK_CG_ON						REG_FLD_MSB_LSB(3, 3)
#define MT6993_DISP_ODDMR_REG_DMR_Y_INI				0xB8
#define DISP_ODDMR_REG_DMR_FRAME_WIDTH				0xBC
#define DISP_ODDMR_REG_DMR_FRAME_HEIGHT				0xC0
#define DISP_ODDMR_REG_DMR_REAL_FRAME_WIDTH			0xC4
#define DISP_ODDMR_REG_DMR_REAL_FRAME_HEIGHT		0xC8
#define MT6993_DISP_ODDMR_REG_DMR_CLK_EN			0x10140
	#define MT6993_REG_DMR_CLK_EN					REG_FLD_MSB_LSB(0, 0)
	#define MT6993_REG_DBI_CLK_EN					REG_FLD_MSB_LSB(8, 8)

#define MT6993_DISP_ODDMR_DDREN_CTRL_DBI					0x74
	#define REG_DBI_DDREN_REQ_DISABLE				REG_FLD_MSB_LSB(0, 0)
	#define REG_DBI_USE_HRT_DDREN_REQ				REG_FLD_MSB_LSB(1, 1)
	#define REG_DBI_STASH_DDREN_REQ_DISABLE			REG_FLD_MSB_LSB(16, 16)
	#define REG_DBI_STASH_USE_HRT_DDREN_REQ			REG_FLD_MSB_LSB(17, 17)

#define DISP_ODDMR_DDREN_CTRL_DMR					0x78
	#define REG_DMR_DDREN_REQ_DISABLE				REG_FLD_MSB_LSB(0, 0)
	#define REG_DMR_USE_HRT_DDREN_REQ				REG_FLD_MSB_LSB(1, 1)
	#define REG_DMR_STASH_DDREN_REQ_DISABLE			REG_FLD_MSB_LSB(16, 16)
	#define REG_DMR_STASH_USE_HRT_DDREN_REQ			REG_FLD_MSB_LSB(17, 17)

#define MT6993_DISP_ODDMR_SMI_SB_FLG_DBI			0x5c
	#define MT6993_REG_DBI_RE_ULTRA_MODE			REG_FLD_MSB_LSB(11, 8)
	#define MT6993_REG_DBI_STASH_ULTRA_RE_FRCE		REG_FLD_MSB_LSB(19, 19)

#define MT6993_DISP_ODDMR_SMI_SB_FLG_DMR			0x60
	#define MT6993_REG_DMR_RE_ULTRA_MODE			REG_FLD_MSB_LSB(11, 8)
	#define MT6993_REG_DMR_STASH_ULTRA_RE_FRCE		REG_FLD_MSB_LSB(19, 19)

#define MT6993_DISP_ODDMR_TOP_DBI_BYPASS			0x1cc

//DBI ctrl
#define DISP_ODDMR_DBI_SHADOW_CTRL					0x10734
	#define DBI_BYPASS_SHADOW						REG_FLD_MSB_LSB(0, 0)
	#define DBI_SR2WRK_CG_ON						REG_FLD_MSB_LSB(3, 3)
//SPR2RGB ctrl
#define DISP_ODDMR_SPR_SHADOW_CTRL					0x10934
	#define SPR2RGB_BYPASS_SHADOW					REG_FLD_MSB_LSB(0, 0)
	#define SPR2RGB_SR2WRK_CG_ON					REG_FLD_MSB_LSB(3, 3)
#define DISP_ODDMR_OD_SPR_SHADOW_CTRL				0x10974
	#define OD_SPR2RGB_BYPASS_SHADOW				REG_FLD_MSB_LSB(0, 0)
	#define OD_SPR2RGB_SR2WRK_CG_ON					REG_FLD_MSB_LSB(3, 3)

#define DISP_ODDMR_DBI_GUSER_CTRL_1 0x084
	#define REG_DBI_SLC_AR REG_FLD_MSB_LSB(4, 0)
	#define REG_DBI_SLC_GID REG_FLD_MSB_LSB(22, 16)
#define DISP_ODDMR_DMR_GUSER_CTRL_1 0x088
	#define REG_DMR_SLC_AR REG_FLD_MSB_LSB(4, 0)
	#define REG_DMR_SLC_GID REG_FLD_MSB_LSB(22, 16)
#define DISP_ODDMR_ODR_GUSER_CTRL_1 0x08c
	#define REG_ODR_SLC_AR REG_FLD_MSB_LSB(4, 0)
#define DISP_ODDMR_ODW_GUSER_CTRL_1 0x090
	#define REG_ODW_SLC_AR REG_FLD_MSB_LSB(4, 0)

#define DISP_ODDMR_OUTP_SUB_IN_HSIZE 0x1E8
#define DISP_ODDMR_OUTP_SUB_IN_VSIZE 0x1EC
#define DISP_ODDMR_OUTP_SUB_OUT_HSIZE 0x1F0
#define DISP_ODDMR_OUTP_SUB_OUT_VSIZE 0x0F4


#define REG_DBI_IR_DROP_STST_ACC_R (0x10c74)
#define REG_DBI_IR_DROP_STST_ACC_G (0x10c78)
#define REG_DBI_IR_DROP_STST_ACC_B (0x10c7c)
#define REG_DBI_IR_DROP_STST_SQUA_ACC_R_0 (0x10c80)
#define REG_DBI_IR_DROP_STST_SQUA_ACC_R_1 (0x10c84)
#define REG_DBI_IR_DROP_STST_SQUA_ACC_G_0 (0x10c88)
#define REG_DBI_IR_DROP_STST_SQUA_ACC_G_1 (0x10c8c)
#define REG_DBI_IR_DROP_STST_SQUA_ACC_B_0 (0x10c90)
#define REG_DBI_IR_DROP_STST_SQUA_ACC_B_1 (0x10c94)
#define REG_DBI_IR_DROP_STST_CLEAR (0x10c98)
#define REG_DBI_IR_DROP_STST_FORCE_UPDATE (0x10c9c)
#define REG_DBI_IR_DROP_EN (0x10ca4)


static bool debug_flow_log;
#define ODDMRFLOW_LOG(fmt, arg...) do { \
	if (debug_flow_log) \
		DDPMSG("[FLOW]%s:" fmt, __func__, ##arg); \
	} while (0)

static bool debug_flow_msg;
#define ODDMRFLOW_MSG(fmt, arg...) do { \
	if (debug_flow_msg) \
		DDPMSG("[FLOW]%s:" fmt, __func__, ##arg); \
	} while (0)

static bool debug_low_log;
#define ODDMRLOW_LOG(fmt, arg...) do { \
	if (debug_low_log) \
		DDPMSG("[LOW]%s:" fmt, __func__, ##arg); \
	} while (0)

static bool debug_api_log;
#define ODDMRAPI_LOG(fmt, arg...) do { \
	if (debug_api_log) \
		DDPMSG("[API]%s:" fmt, __func__, ##arg); \
	} while (0)

//TODO split dmr table in sw for dynamic overhead
static bool g_oddmr_ddren = true;
static bool g_oddmr_hrt_en = true;
static bool g_oddmr_dump_en;
static uint32_t g_od_udma_merge_lines;
#define MAX_LONG_BURST_SIZE 16
#define DDR_RATE_800
#ifdef DDR_RATE_800
static uint32_t g_od_udma_effi[MAX_LONG_BURST_SIZE] = {
	3436, 6946, 6327, 8883,
	7001, 9045, 7357, 9013,
	7780, 8963, 7919, 8682,
	8095, 8803, 7821, 8611
};
#endif
#ifdef DDR_RATE_1600
static uint32_t g_od_udma_effi[MAX_LONG_BURST_SIZE] = {
	3183, 6356, 6365, 8933,
	7525, 9186, 8224, 9491,
	8390, 9578, 8697, 9521,
	8761, 9471, 8825, 9613
};
#endif
static uint32_t g_od_udma_merge_lines_cand[] = {
	1, 2, 4, 6, 8, 10, 12, 14, 16,
};



static unsigned char lookup[16] = {
	0x0, 0x8, 0x4, 0xc, 0x2, 0xa, 0x6, 0xe,
	0x1, 0x9, 0x5, 0xd, 0x3, 0xb, 0x7, 0xf,
};

enum ODDMR_SLC_STATE {
	ODDMR_SLC_UNINIT = 0,
	ODDMR_SLC_REQUESTED = 1,
	ODDMR_SLC_VALID = 2,
};

static int g_slc_gid[ODDMR_SLC_NUM] = {-1, -1, -1};
static int g_slc_state[ODDMR_SLC_NUM];
static int g_slc_read_alloc;
static int g_slc_period;

static int g_dbi_update;
static bool g_dmr_dump_en;
#define DMR_LN_OFFSET 2048

/* 0: instant trigger, 1: delay trigger 2: no trigger*/
static uint32_t g_od_check_trigger = 1;
/*
 * od err: bit(0-3)
 * dmr err: bit(4-7)
 */
#define ODDMR_OD_UDMA_W_ERR 0x01
#define ODDMR_OD_UDMA_R_ERR 0x02
static unsigned int oddmr_err_trigger;
static unsigned int oddmr_err_trigger_mask = 0xFF;

// It's a work around for no comp assigned in functions.
struct mtk_disp_oddmr *g_oddmr_priv;

static DECLARE_WAIT_QUEUE_HEAD(g_oddmr_hrt_wq);

typedef phys_addr_t (*scp_get_reserve_mem_phys_by_id)(enum scp_reserve_mem_id_t id);
typedef phys_addr_t (*scp_get_reserve_mem_virt_by_id)(enum scp_reserve_mem_id_t id);
typedef phys_addr_t (*scp_get_reserve_mem_size_by_id)(enum scp_reserve_mem_id_t id);

scp_get_reserve_mem_phys_by_id get_mem_phys;
scp_get_reserve_mem_virt_by_id get_mem_virt;
scp_get_reserve_mem_size_by_id get_mem_size;

static void mtk_oddmr_od_hsk_force_clk(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static void mtk_oddmr_od_smi(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static void mtk_oddmr_od_set_dram(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static void mtk_oddmr_od_set_dram(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static void mtk_oddmr_set_od_enable(struct mtk_ddp_comp *comp, uint32_t enable,
		bool force_config, struct cmdq_pkt *handle);
static void mtk_oddmr_set_od_enable_dual(struct mtk_ddp_comp *comp, uint32_t enable,
		bool force_config, struct cmdq_pkt *handle);
static uint32_t mtk_oddmr_od_get_dram_size(struct mtk_ddp_comp *comp, uint32_t width,
		uint32_t height, uint32_t scaling_mode, uint32_t od_mode, uint32_t channel, int is_write);
static uint32_t mtk_oddmr_od_get_data_size(struct mtk_ddp_comp *comp, uint32_t width, uint32_t height,
		uint32_t scaling_mode, uint32_t od_mode, uint32_t channel);
static int mtk_oddmr_od_get_bpc(uint32_t od_mode, uint32_t channel);
static void mtk_oddmr_od_dummy(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static int mtk_oddmr_od_set_partial_update(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *handle, unsigned int top_overhead_v,
		unsigned int bot_overhead_v, unsigned int full_height);
static void mtk_oddmr_od_set_full_height(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle);
static int mtk_oddmr_od_trigger_frame(struct mtk_ddp_comp *comp);
static int mtk_oddmr_od_dump_sram(struct mtk_ddp_comp *comp, int sram_idx,
		int channel, bool od_sram_check);

static void mtk_oddmr_dmr_gain_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, unsigned int dbv_node, unsigned int fps_node,
		struct mtk_drm_dmr_cfg_info *cfg_info);
static void mtk_oddmr_tuning_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, struct mtk_drm_oddmr_reg_tuning *tuning_info);
static void mtk_oddmr_set_dmr_enable_dual(struct mtk_ddp_comp *comp, uint32_t enable,
		struct cmdq_pkt *handle);
static void mtk_oddmr_dmr_common_init(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
//static void mtk_oddmr_dmr_smi_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static int mtk_oddmr_dmr_dbv_lookup(unsigned int dbv, struct mtk_drm_dmr_cfg_info *cfg_info,
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node, unsigned int *dbv_table_idx,
	unsigned int *dbv_node);
static int mtk_oddmr_dmr_fps_lookup(unsigned int fps, struct mtk_drm_dmr_cfg_info *cfg_info,
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node, unsigned int *fps_table_idx,
	unsigned int *fps_node);
static void mtk_oddmr_dmr_static_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, struct mtk_drm_dmr_static_cfg *static_cfg_data);
static void mtk_oddmr_set_dmr_enable(struct mtk_ddp_comp *comp, uint32_t enable,
		struct cmdq_pkt *handle);

static int mtk_oddmr_dbi_dbv_lookup(unsigned int dbv, unsigned int *dbv_node_array,
	unsigned int dbv_node_num, unsigned int *dbv_node);
static int mtk_oddmr_dbi_fps_lookup(unsigned int fps, struct mtk_drm_dbi_cfg_info *cfg_info,
		unsigned int *fps_node);
static void mtk_oddmr_set_dbi_enable(struct mtk_ddp_comp *comp, uint32_t enable,
		struct cmdq_pkt *handle);
static void mtk_oddmr_dmr_change_remap_gain(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg);
static void mtk_oddmr_dbi_change_remap_gain(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, uint32_t cur_max_time);
static void mtk_oddmr_remap_set_enable(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, bool en);
static int mtk_oddmr_remap_enable(struct mtk_ddp_comp *comp, bool en);
static void mtk_oddmr_dbi_dbv_table_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, unsigned int dbv_node,
		struct mtk_drm_dbi_cfg_info *cfg_info);
static void mtk_oddmr_dbi_gain_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, unsigned int dbv_node, unsigned int fps_node,
		struct mtk_drm_dbi_cfg_info *cfg_info, unsigned int gain_ratio);
static int mtk_dbi_scp_set_semaphore_noirq(struct mtk_ddp_comp *comp, bool lock);

//static void mtk_oddmr_dbi_smi_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static inline struct mtk_disp_oddmr *comp_to_oddmr(struct mtk_ddp_comp *comp);
static int mtk_oddmr_dmr_enable(struct mtk_ddp_comp *comp, bool en);
static int mtk_oddmr_create_workqueue(struct mtk_disp_oddmr *oddmr_data);
static int disp_oddmr_sof_kthread(void *data);
static void mtk_oddmr_dmr_smi(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static void mtk_oddmr_dbi_smi(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static void mtk_oddmr_dbi_common_init(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg);
static void mtk_oddmr_dbi_read_ir_drop(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle);

static inline unsigned int mtk_oddmr_read(struct mtk_ddp_comp *comp,
		unsigned int offset)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	u32 max_offset = 0x2000;

	if (oddmr_data->data->dbi_version >= MTK_DBI_V2 || oddmr_data->data->od_version >= MTK_OD_V2)
		max_offset = 0x20000;

	if (offset >= max_offset || (offset % 4) != 0) {
		PC_ERR("%s: invalid addr 0x%x\n",__func__, offset);
		return 0;
	}

	return readl(comp->regs + offset);
}

static inline void mtk_oddmr_write_mask_cpu(struct mtk_ddp_comp *comp,
		unsigned int value, unsigned int offset, unsigned int mask)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	u32 max_offset = 0x2000;
	unsigned int tmp;

	if (oddmr_data->data->dbi_version >= MTK_DBI_V2 || oddmr_data->data->od_version >= MTK_OD_V2)
		max_offset = 0x20000;

	if (offset >= max_offset || (offset % 4) != 0) {
		PC_ERR("%s: invalid addr 0x%x\n",
				__func__, offset);
		return;
	}

	tmp = readl(comp->regs + offset);
	tmp = (tmp & ~mask) | (value & mask);
	writel(tmp, comp->regs + offset);
}

static inline void mtk_oddmr_write_cpu(struct mtk_ddp_comp *comp,
		unsigned int value, unsigned int offset)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	u32 max_offset = 0x2000;

	if (oddmr_data->data->dbi_version >= MTK_DBI_V2 || oddmr_data->data->od_version >= MTK_OD_V2)
		max_offset = 0x20000;

	if (offset >= max_offset || (offset % 4) != 0) {
		PC_ERR("%s: invalid addr 0x%x\n",
				__func__, offset);
		return;
	}
	writel(value, comp->regs + offset);
}

static inline void mtk_oddmr_write(struct mtk_ddp_comp *comp, unsigned int value,
		unsigned int offset, void *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	u32 max_offset = 0x2000;

	if (comp == NULL) {
		PC_ERR("%s: invalid comp\n", __func__);
		return;
	}
	if (oddmr_data->data->dbi_version >= MTK_DBI_V2 || oddmr_data->data->od_version >= MTK_OD_V2)
		max_offset = 0x20000;

	if (offset >= max_offset || (offset % 4) != 0) {
		PC_ERR("%s: invalid addr 0x%x\n",
				__func__, offset);
		return;
	}
	if (handle != NULL) {
		cmdq_pkt_write((struct cmdq_pkt *)handle, comp->cmdq_base,
				comp->regs_pa + offset, value, ~0);
	} else {
		writel(value, comp->regs + offset);
	}
}

static inline void mtk_oddmr_write_mask(struct mtk_ddp_comp *comp, unsigned int value,
		unsigned int offset, unsigned int mask, void *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	u32 max_offset = 0x2000;

	if (oddmr_data->data->dbi_version >= MTK_DBI_V2 || oddmr_data->data->od_version >= MTK_OD_V2)
		max_offset = 0x20000;

	if (offset >= max_offset || (offset % 4) != 0) {
		PC_ERR("%s: invalid addr 0x%x\n",
				__func__, offset);
		return;
	}

	if (handle != NULL) {
		cmdq_pkt_write((struct cmdq_pkt *)handle, comp->cmdq_base,
				comp->regs_pa + offset, value, mask);
	} else {
		mtk_oddmr_write_mask_cpu(comp, value, offset, mask);
	}
}

//config register with absolute PA address, value and mask.
static inline void mtk_oddmr_register_write_mask_cpu(struct mtk_ddp_comp *comp,
		unsigned int addr, unsigned int value, unsigned int mask)
{
	unsigned int tmp;
	void __iomem *offset = 0;

	if ((addr % 4) != 0) {
		PC_ERR("%s: invalid addr 0x%x\n",
				__func__, addr);
		return;
	}

	tmp = readl(offset + addr);
	tmp = (tmp & ~mask) | (value & mask);
	writel(tmp, (offset + addr));
}

static inline void mtk_oddmr_register_write_mask(struct mtk_ddp_comp *comp,
		unsigned int addr, unsigned int value, unsigned int mask, void *handle)
{
	if ((addr % 4) != 0) {
		PC_ERR("%s: invalid addr 0x%x\n",
				__func__, addr);
		return;
	}

	if (handle != NULL) {
		cmdq_pkt_write((struct cmdq_pkt *)handle, comp->cmdq_base,
				addr, value, mask);
	} else {
		mtk_oddmr_write_mask_cpu(comp, addr, value, mask);
	}
}

static inline struct mtk_disp_oddmr *comp_to_oddmr(struct mtk_ddp_comp *comp)
{
	return container_of(comp, struct mtk_disp_oddmr, ddp_comp);
}

/* must check after get current table idx*/
static inline bool mtk_oddmr_is_table_valid(int table_idx,
		bool *valid_table, const char *name, int line, int log)
{
	int i;
	char valid_table_str[OD_TABLE_MAX + 1];

	if (table_idx < 0) {
		if (log)
			PC_ERR("%s[%d] invalid tableidx %d\n",
					name, line, table_idx);
		return false;
	}
	if (valid_table[table_idx])
		return true;
	if (log) {
		for (i = 0; i < OD_TABLE_MAX; i++)
			valid_table_str[i] = valid_table[i] ? '1' : '0';
		valid_table_str[OD_TABLE_MAX] = '\0';
		PC_ERR("%s[%d] table %d is invalid: %s\n",
				name, line, table_idx, valid_table_str);
	}
	return false;
}
#define IS_TABLE_VALID(idx, valid) mtk_oddmr_is_table_valid(idx, valid, __func__, __LINE__, 1)
#define IS_TABLE_VALID_LOW(idx, valid) mtk_oddmr_is_table_valid(idx, valid, __func__, __LINE__, 0)
static bool mtk_oddmr_is_svp_on_mtee(void)
{
	struct device_node *dt_node;

	dt_node = of_find_node_by_name(NULL, "MTEE");
	if (!dt_node)
		return false;

	return true;
}
/*
 * @addr init data from addr if needed, set to NULL when no need
 * @secu alloc svp iommu if needed
 */
	static inline struct mtk_drm_gem_obj *
mtk_oddmr_load_buffer(struct drm_crtc *crtc,
		size_t size, void *addr, bool secu)
{
	struct mtk_drm_gem_obj *gem;

	ODDMRAPI_LOG("+\n");

	if (!size) {
		DDPMSG("%s invalid size\n",
				__func__);
		return NULL;
	}
	if (secu) {
		//mtk_svp_page-uncached,mtk_mm-uncached
		gem = mtk_drm_gem_create_from_heap(crtc->dev,
				"mtk_svp_page-uncached", size);
	} else {
		gem = mtk_drm_gem_create(
				crtc->dev, size, true);
	}

	if (!gem) {
		DDPMSG("%s gem create fail\n", __func__);
		return NULL;
	}
	DDPMSG("%s gem create %p iommu %llx size %lu\n", __func__,
		gem->kvaddr, gem->dma_addr, size);

	if ((addr != NULL) && (!secu))
		memcpy(gem->kvaddr, addr, size);

	/* if demura and dbi opened at the same time need combine */

	return gem;
}

	static inline struct mtk_drm_gem_obj *
mtk_oddmr_dbi_load_buffer(struct drm_crtc *crtc,
	size_t size, size_t copy_size, void *addr, bool secu)
{
	struct mtk_drm_gem_obj *gem;

	ODDMRAPI_LOG("+\n");

	if (!size) {
		DDPMSG("%s invalid size\n",
				__func__);
		return NULL;
	}
	if (secu) {
		//mtk_svp_page-uncached,mtk_mm-uncached
		gem = mtk_drm_gem_create_from_heap(crtc->dev,
				"mtk_svp_page-uncached", size);
	} else {
		gem = mtk_drm_gem_create(
				crtc->dev, size, true);
	}

	if (!gem) {
		DDPMSG("%s gem create fail\n", __func__);
		return NULL;
	}
	DDPMSG("%s gem create %p iommu %llx buffer size %lu, copy size %lu\n", __func__,
		gem->kvaddr, gem->dma_addr, size, copy_size);

	if ((addr != NULL) && (!secu))
		memcpy(gem->kvaddr, addr, copy_size);

	/* if demura and dbi opened at the same time need combine */

	return gem;
}

static int mtk_oddmr_create_gce_pkt(struct drm_crtc *crtc,
		struct cmdq_pkt **pkt)
{
	struct mtk_drm_crtc *mtk_crtc = to_mtk_crtc(crtc);
	int index = 0;

	if (!mtk_crtc) {
		DDPMSG("%s:%d, invalid crtc:0x%p\n",
				__func__, __LINE__, crtc);
		return -1;
	}

	index = drm_crtc_index(crtc);
	if (index) {
		DDPMSG("%s:%d, invalid crtc:0x%p, index:%d\n",
				__func__, __LINE__, crtc, index);
		return -1;
	}

	if (*pkt != NULL)
		return 0;

	if (mtk_crtc->gce_obj.client[CLIENT_PQ])
		*pkt = cmdq_pkt_create(mtk_crtc->gce_obj.client[CLIENT_PQ]);
	else
		*pkt = cmdq_pkt_create(mtk_crtc->gce_obj.client[CLIENT_CFG]);

	return 0;
}

static int mtk_oddmr_acquire_clock(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("%d+\n",
			atomic_read(&oddmr_data->oddmr_clock_ref));

	mutex_lock(&oddmr_data->primary_data->clock_lock);
	if (atomic_read(&oddmr_data->oddmr_clock_ref) == 0) {
		ODDMRFLOW_LOG("top clock is off\n");
		mutex_unlock(&oddmr_data->primary_data->clock_lock);
		return -EAGAIN;
	}
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(oddmr_data->companion);

		if (atomic_read(&oddmr1_data->oddmr_clock_ref) == 0) {
			ODDMRFLOW_LOG("top clock is off\n");
			mutex_unlock(&oddmr_data->primary_data->clock_lock);
			return -EAGAIN;
		}
		atomic_inc(&oddmr1_data->oddmr_clock_ref);
	}
	atomic_inc(&oddmr_data->oddmr_clock_ref);
	mutex_unlock(&oddmr_data->primary_data->clock_lock);
	ODDMRAPI_LOG("%d-\n",
			atomic_read(&oddmr_data->oddmr_clock_ref));
	return 0;
}

static int mtk_oddmr_release_clock(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("%d+\n",
			atomic_read(&oddmr_data->oddmr_clock_ref));

	mutex_lock(&oddmr_data->primary_data->clock_lock);
	if (atomic_read(&oddmr_data->oddmr_clock_ref) == 0) {
		ODDMRFLOW_LOG("top clock is off\n");
		mutex_unlock(&oddmr_data->primary_data->clock_lock);
		return -EAGAIN;
	}
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(oddmr_data->companion);

		if (atomic_read(&oddmr1_data->oddmr_clock_ref) == 0) {
			ODDMRFLOW_LOG("top clock is off\n");
			mutex_unlock(&oddmr_data->primary_data->clock_lock);
			return -EAGAIN;
		}
		atomic_dec(&oddmr1_data->oddmr_clock_ref);
	}
	atomic_dec(&oddmr_data->oddmr_clock_ref);
	mutex_unlock(&oddmr_data->primary_data->clock_lock);
	ODDMRAPI_LOG("%d-\n",
			atomic_read(&oddmr_data->oddmr_clock_ref));
	return 0;
}

static inline void mtk_drm_oddmr_partial_update_params_cpy(
	struct mtk_drm_oddmr_partial_update_params *dst,
	struct mtk_drm_oddmr_partial_update_params *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->slice_size)
			vfree(dst->slice_size);
		if (dst->slice_height)
			vfree(dst->slice_height);
	}

	*dst = *src;

	dst->slice_size = NULL;
	dst->slice_height = NULL;
}

static inline void mtk_drm_oddmr_partial_update_params_free(
	struct mtk_drm_oddmr_partial_update_params *data)
{
	if (!data)
		return;

	if (data->slice_size)
		vfree(data->slice_size);
	if (data->slice_height)
		vfree(data->slice_height);

	data->slice_size = NULL;
	data->slice_height = NULL;
}

static inline void mtk_drm_dmr_static_cfg_cpy(struct mtk_drm_dmr_static_cfg *dst,
	struct mtk_drm_dmr_static_cfg *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->reg_offset)
			vfree(dst->reg_offset);
		if (dst->reg_mask)
			vfree(dst->reg_mask);
		if (dst->reg_value)
			vfree(dst->reg_value);
	}

	*dst = *src;

	dst->reg_offset = NULL;
	dst->reg_mask = NULL;
	dst->reg_value = NULL;
}

static inline void mtk_drm_dmr_static_cfg_free(struct mtk_drm_dmr_static_cfg *data)
{
	if (!data)
		return;

	if (data->reg_offset)
		vfree(data->reg_offset);
	if (data->reg_mask)
		vfree(data->reg_mask);
	if (data->reg_value)
		vfree(data->reg_value);

	data->reg_offset = NULL;
	data->reg_mask = NULL;
	data->reg_value = NULL;
}

static inline void mtk_drm_oddmr_reg_tuning_cpy(struct mtk_drm_oddmr_reg_tuning *dst,
	struct mtk_drm_oddmr_reg_tuning *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->reg_addr)
			vfree(dst->reg_addr);
		if (dst->reg_mask)
			vfree(dst->reg_mask);
		if (dst->reg_value)
			vfree(dst->reg_value);
	}

	*dst = *src;

	dst->reg_addr = NULL;
	dst->reg_mask = NULL;
	dst->reg_value = NULL;
}

static inline void mtk_drm_oddmr_reg_tuning_free(struct mtk_drm_oddmr_reg_tuning *data)
{
	if (!data)
		return;

	if (data->reg_addr)
		vfree(data->reg_addr);
	if (data->reg_mask)
		vfree(data->reg_mask);
	if (data->reg_value)
		vfree(data->reg_value);

	data->reg_addr = NULL;
	data->reg_mask = NULL;
	data->reg_value = NULL;
}

static inline void mtk_drm_dmr_table_index_cpy(struct mtk_drm_dmr_table_index *dst,
	struct mtk_drm_dmr_table_index *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->DBV_table_idx)
			vfree(dst->DBV_table_idx);
		if (dst->FPS_table_idx)
			vfree(dst->FPS_table_idx);
	}

	*dst = *src;

	dst->DBV_table_idx = NULL;
	dst->FPS_table_idx = NULL;
}

static inline void mtk_drm_dmr_table_index_free(struct mtk_drm_dmr_table_index *data)
{
	if (!data)
		return;

	if (data->DBV_table_idx)
		vfree(data->DBV_table_idx);
	if (data->FPS_table_idx)
		vfree(data->FPS_table_idx);

	data->DBV_table_idx = NULL;
	data->FPS_table_idx = NULL;
}

static inline void mtk_drm_dmr_table_content_cpy(struct mtk_drm_dmr_table_content *dst,
	struct mtk_drm_dmr_table_content *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->table_single)
			vfree(dst->table_single);
		if (dst->table_single_DC)
			vfree(dst->table_single_DC);
		if (dst->table_L_single)
			vfree(dst->table_L_single);
		if (dst->table_L_single_DC)
			vfree(dst->table_L_single_DC);
		if (dst->table_R_single)
			vfree(dst->table_R_single);
		if (dst->table_R_single_DC)
			vfree(dst->table_R_single_DC);
	}

	*dst = *src;

	dst->table_single = NULL;
	dst->table_single_DC = NULL;
	dst->table_L_single = NULL;
	dst->table_L_single_DC = NULL;
	dst->table_R_single = NULL;
	dst->table_R_single_DC = NULL;
}

static inline void mtk_drm_dmr_table_content_free(struct mtk_drm_dmr_table_content *data)
{
	if (!data)
		return;

	if (data->table_single)
		vfree(data->table_single);
	if (data->table_single_DC)
		vfree(data->table_single_DC);
	if (data->table_L_single)
		vfree(data->table_L_single);
	if (data->table_L_single_DC)
		vfree(data->table_L_single_DC);
	if (data->table_R_single)
		vfree(data->table_R_single);
	if (data->table_R_single_DC)
		vfree(data->table_R_single_DC);

	data->table_single = NULL;
	data->table_single_DC = NULL;
	data->table_L_single = NULL;
	data->table_L_single_DC = NULL;
	data->table_R_single = NULL;
}

static inline void mtk_drm_dmr_fps_dbv_node_cpy(struct mtk_drm_dmr_fps_dbv_node *dst,
	struct mtk_drm_dmr_fps_dbv_node *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->DBV_node)
			vfree(dst->DBV_node);
		if (dst->FPS_node)
			vfree(dst->FPS_node);
		if (dst->remap_reduce_offset_node)
			vfree(dst->remap_reduce_offset_node);
		if (dst->remap_reduce_offset_value)
			vfree(dst->remap_reduce_offset_value);
		if (dst->remap_dbv_gain_node)
			vfree(dst->remap_dbv_gain_node);
		if (dst->remap_dbv_gain_value)
			vfree(dst->remap_dbv_gain_value);
	}

	*dst = *src;

	dst->DBV_node = NULL;
	dst->FPS_node = NULL;
	dst->remap_reduce_offset_node = NULL;
	dst->remap_reduce_offset_value = NULL;
	dst->remap_dbv_gain_node = NULL;
	dst->remap_dbv_gain_value = NULL;
}

static inline void mtk_drm_dmr_fps_dbv_node_free(struct mtk_drm_dmr_fps_dbv_node *data)
{
	if (!data)
		return;

	if (data->DBV_node)
		vfree(data->DBV_node);
	if (data->FPS_node)
		vfree(data->FPS_node);
	if (data->remap_reduce_offset_node)
		vfree(data->remap_reduce_offset_node);
	if (data->remap_reduce_offset_value)
		vfree(data->remap_reduce_offset_value);
	if (data->remap_dbv_gain_node)
		vfree(data->remap_dbv_gain_node);
	if (data->remap_dbv_gain_value)
		vfree(data->remap_dbv_gain_value);

	data->DBV_node = NULL;
	data->FPS_node = NULL;
	data->remap_reduce_offset_node = NULL;
	data->remap_reduce_offset_value = NULL;
	data->remap_dbv_gain_node = NULL;
	data->remap_dbv_gain_value = NULL;
}

static inline void mtk_drm_dmr_fps_dbv_change_cfg_cpy(struct mtk_drm_dmr_fps_dbv_change_cfg *dst,
	struct mtk_drm_dmr_fps_dbv_change_cfg *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->reg_offset)
			vfree(dst->reg_offset);
		if (dst->reg_mask)
			vfree(dst->reg_mask);
		if (dst->reg_value)
			vfree(dst->reg_value);
		if (dst->reg_DC_value)
			vfree(dst->reg_DC_value);
	}

	*dst = *src;

	dst->reg_offset = NULL;
	dst->reg_mask = NULL;
	dst->reg_value = NULL;
	dst->reg_DC_value = NULL;
}

static inline void mtk_drm_dmr_fps_dbv_change_cfg_free(struct mtk_drm_dmr_fps_dbv_change_cfg *data)
{
	if (!data)
		return;

	if (data->reg_offset)
		vfree(data->reg_offset);
	if (data->reg_mask)
		vfree(data->reg_mask);
	if (data->reg_value)
		vfree(data->reg_value);
	if (data->reg_DC_value)
		vfree(data->reg_DC_value);

	data->reg_offset = NULL;
	data->reg_mask = NULL;
	data->reg_value = NULL;
	data->reg_DC_value = NULL;
}

static inline void mtk_drm_oddmr_dbv_node_cpy(struct mtk_drm_oddmr_dbv_node *dst,
	struct mtk_drm_oddmr_dbv_node *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (dst->DBV_node && need_free)
		vfree(dst->DBV_node);

	*dst = *src;

	dst->DBV_node = NULL;
}

static inline void mtk_drm_oddmr_dbv_node_free(struct mtk_drm_oddmr_dbv_node *data)
{
	if (data)
		return;

	if (data->DBV_node)
		vfree(data->DBV_node);

	data->DBV_node = NULL;
}

static inline void mtk_drm_oddmr_dbv_chg_cfg_cpy(struct mtk_drm_oddmr_dbv_chg_cfg *dst,
	struct mtk_drm_oddmr_dbv_chg_cfg *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->reg_offset)
			vfree(dst->reg_offset);
		if (dst->reg_mask)
			vfree(dst->reg_mask);
		if (dst->reg_value)
			vfree(dst->reg_value);
	}

	*dst = *src;

	dst->reg_offset = NULL;
	dst->reg_mask = NULL;
	dst->reg_value = NULL;
}

static inline void mtk_drm_oddmr_dbv_chg_cfg_free(struct mtk_drm_oddmr_dbv_chg_cfg *data)
{
	if (!data)
		return;

	if (data->reg_offset)
		vfree(data->reg_offset);
	if (data->reg_mask)
		vfree(data->reg_mask);
	if (data->reg_value)
		vfree(data->reg_value);

	data->reg_offset = NULL;
	data->reg_mask = NULL;
	data->reg_value = NULL;
}

static inline void mtk_drm_oddmr_binset_info_cpy(struct mtk_drm_oddmr_binset_info *dst,
	struct mtk_drm_oddmr_binset_info *src, bool need_free)
{
	if (!dst || !src)
		return;

	if (need_free) {
		if (dst->dbv_interval_node)
			vfree(dst->dbv_interval_node);
		if (dst->dbv_interval_bin_idx)
			vfree(dst->dbv_interval_bin_idx);
	}

	*dst = *src;

	dst->dbv_interval_node = NULL;
	dst->dbv_interval_bin_idx = NULL;
}

static inline void mtk_drm_oddmr_binset_info_free(struct mtk_drm_oddmr_binset_info *data)
{
	if (!data)
		return;

	if (data->dbv_interval_node)
		vfree(data->dbv_interval_node);
	if (data->dbv_interval_bin_idx)
		vfree(data->dbv_interval_bin_idx);

	data->dbv_interval_node = NULL;
	data->dbv_interval_bin_idx = NULL;
}

static void mtk_drm_oddmr_binset_cfg_info_rst(struct mtk_drm_oddmr_binset_cfg_info *data)
{
	struct mtk_drm_dmr_fps_dbv_node *remap_params;
	int i;

	if (!data)
		return;

	remap_params = &data->remap_params;
	for (i = 0; i < MAX_BINSET_NUM; i++)
		mtk_drm_oddmr_binset_info_free(&data->binset_list[i]);

	mtk_drm_dmr_fps_dbv_node_free(remap_params);

	memset(data, 0, sizeof(struct mtk_drm_oddmr_binset_cfg_info));
}

static void mtk_drm_dmr_cfg_info_rst(struct mtk_drm_dmr_cfg_info *data)
{
	if (!data)
		return;

	mtk_drm_dmr_static_cfg_free(&data->static_cfg);
	mtk_drm_dmr_fps_dbv_node_free(&data->fps_dbv_node);
	mtk_drm_dmr_fps_dbv_change_cfg_free(&data->fps_dbv_change_cfg);
	mtk_drm_dmr_table_index_free(&data->table_index);
	mtk_drm_dmr_table_content_free(&data->table_content);
	mtk_drm_oddmr_partial_update_params_free(&data->dmr_pu_info);

	memset(data, 0, sizeof(struct mtk_drm_dmr_cfg_info));
}

static void mtk_drm_cus_setting_info_rst(struct mtk_drm_cus_setting_info *data)
{
	int i;

	if (!data)
		return;

	for (i = 0; i < MAX_DBV_MODE_NUM; i++) {
		mtk_drm_dmr_fps_dbv_node_free(&data->fps_dbv_node[i]);
		mtk_drm_dmr_fps_dbv_change_cfg_free(&data->fps_dbv_change_cfg[i]);
	}
	memset(data, 0, sizeof(struct mtk_drm_cus_setting_info));
}

static void mtk_oddmr_set_top_clk_force(struct mtk_ddp_comp *comp, uint32_t enable, struct cmdq_pkt *handle)
{
	uint32_t value = 0, mask = 0;

	ODDMRAPI_LOG("%d\n", enable);
	if (enable)
		SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
	else
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);
}

static void mtk_oddmr_set_od_clk(struct mtk_ddp_comp *comp, uint32_t enable, struct cmdq_pkt *handle)
{
	uint32_t value = 0, mask = 0;

	ODDMRAPI_LOG("%d\n", enable);
	if (enable) {
		value = 0x0880; mask = 0x0880;
		SET_VAL_MASK(value, mask, 1, REG_OD_CLK_EN);
	} else {
		SET_VAL_MASK(value, mask, 0, REG_OD_CLK_EN);
	}
	mtk_oddmr_write_mask(comp, value,
			DISP_ODDMR_OD_UDMA_CTR_0, mask, handle);
}

static void mtk_oddmr_set_pq(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, struct mtk_oddmr_pq_param *pq)
{
	struct mtk_oddmr_pq_pair *param;
	uint32_t cnt;
	int i;

	ODDMRAPI_LOG("+\n");
	param = pq->param;
	cnt = pq->counts;
	if (0 == cnt || NULL == param) {
		ODDMRFLOW_LOG("pq is NULL\n");
	} else {
		for (i = 0; i < cnt; i++) {
			ODDMRLOW_LOG("i %d, 0x%x 0x%x\n", i, param[i].addr, param[i].value);
			mtk_oddmr_write(comp, param[i].value, param[i].addr, pkg);
		}
	}
}

static void mtk_oddmr_set_crop(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t tile_overhead, comp_width, height;
	uint32_t reg_value, reg_mask, win_lr = 0;

	ODDMRAPI_LOG("+\n");
	reg_value = 0;
	reg_mask = 0;
	tile_overhead = oddmr_data->cfg.comp_overhead;
	comp_width = oddmr_data->cfg.comp_in_width;
	height = oddmr_data->cfg.height;
	if (oddmr_data->is_right_pipe)
		win_lr = 1;
	ODDMRAPI_LOG("comp_width %u tile_overhead %u win_lr %u+\n",
		comp_width, tile_overhead, win_lr);
	SET_VAL_MASK(reg_value, reg_mask, win_lr, REG_WINDOW_LR);
	SET_VAL_MASK(reg_value, reg_mask, tile_overhead, REG_GUARD_BAND_PIXEL);
	mtk_oddmr_write(comp, reg_value, DISP_ODDMR_CRP_CTR_2, pkg);
	//actual width
	mtk_oddmr_write(comp, comp_width - tile_overhead, DISP_ODDMR_CRP_CTR_0, pkg);
	mtk_oddmr_write(comp, height, DISP_ODDMR_CRP_CTR_1, pkg);
	mtk_oddmr_write(comp, !tile_overhead, DISP_ODDMR_TOP_CRP_BYPSS, pkg);
}

static void mtk_oddmr_set_crop_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	ODDMRAPI_LOG("+\n");
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_set_crop(comp, pkg);
		mtk_oddmr_set_crop(comp1, pkg);
	} else
		mtk_oddmr_write(comp, 1, DISP_ODDMR_TOP_CRP_BYPSS, pkg);
}

static int disp_oddmr_get_slc_uid(enum DISP_ODDMR_SLC_IDX idx)
{
	int uid = -1;

	switch (idx) {
	case DMR_SLC:
		uid = ID_DMR;
		break;
	case OD_SLC:
		uid = ID_OD;
		break;
	case DBI_SLC:
		uid = ID_DBI;
		break;
	default:
		PC_ERR("%s not support idx %d\n", __func__, idx);
	}
	return uid;
}

static int disp_oddmr_slc_request(struct mtk_ddp_comp *comp, enum DISP_ODDMR_SLC_IDX idx)
{
	struct slbc_gid_data data = {0};
	int uid, gid;
	int ret = -1;

	data.sign = SLC_DATA_MAGIC;
	uid = disp_oddmr_get_slc_uid(idx);
	if (uid < 0)
		return ret;
	if (g_slc_state[idx] == ODDMR_SLC_UNINIT) {
		gid = -1;
		ret = slbc_gid_request(uid, &gid, &data);
		if (g_slc_gid[idx] < 0)
			g_slc_gid[idx] = gid;
		if (ret)
			PC_ERR("%s request failed %d\n", __func__, ret);
		else
			g_slc_state[idx] = ODDMR_SLC_REQUESTED;
	} else {
		DDPINFO("%s already requested for %d:%d\n", __func__, idx, g_slc_gid[idx]);
		ret = 0;
	}
	return ret;
}

static int disp_oddmr_slc_valid(struct mtk_ddp_comp *comp, enum DISP_ODDMR_SLC_IDX idx)
{
	int uid;
	int ret = -1;

	uid = disp_oddmr_get_slc_uid(idx);
	if (uid < 0)
		return ret;

	if (g_slc_state[idx] == ODDMR_SLC_REQUESTED) {
		ret = slbc_validate(uid, g_slc_gid[idx]);
		if (!ret)
			g_slc_state[idx] = ODDMR_SLC_VALID;
		else
			PC_ERR("%s failed %d %d\n", __func__, idx, g_slc_gid[idx]);
	} else
		DDPINFO("%s skip %d %d %d\n", __func__, idx, g_slc_gid[idx], g_slc_state[idx]);
	return ret;
}

static int disp_oddmr_slc_invalid(struct mtk_ddp_comp *comp, enum DISP_ODDMR_SLC_IDX idx)
{
	int uid;
	int ret = -1;

	uid = disp_oddmr_get_slc_uid(idx);
	if (uid < 0)
		return ret;

	if (g_slc_gid[idx] > 0 && g_slc_state[idx] == ODDMR_SLC_VALID) {
		ret = slbc_invalidate(uid, g_slc_gid[idx]);
		if (!ret)
			g_slc_state[idx] = ODDMR_SLC_REQUESTED;
		else
			PC_ERR("%s failed %d %d\n", __func__, idx, g_slc_gid[idx]);
	} else
		PC_ERR("%s skip %d %d %d\n", __func__, idx, g_slc_gid[idx], g_slc_state[idx]);
	return ret;
}

static void mtk_oddmr_od_udma_init(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t od_mode = oddmr_data->primary_data->od_param.od_basic_info.basic_param.od_mode;

	ODDMRAPI_LOG("+\n");
	switch (od_mode) {
	case OD_MODE_TYPE_COMPRESS_18:
		break;
	case OD_MODE_TYPE_COMPRESS_12:
		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			mtk_oddmr_write(comp, 0x00000000, 0x0A3c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A00, pkg);
			mtk_oddmr_write(comp, 0x00000009, 0x0A04, pkg);
			mtk_oddmr_write(comp, 0x00007fff, 0x0A08, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x0A0c, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x0A10, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A14, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A18, pkg);
			mtk_oddmr_write(comp, 0x00000008, 0x0A1c, pkg);
			mtk_oddmr_write(comp, 0x00000010, 0x0A20, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A24, pkg);
			mtk_oddmr_write(comp, 0x00000020, 0x0A28, pkg);
			mtk_oddmr_write(comp, 0x00000001, 0x0A3c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A00, pkg);
			mtk_oddmr_write(comp, 0x00000009, 0x0A04, pkg);
			mtk_oddmr_write(comp, 0x00007fff, 0x0A08, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x0A0c, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x0A10, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A14, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A18, pkg);
			mtk_oddmr_write(comp, 0x00000008, 0x0A1c, pkg);
			mtk_oddmr_write(comp, 0x00000010, 0x0A20, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A24, pkg);
			mtk_oddmr_write(comp, 0x00000020, 0x0A28, pkg);
			mtk_oddmr_write(comp, 0x00000002, 0x0A3c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A00, pkg);
			mtk_oddmr_write(comp, 0x00000009, 0x0A04, pkg);
			mtk_oddmr_write(comp, 0x00007fff, 0x0A08, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x0A0c, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x0A10, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A14, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A18, pkg);
			mtk_oddmr_write(comp, 0x00000008, 0x0A1c, pkg);
			mtk_oddmr_write(comp, 0x00000010, 0x0A20, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0A24, pkg);
			mtk_oddmr_write(comp, 0x00000020, 0x0A28, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0800, pkg);
			mtk_oddmr_write(comp, 0x000000ff, 0x0804, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0808, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x080c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0810, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0814, pkg);
			mtk_oddmr_write(comp, 0x000000ff, 0x0818, pkg);
			mtk_oddmr_write(comp, 0x000000ff, 0x081c, pkg);
			mtk_oddmr_write(comp, 0x00000007, 0x0820, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0824, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x0828, pkg);
			mtk_oddmr_write(comp, 0x000000f8, 0x082c, pkg);
			mtk_oddmr_write(comp, 0x000000f8, 0x0830, pkg);
			mtk_oddmr_write(comp, 0x000000f8, 0x0834, pkg);
			mtk_oddmr_write(comp, 0x0000ffea, 0x0838, pkg);
		} else {
			mtk_oddmr_write(comp, 0x00000000, 0x183c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1800, pkg);
			mtk_oddmr_write(comp, 0x00000009, 0x1804, pkg);
			mtk_oddmr_write(comp, 0x00007fff, 0x1808, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x180c, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x1810, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1814, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1818, pkg);
			mtk_oddmr_write(comp, 0x00000008, 0x181c, pkg);
			mtk_oddmr_write(comp, 0x00000010, 0x1820, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1824, pkg);
			mtk_oddmr_write(comp, 0x00000020, 0x1828, pkg);
			mtk_oddmr_write(comp, 0x00000001, 0x183c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1800, pkg);
			mtk_oddmr_write(comp, 0x00000009, 0x1804, pkg);
			mtk_oddmr_write(comp, 0x00007fff, 0x1808, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x180c, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x1810, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1814, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1818, pkg);
			mtk_oddmr_write(comp, 0x00000008, 0x181c, pkg);
			mtk_oddmr_write(comp, 0x00000010, 0x1820, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1824, pkg);
			mtk_oddmr_write(comp, 0x00000020, 0x1828, pkg);
			mtk_oddmr_write(comp, 0x00000002, 0x183c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1800, pkg);
			mtk_oddmr_write(comp, 0x00000009, 0x1804, pkg);
			mtk_oddmr_write(comp, 0x00007fff, 0x1808, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x180c, pkg);
			mtk_oddmr_write(comp, 0x00008008, 0x1810, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1814, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1818, pkg);
			mtk_oddmr_write(comp, 0x00000008, 0x181c, pkg);
			mtk_oddmr_write(comp, 0x00000010, 0x1820, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1824, pkg);
			mtk_oddmr_write(comp, 0x00000020, 0x1828, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1600, pkg);
			mtk_oddmr_write(comp, 0x000000ff, 0x1604, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1608, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x160c, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1610, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1614, pkg);
			mtk_oddmr_write(comp, 0x000000ff, 0x1618, pkg);
			mtk_oddmr_write(comp, 0x000000ff, 0x161c, pkg);
			mtk_oddmr_write(comp, 0x00000007, 0x1620, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1624, pkg);
			mtk_oddmr_write(comp, 0x00000000, 0x1628, pkg);
			mtk_oddmr_write(comp, 0x000000f8, 0x162c, pkg);
			mtk_oddmr_write(comp, 0x000000f8, 0x1630, pkg);
			mtk_oddmr_write(comp, 0x000000f8, 0x1634, pkg);
			mtk_oddmr_write(comp, 0x0000ffea, 0x1638, pkg);
		}
		break;
	default:
		break;
	}

	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		mtk_oddmr_write(comp, 0xFF, MT6991_DISP_ODDMR_UDMA_W_CTR_23, pkg);
		mtk_oddmr_write(comp, 0x01, MT6991_DISP_ODDMR_UDMA_W_CTR_1D, pkg);
	} else {
		mtk_oddmr_write(comp, 0xFF, DISP_ODDMR_UDMA_W_CTR_23, pkg);
		mtk_oddmr_write(comp, 0x01, DISP_ODDMR_UDMA_W_CTR_16, pkg);
	}
}

/* top,dither,common pq, udma */
static void mtk_oddmr_od_common_init(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	uint32_t value = 0, mask = 0;

	ODDMRAPI_LOG("+\n");
	/* top */
	SET_VAL_MASK(value, mask, 0, REG_OD_EN);
	SET_VAL_MASK(value, mask, od_param->od_basic_info.basic_param.od_mode, REG_OD_MODE);
	if (oddmr_data->data->od_version >= MTK_OD_V2)
		mtk_oddmr_write(comp, value, MT6991_DISP_ODDMR_OD_CTRL_EN, pkg);
	else {
		mtk_oddmr_write(comp, value, DISP_ODDMR_OD_CTRL_EN, pkg);
		if (od_param->od_basic_info.basic_param.dither_sel == 1) {
			mtk_oddmr_write(comp, od_param->od_basic_info.basic_param.dither_ctl,
					DISP_ODDMR_DITHER_CTR_1, pkg);
			mtk_oddmr_write(comp, 0, DISP_ODDMR_DITHER_12TO11_BYPASS, pkg);
			mtk_oddmr_write(comp, 1, DISP_ODDMR_DITHER_12TO10_BYPASS, pkg);
		} else if (od_param->od_basic_info.basic_param.dither_sel == 2) {
			mtk_oddmr_write(comp, od_param->od_basic_info.basic_param.dither_ctl,
					DISP_ODDMR_DITHER_CTR_2, pkg);
			mtk_oddmr_write(comp, 1, DISP_ODDMR_DITHER_12TO11_BYPASS, pkg);
			mtk_oddmr_write(comp, 0, DISP_ODDMR_DITHER_12TO10_BYPASS, pkg);
		} else if (od_param->od_basic_info.basic_param.dither_sel == 0) {
			mtk_oddmr_write(comp, 1, DISP_ODDMR_DITHER_12TO11_BYPASS, pkg);
			mtk_oddmr_write(comp, 1, DISP_ODDMR_DITHER_12TO10_BYPASS, pkg);
		}
	}
	/* od basic pq */
	mtk_oddmr_set_pq(comp, pkg, &od_param->od_basic_info.basic_pq);
}

static void mtk_oddmr_od_hsk(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	uint32_t hsk_0, hsk_1, hsk_2, merge_lines;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	if (oddmr_data == NULL)
		return;
	merge_lines = oddmr_data->od_data.merge_lines;
	hsk_0 = DIV_ROUND_UP(oddmr_data->cfg.comp_in_width * merge_lines, 2); //2p-align/2
	if (oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {//OD_PU
		unsigned int top_overhead_v =
						(!comp->mtk_crtc->tile_overhead_v.top_overhead_v)
						? 0 : oddmr_data->tile_overhead_v.top_overhead_v;
		unsigned int bot_overhead_v =
						(!comp->mtk_crtc->tile_overhead_v.bot_overhead_v)
						? 0 : oddmr_data->tile_overhead_v.bot_overhead_v;
		ODDMRAPI_LOG("PU=1: roi_height %d, overhead_v T %d B %d\n",
					oddmr_data->roi_height,top_overhead_v, bot_overhead_v);
		hsk_1 = (oddmr_data->roi_height + top_overhead_v + bot_overhead_v)
				/ merge_lines;
	} else
		hsk_1 = oddmr_data->cfg.height / merge_lines;
	hsk_2 = 1;
	ODDMRAPI_LOG("hsk_0 %d, hsk_1 %d\n", hsk_0, hsk_1);

	mtk_oddmr_write(comp, hsk_0, DISP_ODDMR_OD_HSK_0, pkg);
	mtk_oddmr_write(comp, hsk_1, DISP_ODDMR_OD_HSK_1, pkg);
	mtk_oddmr_write(comp, hsk_2, DISP_ODDMR_OD_HSK_2, pkg);
	if (oddmr_data->data->od_version >= MTK_OD_V3) {
		mtk_oddmr_write(comp, 0xFFF, DISP_ODDMR_OD_HSK_3, pkg);
		mtk_oddmr_write(comp, 0x3, DISP_ODDMR_OD_HSK_4, pkg);
		return;
	}
	mtk_oddmr_write(comp, 0, DISP_ODDMR_OD_HSK_3, pkg);
	mtk_oddmr_write(comp, 0x8003, DISP_ODDMR_OD_HSK_4, pkg);
}

static void mtk_oddmr_od_hsk_6989(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	uint32_t comp_width, hsk_0, hsk_1, hsk_2;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	if (oddmr_data == NULL)
		return;
	//merge_lines = oddmr_data->od_data.merge_lines;
	hsk_0 = oddmr_data->cfg.comp_in_width / 2;
	hsk_1 = oddmr_data->cfg.height;

	comp_width = oddmr_data->cfg.comp_in_width;
	if(oddmr_data->data->p_num != 0)
		hsk_2 = comp_width / oddmr_data->data->p_num;
	else
		hsk_2 = comp_width / 2;

	mtk_oddmr_write(comp, hsk_0, DISP_ODDMR_OD_HSK_0, pkg);
	mtk_oddmr_write(comp, hsk_1, DISP_ODDMR_OD_HSK_1, pkg);
	mtk_oddmr_write(comp, hsk_2, DISP_ODDMR_OD_HSK_2, pkg);
	mtk_oddmr_write(comp, 1, DISP_ODDMR_OD_HSK_3, pkg);
	mtk_oddmr_write(comp, 0x8003, DISP_ODDMR_OD_HSK_4, pkg);
}

static void mtk_oddmr_od_hsk_6985(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	uint32_t hsk_0, hsk_1, hsk_2, merge_lines;

	if (oddmr_data == NULL)
		return;

	merge_lines = oddmr_data->od_data.merge_lines;
	hsk_0 = oddmr_data->cfg.comp_in_width * merge_lines;
	hsk_1 = oddmr_data->cfg.height / merge_lines;
	hsk_2 = (4368 + hsk_0) / 16;

	mtk_oddmr_write(comp, hsk_0, DISP_ODDMR_OD_HSK_0, pkg);
	mtk_oddmr_write(comp, hsk_1, DISP_ODDMR_OD_HSK_1, pkg);
	mtk_oddmr_write(comp, hsk_2,
			DISP_ODDMR_OD_HSK_2, pkg);
	mtk_oddmr_write(comp, 0xFFF,
			DISP_ODDMR_OD_HSK_3, pkg);
	mtk_oddmr_write(comp, od_param->od_basic_info.basic_param.od_hsk_4,
			DISP_ODDMR_OD_HSK_4, pkg);
}

static void mtk_oddmr_od_set_res_udma(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	uint32_t scaling_mode, hsize_scale, od_mode, dummy_1, hsize_align, hscaling;
	uint32_t comp_width, width, height, line_offset = 0, hsize = 0, vsize = 0, merge_lines;
	uint32_t reg_value = 0, reg_mask = 0, is_hscaling, is_vscaling, is_h_2x4x_sel;

	ODDMRAPI_LOG("+\n");
	scaling_mode = od_param->od_basic_info.basic_param.scaling_mode;
	od_mode = od_param->od_basic_info.basic_param.od_mode;
	is_hscaling = (scaling_mode & BIT(0)) > 0 ? 1 : 0;
	is_vscaling = (scaling_mode & BIT(1)) > 0 ? 1 : 0;
	is_h_2x4x_sel = (scaling_mode & BIT(2)) > 0 ? 1 : 0;
	comp_width = oddmr_data->cfg.comp_in_width;
	width = oddmr_data->cfg.width;
	height = oddmr_data->cfg.height;
	mtk_oddmr_od_get_dram_size(comp, comp_width, height, scaling_mode, od_mode, 0, 1);
	line_offset = oddmr_data->od_data.ln_offset;
	merge_lines = oddmr_data->od_data.merge_lines;
	if (priv->data->mmsys_id == MMSYS_MT6989) {
		hsize = comp_width;
		vsize = height;
		line_offset = line_offset > hsize ? line_offset:hsize;
		ODDMRAPI_LOG("line_offset %u, hsize %u\n", line_offset, hsize);

		hscaling = is_hscaling ? (is_h_2x4x_sel ? 4 : 2) : 1;
		hsize_align = is_hscaling ?
			(is_h_2x4x_sel ?
			DIV_ROUND_UP(comp_width, 8) * 8 : DIV_ROUND_UP(comp_width, 4) * 4)
			: comp_width;
		hsize_scale = hsize_align / hscaling;
		dummy_1 = hsize_scale * merge_lines;
		ODDMRAPI_LOG("hscaling %u, hsize_align %u, hsize_scale %u\n",
			hscaling, hsize_align, hsize_scale);
		line_offset = line_offset > dummy_1 ? line_offset : dummy_1;
		ODDMRAPI_LOG("line_offset %u, dummy_1 %u\n", line_offset, dummy_1);
	} else {
		hsize = comp_width * merge_lines;
		vsize = height / merge_lines;
	}
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		mtk_oddmr_write(comp, 0, MT6991_DISP_ODDMR_OD_UMDA_CTRL_0, pkg);
		mtk_oddmr_write(comp, line_offset, MT6991_DISP_ODDMR_OD_UMDA_CTRL_1, pkg);
		mtk_oddmr_write(comp, hsize, MT6991_DISP_ODDMR_OD_UMDA_CTRL_2, pkg);
		if (oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {//OD_PU
			unsigned int top_overhead_v =
						(!comp->mtk_crtc->tile_overhead_v.top_overhead_v)
						? 0 : oddmr_data->tile_overhead_v.top_overhead_v;
			unsigned int bot_overhead_v =
						(!comp->mtk_crtc->tile_overhead_v.bot_overhead_v)
						? 0 : oddmr_data->tile_overhead_v.bot_overhead_v;
			ODDMRAPI_LOG("PU=1: roi_height %d, overhead_v T %d B %d\n",
					oddmr_data->roi_height, top_overhead_v, bot_overhead_v);
			vsize = (oddmr_data->roi_height + top_overhead_v + bot_overhead_v)
					/ merge_lines;
		}
		mtk_oddmr_write(comp, vsize, MT6991_DISP_ODDMR_OD_UMDA_CTRL_3, pkg);
	} else {
		mtk_oddmr_write(comp, 0, DISP_ODDMR_OD_UMDA_CTRL_0, pkg);
		mtk_oddmr_write(comp, line_offset, DISP_ODDMR_OD_UMDA_CTRL_1, pkg);
		mtk_oddmr_write(comp, hsize, DISP_ODDMR_OD_UMDA_CTRL_2, pkg);
		mtk_oddmr_write(comp, vsize, DISP_ODDMR_OD_UMDA_CTRL_3, pkg);
	}
	SET_VAL_MASK(reg_value, reg_mask, is_hscaling, REG_ENABLE_HSCALING);
	SET_VAL_MASK(reg_value, reg_mask, is_vscaling, REG_ENABLE_VSCALING);
	SET_VAL_MASK(reg_value, reg_mask, 1, REG_DE_ALIGN8_EN);
	SET_VAL_MASK(reg_value, reg_mask, is_h_2x4x_sel, REG_HSD_2X4X_SEL);
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		if (oddmr_data->od_data.spr_rgbg_mode == 1 &&
			(oddmr_data->spr_enable == 1 && oddmr_data->spr_relay == 0 &&
				(oddmr_data->spr_format == MTK_PANEL_RGBG_BGRG_TYPE ||
				oddmr_data->spr_format == MTK_PANEL_BGRG_RGBG_TYPE)))
			SET_VAL_MASK(reg_value, reg_mask, 1, MT6991_REG_SPR_RGBG_MODE);
		else
			SET_VAL_MASK(reg_value, reg_mask, 0, MT6991_REG_SPR_RGBG_MODE);
		mtk_oddmr_write_mask(comp, reg_value, MT6991_DISP_ODDMR_OD_SCALING_6, reg_mask, pkg);
	} else
		mtk_oddmr_write_mask(comp, reg_value, DISP_ODDMR_OD_SCALING_6, reg_mask, pkg);
	ODDMRAPI_LOG("w %u, h %u, comp_w %u ln_h_v %u, %u, %u, spr_format %d, OD_SCALING_6 0x%x\n",
		width, height, comp_width, line_offset, hsize, vsize, oddmr_data->spr_format, reg_value);
}

static void mtk_oddmr_od_init_end(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	struct mtk_drm_private *priv = mtk_crtc->base.dev->dev_private;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->data->od_version >= MTK_OD_V2 && oddmr_data->od_enable == 0) {
		ODDMRAPI_LOG("od_en %d\n",oddmr_data->od_enable);
		return;
	}
	//od reset
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		mtk_oddmr_set_top_clk_force(comp, 1, handle); //needed by writing sram and udma init
		mtk_oddmr_set_od_clk(comp, 1, handle);
		mtk_oddmr_write(comp, 0x200, MT6991_DISP_ODDMR_OD_SW_RESET, handle);
		mtk_oddmr_write(comp, 0, MT6991_DISP_ODDMR_OD_SW_RESET, handle);
	} else {
		mtk_oddmr_write(comp, 0x200, DISP_ODDMR_OD_SW_RESET, handle);
		mtk_oddmr_write(comp, 0, DISP_ODDMR_OD_SW_RESET, handle);
	}
	mtk_oddmr_od_udma_init(comp, handle);
	if (mtk_drm_helper_get_opt(priv->helper_opt,
		MTK_DRM_OPT_ODDMR_OD_AEE)) {
		/* better hw aee check method in future */
		mtk_oddmr_write_mask(comp, ODDMR_IRQ_MASK_VAL,
			DISP_ODDMR_IRQ_MASK, ODDMR_IRQ_MASK_VAL, handle);
		if (oddmr_data->data->od_version >= MTK_OD_V2)
			mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_UDMA_R_CTRL88, handle);
		else
			mtk_oddmr_write(comp, 1, DISP_ODDMR_UDMA_R_CTRL88, handle);
	}
	//force clk off
	if (oddmr_data->data->od_version >= MTK_OD_V2)
		mtk_oddmr_od_hsk(comp, handle);
	else if (priv->data->mmsys_id == MMSYS_MT6985)
		mtk_oddmr_od_hsk_6985(comp, handle);
	else {
		mtk_oddmr_od_hsk_6989(comp, handle);
		mtk_oddmr_od_dummy(comp, handle);
	}

	//bypass off
	mtk_oddmr_write(comp, 0,
			DISP_ODDMR_TOP_OD_BYASS, handle);
	if (oddmr_data->data->od_version < MTK_OD_V2)
		mtk_oddmr_write(comp, 1,
				DISP_ODDMR_TOP_HRT0_BYPASS, handle);

	if (oddmr_data->data->od_version == MTK_OD_V2 && oddmr_data->od_update_sram == 0 &&
			!oddmr_data->dmr_enable)
		mtk_oddmr_set_top_clk_force(comp, 0, handle); //no need to update sram table, top_clk can be closed

}

static void mtk_oddmr_fill_cfg(struct mtk_ddp_comp *comp, struct mtk_ddp_config *cfg)
{
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	oddmr_data->cfg.width = cfg->w;
	oddmr_data->cfg.height = cfg->h;

	if (!cfg->tile_overhead.is_support) {
		if (mtk_crtc->is_dual_pipe) {
			oddmr_data->cfg.comp_in_width = cfg->w / 2;
			oddmr_data->cfg.comp_overhead = 0;
			oddmr_data->cfg.total_overhead = 0;
		} else {
			oddmr_data->cfg.comp_in_width = cfg->w;
			oddmr_data->cfg.comp_overhead = 0;
			oddmr_data->cfg.total_overhead = 0;
		}
	}
}
static bool mtk_oddmr_drm_mode_to_oddmr_timg(struct drm_display_mode *mode,
		struct mtk_oddmr_timing *oddmr_mode)
{
	bool ret = false;

	ODDMRAPI_LOG("+\n");
	if ((mode != NULL) && (oddmr_mode != NULL)) {
		oddmr_mode->hdisplay = mode->hdisplay;
		oddmr_mode->vdisplay = mode->vdisplay;
		oddmr_mode->vrefresh = drm_mode_vrefresh(mode);
		ret = true;
	} else
		ret =  false;
	return ret;
}

static void mtk_oddmr_copy_oddmr_timg(struct mtk_oddmr_timing *dst,
		struct mtk_oddmr_timing *src)
{
	ODDMRAPI_LOG("+\n");
	dst->hdisplay = src->hdisplay;
	dst->vdisplay = src->vdisplay;
	dst->vrefresh = src->vrefresh;
	dst->mode_chg_index = src->mode_chg_index;
	dst->bl_level = src->bl_level;
}

static bool mtk_oddmr_match_panelid(struct mtk_oddmr_panelid *read,
		struct mtk_oddmr_panelid *expected)
{
	int i;
	bool flag = true;

	ODDMRAPI_LOG("+\n");
	/* always return true if panelid in bin is zero*/
	if (expected->len == 0)
		return true;
	if (expected->len > 16)
		expected->len = 16;

	for (i = 0; i < expected->len; i++) {
		if (expected->data[i] != 0) {
			flag = false;
			break;
		}
	}
	if (flag == true)
		return flag;
	/* compare */
	flag = true;
	if (read->len > 16)
		read->len = 16;

	for (i = 0; i < read->len; i++) {
		if (expected->data[i] != read->data[i]) {
			flag = false;
			PC_ERR("%s, idx %d, expected %u but %u\n",
					__func__, i, expected->data[i], read->data[i]);
			break;
		}
	}
	return flag;
}

/* return 100 x byte per pixel */
static int mtk_oddmr_dbi_bpp(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int ret = 0;
	unsigned long  table_size = oddmr_data->dbi_data.table_size;
	unsigned long  layer_size;
	struct mtk_drm_dbi_cfg_info *dbi_cfg_info = &oddmr_data->primary_data->dbi_cfg_info;

	if(dbi_cfg_info){
		layer_size = dbi_cfg_info->basic_info.panel_width
			* dbi_cfg_info->basic_info.panel_height * 4;
		ret = (400 * table_size + layer_size -1)/layer_size;
		ODDMRFLOW_LOG("dbi hrt %d\n", ret);
	}
	return ret;

}

/* return 100 x byte per pixel */
static int mtk_oddmr_dmr_bpp(struct mtk_ddp_comp *comp, bool max)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int ret = 0;
	unsigned long table_size = 0, layer_size = 1;
	struct mtk_drm_dmr_cfg_info *dmr_cfg_info;
	int cur_bin_idx;

	if (max) {
		table_size = oddmr_data->dmr_data.max_table_size + DMR_LN_OFFSET;
		dmr_cfg_info = &oddmr_data->primary_data->dmr_multi_bin[0];
		layer_size = dmr_cfg_info->basic_info.panel_width
			* dmr_cfg_info->basic_info.panel_height * 4;
	} else {
		cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
		DDPINFO("cur_bin_idx %d\n", cur_bin_idx);
		if (cur_bin_idx == -1)
			return 0;
		if (cur_bin_idx < 0 || cur_bin_idx >= MAX_BIN_NUM) {
			PC_ERR("%s cur_bin_idx %d is out of range (0, %d)\n",
				__func__, cur_bin_idx, MAX_BIN_NUM);
			return 0;
		}
		dmr_cfg_info = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
		table_size = dmr_cfg_info->table_index.table_byte_num + DMR_LN_OFFSET;
		layer_size = dmr_cfg_info->basic_info.panel_width
			* dmr_cfg_info->basic_info.panel_height * 4;
	}
	ret = (400 * table_size + layer_size - 1) / layer_size;
	DDPINFO("dmr hrt %d\n", ret);

	return ret;
}

/* return hscaling and vscaling */
static void mtk_oddmr_od_get_scaling(uint32_t scaling_mode, uint32_t *hscaling, uint32_t *vscaling)
{
	uint32_t h_2x4x_sel;

	ODDMRAPI_LOG("+\n");
	*hscaling = (scaling_mode & BIT(0)) > 0 ? 2 : 1;
	*vscaling = (scaling_mode & BIT(1)) > 0 ? 2 : 1;
	h_2x4x_sel = (scaling_mode & BIT(2)) > 0 ? 2 : 1;
	*hscaling = (*hscaling) * h_2x4x_sel;
	ODDMRAPI_LOG("od_bpp_h, od_bpp_v, od_bpp_2x4x, %d, %d, %d\n", *hscaling, *vscaling, h_2x4x_sel);
}


/* return 100 x byte per pixel */
static int mtk_oddmr_od_bpp(struct mtk_ddp_comp *comp, int mode)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int bits, ret = 100;
	uint32_t scaling_mode = oddmr_data->primary_data->od_param.od_basic_info.basic_param.scaling_mode;
	uint32_t hscaling, vscaling;

	ODDMRAPI_LOG("+\n");
	mtk_oddmr_od_get_scaling(scaling_mode, &hscaling, &vscaling);
	switch (mode) {
	case OD_MODE_TYPE_RGB444:
	case OD_MODE_TYPE_COMPRESS_12:
		bits = 12;
		break;
	case OD_MODE_TYPE_RGB565:
		bits = 16;
		break;
	case OD_MODE_TYPE_COMPRESS_18:
		bits = 18;
		break;
	case OD_MODE_TYPE_RGB555:
		bits = 15;
		break;
	case OD_MODE_TYPE_RGB888:
		bits = 24;
		break;
	default:
		bits = 24;
		break;
	}
	/* double for R & W */
	ret = 2 * ret;
	ret = ret * bits / ((int)hscaling * (int)vscaling * 8);
	ODDMRAPI_LOG("od hrt %d\n", ret);
	return ret;
}

/* MT6991 return 100 x byte per pixel */
static int mtk_oddmr_od_bpp_v(struct mtk_ddp_comp *comp, int mode)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int bits, ret = 100;
	uint32_t scaling_mode = oddmr_data->primary_data->od_param.od_basic_info.basic_param.scaling_mode;
	uint32_t hscaling, vscaling;

	ODDMRAPI_LOG("+\n");
	mtk_oddmr_od_get_scaling(scaling_mode, &hscaling, &vscaling);
	if (oddmr_data->od_data.spr_rgbg_mode == 1 &&
		(oddmr_data->spr_enable == 1 && oddmr_data->spr_relay == 0 &&
		(oddmr_data->spr_format == MTK_PANEL_RGBG_BGRG_TYPE ||
		oddmr_data->spr_format == MTK_PANEL_BGRG_RGBG_TYPE))) {
		switch (mode) {
		case OD_MODE_TYPE_RGB444:
		case OD_MODE_TYPE_COMPRESS_12:
			bits = 8;
			break;
		case OD_MODE_TYPE_RGB565:
			bits = 12;
			break;
		case OD_MODE_TYPE_COMPRESS_18:
			bits = 12;
			break;
		case OD_MODE_TYPE_RGB555:
			bits = 10;
			break;
		case OD_MODE_TYPE_RGB888:
			bits = 16;
			break;
		default:
			bits = 16;
			break;
		}
	} else {
		switch (mode) {
		case OD_MODE_TYPE_RGB444:
		case OD_MODE_TYPE_COMPRESS_12:
			bits = 12;
			break;
		case OD_MODE_TYPE_RGB565:
			bits = 16;
			break;
		case OD_MODE_TYPE_COMPRESS_18:
			bits = 18;
			break;
		case OD_MODE_TYPE_RGB555:
			bits = 15;
			break;
		case OD_MODE_TYPE_RGB888:
			bits = 24;
			break;
		default:
			bits = 24;
			break;
		}
	}
	oddmr_data->od_data.bpp = bits;
	ODDMRAPI_LOG("od_data.bpp= %d, mode= %d, spr_enable = %d, spr_relay =%d, spr_format= %d\n",
			oddmr_data->od_data.bpp, mode, oddmr_data->spr_enable,
			oddmr_data->spr_relay, oddmr_data->spr_format);
	/* double for R & W */
	ret = 2 * ret;
	ret = ret * bits / ((int)hscaling * (int)vscaling * 8);
	ODDMRAPI_LOG("od hrt %d\n", ret);
	return ret;
}

static void mtk_oddmr_od_srt_cal(struct mtk_ddp_comp *comp, int en)
{
	struct mtk_disp_oddmr *oddmr_data;
	struct mtk_oddmr_od_param *od_param;
	uint32_t srt = 0, scaling_mode, od_mode, vrefresh;

	ODDMRAPI_LOG("+\n");
	if (comp == NULL)
		return;
	oddmr_data = comp_to_oddmr(comp);
	od_param = &oddmr_data->primary_data->od_param;
	if (en) {
		scaling_mode = od_param->od_basic_info.basic_param.scaling_mode;
		od_mode = od_param->od_basic_info.basic_param.od_mode;
		srt += mtk_oddmr_od_get_data_size(comp, oddmr_data->cfg.comp_in_width,
			oddmr_data->cfg.height, scaling_mode, od_mode, 0);
		if (oddmr_data->data->od_version < MTK_OD_V2) {
			srt += mtk_oddmr_od_get_data_size(comp, oddmr_data->cfg.comp_in_width,
				oddmr_data->cfg.height, scaling_mode, od_mode, 1);
			srt += mtk_oddmr_od_get_data_size(comp, oddmr_data->cfg.comp_in_width,
				oddmr_data->cfg.height, scaling_mode, od_mode, 2);
		}
		vrefresh = oddmr_data->primary_data->current_timing.vrefresh;
		//blanking ratio
		srt = DO_COMMON_DIV(srt, 1000);
		srt *= 125;
		srt = DO_COMMON_DIV(srt, 100);
		srt = srt * vrefresh;
		srt = DO_COMMON_DIV(srt, 1000);
		oddmr_data->qos_srt_odr = srt;
		oddmr_data->qos_srt_odw = srt;
	} else {
		oddmr_data->qos_srt_odr = 0;
		oddmr_data->qos_srt_odw = 0;
	}
	ODDMRAPI_LOG("srt %u -\n", srt);
}

static void mtk_oddmr_dbi_srt_cal(struct mtk_ddp_comp *comp, int en)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int table_size = oddmr_data->dbi_data.table_size;
	uint32_t vrefresh;
	uint32_t srt = 0;

	if (en) {
		srt = table_size;
		vrefresh = oddmr_data->primary_data->current_timing.vrefresh;
		//blanking ratio
		srt = DO_COMMON_DIV(srt, 1000);
		srt *= 125;
		srt = DO_COMMON_DIV(srt, 100);
		srt = srt * vrefresh;
		srt = DO_COMMON_DIV(srt, 1000);

		if (srt < oddmr_data->last_cal_srt_dbi)
			oddmr_data->srt_delay_dbi = 0;

		if ((srt < oddmr_data->qos_srt_dbir) && (oddmr_data->srt_delay_dbi < 5)) {
			oddmr_data->srt_delay_dbi++;
		} else {
			oddmr_data->srt_delay_dbi = 0;
			oddmr_data->qos_srt_dbir = srt;
		}
		oddmr_data->last_cal_srt_dbi = srt;
	} else {
		oddmr_data->qos_srt_dbir = 0;
	}
	ODDMRAPI_LOG("cal srt %d/%d\n", oddmr_data->qos_srt_dbir,oddmr_data->last_qos_srt_dbir);
}


static void mtk_oddmr_dmr_srt_cal(struct mtk_ddp_comp *comp, int en)
{
	struct mtk_disp_oddmr *oddmr_data;
	struct mtk_drm_crtc *mtk_crtc;
	unsigned int table_size;
	uint32_t vrefresh;
	uint32_t srt = 0;
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data;
	int cur_bin_idx;

	if (comp == NULL)
		return;
	oddmr_data = comp_to_oddmr(comp);
	mtk_crtc = comp->mtk_crtc;
	cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
	if (en) {
		dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
		table_size = dmr_cfg_data->table_index.table_byte_num + DMR_LN_OFFSET;
		srt = table_size;
		vrefresh = oddmr_data->primary_data->current_timing.vrefresh;
		//blanking ratio
		srt = DO_COMMON_DIV(srt, 1000);
		srt *= 125;
		srt = DO_COMMON_DIV(srt, 100);
		srt = srt * vrefresh;
		srt = DO_COMMON_DIV(srt, 1000);
		oddmr_data->qos_srt_dmrr = srt;
	} else {
		oddmr_data->qos_srt_dmrr = 0;
	}
	DDPINFO("cal srt %d/%d en=%d\n", oddmr_data->qos_srt_dmrr,oddmr_data->last_qos_srt_dmrr, en);
}

static void mtk_oddmr_set_spr2rgb(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	uint32_t mask_2x2 = 0, spr_mask[6] = {0}, x_init = 0, spr_format = 0;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool is_right_pipe = false;
	uint32_t overhead, comp_width, width;
	uint32_t value = 0, mask = 0;
	bool dmr_support, od_support, dbi_support;

	if (oddmr_data->spr_enable == 0 || oddmr_data->spr_relay == 1)
		return;
	ODDMRAPI_LOG("+\n");
	is_right_pipe = oddmr_data->is_right_pipe;
	spr_format = oddmr_data->spr_format;
	overhead = oddmr_data->cfg.comp_overhead;
	comp_width = oddmr_data->cfg.comp_in_width;
	width = oddmr_data->cfg.width;
	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;
	switch (spr_format) {
	case MTK_PANEL_RGBG_BGRG_TYPE:
		mask_2x2 = 1;
		spr_mask[0] = 1;
		spr_mask[1] = 3;
		spr_mask[2] = 3;
		spr_mask[3] = 1;
		spr_mask[4] = 0;
		spr_mask[5] = 0;
		break;
	case MTK_PANEL_BGRG_RGBG_TYPE:
		mask_2x2 = 1;
		spr_mask[0] = 3;
		spr_mask[1] = 1;
		spr_mask[2] = 1;
		spr_mask[3] = 3;
		spr_mask[4] = 0;
		spr_mask[5] = 0;
		break;
	case MTK_PANEL_RGBRGB_BGRBGR_TYPE:
		mask_2x2 = 0;
		spr_mask[0] = 1;
		spr_mask[1] = 2;
		spr_mask[2] = 3;
		spr_mask[3] = 3;
		spr_mask[4] = 2;
		spr_mask[5] = 1;
		break;
	case MTK_PANEL_BGRBGR_RGBRGB_TYPE:
		mask_2x2 = 0;
		spr_mask[0] = 3;
		spr_mask[1] = 2;
		spr_mask[2] = 1;
		spr_mask[3] = 1;
		spr_mask[4] = 2;
		spr_mask[5] = 3;
		break;
	case MTK_PANEL_RGBRGB_BRGBRG_TYPE:
		mask_2x2 = 0;
		spr_mask[0] = 1;
		spr_mask[1] = 2;
		spr_mask[2] = 3;
		spr_mask[3] = 2;
		spr_mask[4] = 3;
		spr_mask[5] = 1;
		break;
	case MTK_PANEL_BRGBRG_RGBRGB_TYPE:
		mask_2x2 = 0;
		spr_mask[0] = 2;
		spr_mask[1] = 3;
		spr_mask[2] = 1;
		spr_mask[3] = 1;
		spr_mask[4] = 2;
		spr_mask[5] = 3;
		break;
	default:
		break;
	}

	if (oddmr_data->data->dbi_version >= MTK_DBI_V2 || oddmr_data->data->od_version >= MTK_OD_V2 ||
		oddmr_data->data->dmr_version == MTK_DMR_V1) {
		mtk_oddmr_write(comp, mask_2x2, MT6991_DISP_ODDMR_REG_SPR_MASK_2X2, pkg);
		mtk_oddmr_write(comp, spr_mask[0], MT6991_DISP_ODDMR_REG_SPR_MASK_0, pkg);
		mtk_oddmr_write(comp, spr_mask[1], MT6991_DISP_ODDMR_REG_SPR_MASK_1, pkg);
		mtk_oddmr_write(comp, spr_mask[2], MT6991_DISP_ODDMR_REG_SPR_MASK_2, pkg);
		mtk_oddmr_write(comp, spr_mask[3], MT6991_DISP_ODDMR_REG_SPR_MASK_3, pkg);
		mtk_oddmr_write(comp, spr_mask[4], MT6991_DISP_ODDMR_REG_SPR_MASK_4, pkg);
		mtk_oddmr_write(comp, spr_mask[5], MT6991_DISP_ODDMR_REG_SPR_MASK_5, pkg);
		if (width % 2 == 1)
			width += 1;
		if (is_right_pipe) {
			//start idx of right pipe
			x_init = width - comp_width;
			x_init = mask_2x2 ? x_init % 2 : x_init % 3;
		}
		mtk_oddmr_write(comp, x_init, MT6991_DISP_ODDMR_REG_SPR_X_INIT, pkg);
		if (comp->mtk_crtc->is_dual_pipe)
			mtk_oddmr_write(comp, comp_width, MT6991_DISP_ODDMR_REG_SPR_PANEL_WIDTH, pkg);
		else
			mtk_oddmr_write(comp, width, MT6991_DISP_ODDMR_REG_SPR_PANEL_WIDTH, pkg);
		mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_REG_SPR_COMP_EN, pkg);
		if (dbi_support || dmr_support || od_support) {
			SET_VAL_MASK(value, mask, 0, MT6991_REG_SPR2RGB_BYPASS);
			if (od_support)
				SET_VAL_MASK(value, mask, 0, MT6991_REG_OD_SPR2RGB_BYPASS);
			mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS,
				mask, pkg);
		}
		return;
	}

	mtk_oddmr_write(comp, mask_2x2, DISP_ODDMR_REG_SPR_MASK_2X2, pkg);
	mtk_oddmr_write(comp, spr_mask[0], DISP_ODDMR_REG_SPR_MASK_0, pkg);
	mtk_oddmr_write(comp, spr_mask[1], DISP_ODDMR_REG_SPR_MASK_1, pkg);
	mtk_oddmr_write(comp, spr_mask[2], DISP_ODDMR_REG_SPR_MASK_2, pkg);
	mtk_oddmr_write(comp, spr_mask[3], DISP_ODDMR_REG_SPR_MASK_3, pkg);
	mtk_oddmr_write(comp, spr_mask[4], DISP_ODDMR_REG_SPR_MASK_4, pkg);
	mtk_oddmr_write(comp, spr_mask[5], DISP_ODDMR_REG_SPR_MASK_5, pkg);
	if (is_right_pipe) {
		//start idx of right pipe
		x_init = width - comp_width;
		x_init = mask_2x2 ? x_init % 2 : x_init % 3;
	}
	mtk_oddmr_write(comp, x_init, DISP_ODDMR_REG_SPR_X_INIT, pkg);
	if (comp->mtk_crtc->is_dual_pipe)
		mtk_oddmr_write(comp, comp_width, DISP_ODDMR_REG_SPR_PANEL_WIDTH, pkg);
	else
		mtk_oddmr_write(comp, width, DISP_ODDMR_REG_SPR_PANEL_WIDTH, pkg);
	mtk_oddmr_write(comp, 1, DISP_ODDMR_REG_SPR_COMP_EN, pkg);
	mtk_oddmr_write(comp, 0, DISP_ODDMR_TOP_S2R_BYPASS, pkg);
}

static void mtk_oddmr_set_spr2rgb_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->spr_enable == 0 || oddmr_data->spr_relay == 1)
		return;
	mtk_oddmr_set_spr2rgb(comp, pkg);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_set_spr2rgb(comp1, pkg);
	}
}

static void mtk_oddmr_start(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	ODDMRLOW_LOG("%s oddmr_start\n", mtk_dump_comp_str(comp));
}

static void mtk_oddmr_stop(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRFLOW_LOG("%s oddmr_stop\n", mtk_dump_comp_str(comp));
	oddmr_data->qos_srt_dmrr = 0;
	oddmr_data->qos_srt_dbir = 0;
	oddmr_data->qos_srt_odr = 0;
	oddmr_data->qos_srt_odw = 0;
}

static void mtk_oddmr_od_prepare(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRFLOW_LOG("%s+\n", mtk_dump_comp_str(comp));
	if (oddmr_data->data->is_od_need_force_clk)
		mtk_oddmr_od_hsk_force_clk(comp, NULL);
	if (oddmr_data->data->is_od_need_crop_garbage == true) {
		mtk_oddmr_write_cpu(comp, 0, DISP_ODDMR_CRP_CTR_0);
		mtk_oddmr_write_cpu(comp, 0, DISP_ODDMR_CRP_CTR_1);
		mtk_oddmr_write_cpu(comp, 0, DISP_ODDMR_TOP_CRP_BYPSS);
		udelay(1);
	}
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		mtk_oddmr_set_od_clk(comp, 0, NULL);
	} else {
		mtk_oddmr_set_od_clk(comp, 1, NULL);
		//crop off, add for first boot
		if (comp->mtk_crtc->is_dual_pipe)
			mtk_oddmr_set_crop(comp, NULL);
		else
			mtk_oddmr_write(comp, 1, DISP_ODDMR_TOP_CRP_BYPSS, NULL);
	}
}

static void mtk_oddmr_top_prepare(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t value = 0, mask = 0;
	bool od_support = oddmr_data->primary_data->od_support;

	ODDMRAPI_LOG("+\n");

	if (oddmr_data->data->dbi_version == MTK_DBI_V3 ||
		oddmr_data->data->od_version == MTK_OD_V3) {
		mtk_oddmr_write(comp, 32, MT6991_DISP_ODDMR_TOP_CTR_1, handle);
		mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_TOP_CTR_2, handle);
		if (od_support == true && oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE)
			SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
		else
			SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_BYPASS);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);
		return;
	}

	if (oddmr_data->data->dbi_version == MTK_DBI_V2 ||
		oddmr_data->data->dmr_version == MTK_DMR_V1 ||
		oddmr_data->data->od_version == MTK_OD_V2) {
		mtk_oddmr_write(comp, 32, MT6991_DISP_ODDMR_TOP_CTR_1, handle);
		mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_TOP_CTR_2, handle);
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
		if (oddmr_data->data->need_bypass_shadow == true) {
			SET_VAL_MASK(value, mask, 1, MT6991_REG_BYPASS_SHADOW);
			mtk_oddmr_write(comp, 3,
				MT6991_DISP_ODDMR_DBI_SHADOW_CTRL, handle);
			mtk_oddmr_write(comp, 3,
				MT6991_DISP_ODDMR_DMR_SHADOW_CTRL, handle);
			mtk_oddmr_write(comp, 1,
				MT6991_DISP_ODDMR_MURA_SHADOW_CTRL, handle);
			mtk_oddmr_write(comp, 3,
				MT6991_DISP_ODDMR_SPR_SHADOW_CTRL, handle);
		} else {
			SET_VAL_MASK(value, mask, 0, MT6991_REG_BYPASS_SHADOW);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_DBI_SHADOW_CTRL, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_DMR_SHADOW_CTRL, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_MURA_SHADOW_CTRL, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_SPR_SHADOW_CTRL, handle);
		}
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_BYPASS);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);

		/* ODDMR input&output enable */
		value = 0;
		mask = 0;
		SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_OUTP_EN);
		SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_INP_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_EN, mask, handle);

		/* ODDMR input&output size */
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_WIDTH, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
		mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DMR_CLK_EN, handle);
		return;
	}

	SET_VAL_MASK(value, mask, 1, REG_ODDMR_TOP_CLK_FORCE_EN);
	SET_VAL_MASK(value, mask, 1, REG_FORCE_COMMIT);
	if (oddmr_data->data->need_bypass_shadow == true)
		SET_VAL_MASK(value, mask, 1, REG_BYPASS_SHADOW);
	else
		SET_VAL_MASK(value, mask, 0, REG_BYPASS_SHADOW);
	mtk_oddmr_write_mask(comp, value,
			DISP_ODDMR_TOP_CTR_3, mask, handle);

}

static void mtk_oddmr_relay(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t value = 0, mask = 0;

	ODDMRAPI_LOG("+\n");

	if (oddmr_data->data->dbi_version == MTK_DBI_V3 || oddmr_data->data->od_version >= MTK_OD_V3) {
		mtk_oddmr_write(comp, 32, MT6991_DISP_ODDMR_TOP_CTR_1, handle);
		mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_TOP_CTR_2, handle);
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_BYPASS);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);
		return;
	}

	if (oddmr_data->data->dbi_version == MTK_DBI_V2 ||
		oddmr_data->data->dmr_version == MTK_DMR_V1 ||
		oddmr_data->data->od_version == MTK_OD_V2) {
		mtk_oddmr_write(comp, 32, MT6991_DISP_ODDMR_TOP_CTR_1, handle);
		mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_TOP_CTR_2, handle);

		/* ODDMR relay */
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
		if (oddmr_data->data->need_bypass_shadow == true)
			SET_VAL_MASK(value, mask, 1, MT6991_REG_BYPASS_SHADOW);
		else
			SET_VAL_MASK(value, mask, 0, MT6991_REG_BYPASS_SHADOW);
		SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_BYPASS);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);

		/* DMR&DBI clock off*/
		mtk_oddmr_write(comp, 0,
			MT6991_DISP_ODDMR_REG_DMR_CLK_EN, handle);

		/* ODDMR input&output enable */
		value = 0;
		mask = 0;
		SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_OUTP_EN);
		SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_INP_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_EN, mask, handle);

		/* ODDMR input&output size */
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_WIDTH, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
	}
}

static void mtk_oddmr_prepare(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int postalign_en = comp->mtk_crtc->panel_ext->params->spr_params.postalign_en;
	bool dmr_support, od_support, dbi_support;

	ODDMRAPI_LOG("+\n");
	mtk_ddp_comp_clk_prepare(comp);
	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;
	if (od_support || dmr_support || dbi_support ||
		((comp->mtk_crtc->panel_ext->params->spr_params.enable == 1) &&
		(comp->mtk_crtc->panel_ext->params->spr_params.relay == 0) &&
		postalign_en == 0))
		mtk_oddmr_top_prepare(comp, NULL);
	else
		mtk_oddmr_relay(comp, NULL);

	if (od_support)
		mtk_oddmr_od_prepare(comp, NULL);

	atomic_set(&oddmr_data->oddmr_clock_ref, 1);
}

static void mtk_oddmr_unprepare(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	mutex_lock(&oddmr_data->primary_data->clock_lock);
	atomic_dec(&oddmr_data->oddmr_clock_ref);
	while (atomic_read(&oddmr_data->oddmr_clock_ref) > 0) {
		mutex_unlock(&oddmr_data->primary_data->clock_lock);
		DDPINFO("waiting for oddmr_lock, %d\n",
				atomic_read(&oddmr_data->oddmr_clock_ref));
		usleep_range(50, 100);
		mutex_lock(&oddmr_data->primary_data->clock_lock);
	}
	mutex_unlock(&oddmr_data->primary_data->clock_lock);
	mtk_ddp_comp_clk_unprepare(comp);
}

static void mtk_disp_oddmr_config_overhead(struct mtk_ddp_comp *comp, struct mtk_ddp_config *cfg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	uint32_t comp_overhead;
	bool dmr_support, od_support, dbi_support;

	ODDMRAPI_LOG("+\n");

	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;
	if (cfg->tile_overhead.is_support) {
		//TODO: dmr blocksize
		if (mtk_crtc->is_dual_pipe)
			comp_overhead = oddmr_data->data->tile_overhead;
		else
			comp_overhead = 0;
		dmr_support = comp->mtk_crtc->panel_ext->params->is_support_dmr;
		od_support = comp->mtk_crtc->panel_ext->params->is_support_od;
		if (!dmr_support && !od_support)
			comp_overhead = 0;
		if (oddmr_data->is_right_pipe) {
			cfg->tile_overhead.right_in_width += comp_overhead;
			cfg->tile_overhead.right_overhead += comp_overhead;
			oddmr_data->cfg.comp_overhead = comp_overhead;
			oddmr_data->cfg.comp_in_width = cfg->tile_overhead.right_in_width;
			oddmr_data->cfg.total_overhead = cfg->tile_overhead.right_overhead;
		} else {
			cfg->tile_overhead.left_in_width += comp_overhead;
			cfg->tile_overhead.left_overhead += comp_overhead;
			oddmr_data->cfg.comp_overhead = comp_overhead;
			oddmr_data->cfg.comp_in_width = cfg->tile_overhead.left_in_width;
			oddmr_data->cfg.total_overhead = cfg->tile_overhead.left_overhead;
		}
	}
}

static void mtk_disp_oddmr_config_overhead_v(struct mtk_ddp_comp *comp,
	struct total_tile_overhead_v  *tile_overhead_v)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int oddmr_overhead_v = 0;
	unsigned int dbi_overhead_v = 0;

	DDPDBG("%s line: %d\n", __func__, __LINE__);

	if ( comp->mtk_crtc->panel_ext->params->is_support_dbi == true)
		oddmr_overhead_v += dbi_overhead_v;

	/*set component overhead*/
	oddmr_data->tile_overhead_v.comp_overhead_v = oddmr_overhead_v;
	/*add component overhead on total overhead*/
	tile_overhead_v->top_overhead_v +=
			oddmr_data->tile_overhead_v.comp_overhead_v;
	tile_overhead_v->bot_overhead_v +=
			oddmr_data->tile_overhead_v.comp_overhead_v;
	/*copy from total overhead info*/
	oddmr_data->tile_overhead_v.top_overhead_v =
				tile_overhead_v->top_overhead_v;
	oddmr_data->tile_overhead_v.bot_overhead_v =
				tile_overhead_v->bot_overhead_v;
}

static void mtk_oddmr_top_config(struct mtk_ddp_comp *comp,
	struct mtk_ddp_config *cfg, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t value = 0, mask = 0;

	if (oddmr_data->data->dbi_version == MTK_DBI_V3 || oddmr_data->data->od_version >= MTK_OD_V3) {
		if (oddmr_data->data->need_bypass_shadow == true) {
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_TOP_SHADOW_CTRL, mask, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, OD_BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_SHADOW_CTRL, mask, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, MURA_BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_MURA_SHADOW_CTRL, mask, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, DMR_BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DMR_SHADOW_CTRL, mask, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, AREAL_BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_AREAL_SHADOW_CTRL, mask, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, DBI_BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DBI_SHADOW_CTRL, mask, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, SPR2RGB_BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SPR_SHADOW_CTRL, mask, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, OD_SPR2RGB_BYPASS_SHADOW);
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_SPR_SHADOW_CTRL, mask, handle);
		}
		/* ODDMR input&output enable */
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 1, MT6993_REG_ODDMR_OUTP_EN);
		SET_VAL_MASK(value, mask, 1, MT6993_REG_ODDMR_OUTP_SUB_EN);
		SET_VAL_MASK(value, mask, 1, MT6993_REG_ODDMR_INP_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6993_DISP_ODDMR_REG_ODDMR_OUTP_EN, mask, handle);
		/* ODDMR input&output size */
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_WIDTH, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);

		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			DISP_ODDMR_OUTP_SUB_IN_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			DISP_ODDMR_OUTP_SUB_IN_VSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.width,
			DISP_ODDMR_OUTP_SUB_OUT_HSIZE, handle);
		mtk_oddmr_write(comp, oddmr_data->cfg.height,
			DISP_ODDMR_OUTP_SUB_OUT_VSIZE, handle);
	}
}

static void mtk_oddmr_first_cfg(struct mtk_ddp_comp *comp,
		struct mtk_ddp_config *cfg, struct cmdq_pkt *handle)
{
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_ddp_comp *out_comp = NULL;
	int crtc_idx;
	unsigned int postalign_en;
	bool dmr_support, od_support, dbi_support;

	DDPMSG("%s+\n", __func__);
	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;
	postalign_en = comp->mtk_crtc->panel_ext->params->spr_params.postalign_en;
	/* get spr status */
	oddmr_data->spr_enable = comp->mtk_crtc->panel_ext->params->spr_params.enable;
	oddmr_data->spr_relay = comp->mtk_crtc->panel_ext->params->spr_params.relay;
	oddmr_data->spr_format = comp->mtk_crtc->panel_ext->params->spr_params.spr_format_type;
	oddmr_data->od_user_gain = 64;
	/* read panelid */
	crtc_idx = drm_crtc_index(&mtk_crtc->base);
	if (crtc_idx == 0)
		out_comp = mtk_ddp_comp_request_output(mtk_crtc);
	if (out_comp && (dmr_support || od_support))
		out_comp->funcs->io_cmd(out_comp, NULL, DSI_READ_PANELID, &oddmr_data->primary_data->panelid);
	mtk_oddmr_fill_cfg(comp, cfg);
	if (dmr_support || od_support ||
		((comp->mtk_crtc->panel_ext->params->spr_params.enable == 1) &&
		(comp->mtk_crtc->panel_ext->params->spr_params.relay == 0) &&
		postalign_en == 0)) {
		mtk_oddmr_set_spr2rgb(comp, handle);
		if (oddmr_data->data->od_version < MTK_OD_V2) {
			if (comp->mtk_crtc->is_dual_pipe)
				mtk_oddmr_set_crop(comp, NULL);
			else
				mtk_oddmr_write(comp, 1, DISP_ODDMR_TOP_CRP_BYPSS, NULL);
		}
	}
	mtk_oddmr_top_config(comp, cfg, handle);
	DDPMSG("%s dmr %d od %d dbi %d-\n", __func__, dmr_support, od_support, dbi_support);
}

static void mtk_oddmr_remap_config(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *handle)
{
	int remap_enable;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");

	remap_enable = atomic_read(&oddmr_data->dmr_data.remap_enable);
	if (remap_enable) {
		mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
		mtk_oddmr_dmr_change_remap_gain(comp, handle);
		mtk_oddmr_remap_set_enable(comp, handle, true);
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
	}

	remap_enable = atomic_read(&oddmr_data->dbi_data.remap_enable);

	if (remap_enable) {
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		mtk_oddmr_dbi_change_remap_gain(comp, handle, oddmr_data->dbi_data.cur_max_time);
		mtk_oddmr_remap_set_enable(comp, handle, true);
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
	}

}

static void mtk_oddmr_dmr_set_slc(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle, int ar)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int value, mask;

	if (oddmr_data->use_slc[DMR_SLC] && g_slc_state[DMR_SLC] == ODDMR_SLC_VALID) {
		value = 0;
		mask = 0;
		SET_VAL_MASK(value, mask, ar, REG_DMR_SLC_AR);
		if (g_slc_gid[DMR_SLC] > 0)
			SET_VAL_MASK(value, mask, g_slc_gid[DMR_SLC], REG_DMR_SLC_GID);
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DMR_GUSER_CTRL_1, mask, handle);
	}
}

static void mtk_oddmr_dmr_config(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data;
	struct mtk_drm_cus_setting_info *cus_setting_info = NULL;
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node = NULL;
	unsigned int cus_setting_state = 0;
	unsigned int dbv_table_idx = 0;
	unsigned int dbv_node = 0;
	unsigned int fps_table_idx = 0;
	unsigned int fps_node = 0;
	dma_addr_t addr = 0;
	uint32_t value = 0, mask = 0;
	unsigned int cur_dbv;
	unsigned int cur_fps;
	unsigned int cur_dbv_mode;

	// DMR V2 partial update
	unsigned int crop_height;
	unsigned int top_overhead_v, bot_overhead_v;
	unsigned int top_comp_overhead_v, bot_comp_overhead_v;
	unsigned int dmr_y_ini, dmr_y_offset = 0;
	unsigned int dmr_input_height; //pixel base
	unsigned int is_compression_mode;
	int cur_bin_idx;
	unsigned int reg_tuning_en = 0;
	unsigned int full_height = mtk_crtc_get_height_by_comp(__func__,
				&comp->mtk_crtc->base, comp, true);
	unsigned int full_width = mtk_crtc_get_width_by_comp(__func__,
				&comp->mtk_crtc->base, comp, true);
	struct mtk_ddp_comp *output_comp = mtk_ddp_comp_request_output(comp->mtk_crtc);
	struct mtk_dsi *dsi = container_of(output_comp, struct mtk_dsi, ddp_comp);

	unsigned int i = 0;
	unsigned int dmr_udma_height = 0; //byte base
	unsigned int dmr_udma_y_ini = 0; //byte base
	unsigned int slice_height_sum = 0;
	unsigned int slice_size_sum = 0;

	ODDMRAPI_LOG("+\n");
	if (!oddmr_data->primary_data->dmr_support) {
		ODDMRFLOW_LOG("%s: dmr is not support\n", __func__);
		return;
	}

	if (oddmr_data->primary_data->dmr_state != ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("%s: dmr bin file loading not finished\n", __func__);
		return;
	}

	cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
	if (cur_bin_idx == -1) {
		is_compression_mode = 0;
	} else {
		dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
		is_compression_mode =
			dmr_cfg_data->dmr_pu_info.is_compression_mode;
	}

	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
	cur_fps = oddmr_data->primary_data->current_timing.vrefresh;
	cur_dbv_mode = oddmr_data->primary_data->current_timing.dbv_mode;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);
	cus_setting_state = atomic_read(&oddmr_data->dmr_data.cus_setting_state);

	mtk_oddmr_dmr_common_init(comp, handle);
	/* spr2rgb config */
	if (!(oddmr_data->spr_enable == 0 || oddmr_data->spr_relay == 1)) {
		switch(oddmr_data->spr_format) {
		case MTK_PANEL_RGBG_BGRG_TYPE:
		case MTK_PANEL_BGRG_RGBG_TYPE:
			SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_SPR_MODE);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
				mask, handle);
			mtk_oddmr_set_spr2rgb(comp, handle);
			break;
		case MTK_PANEL_RGBRGB_BGRBGR_TYPE:
		case MTK_PANEL_BGRBGR_RGBRGB_TYPE:
		case MTK_PANEL_RGBRGB_BRGBRG_TYPE:
		case MTK_PANEL_BRGBRG_RGBRGB_TYPE:
			SET_VAL_MASK(value, mask, 1, MT6991_REG_SPR2RGB_BYPASS);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS,
				mask, handle);
			SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_SPR_MODE);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
				mask, handle);
			SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DELTA_MODE_ODD);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
				mask, handle);
			SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DELTA_MODE_EVEN);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
				mask, handle);
			break;
		default:
			break;
		}
	}
	mtk_oddmr_dmr_smi(comp, handle);

	/* config dmr register whitch from bin file */
	if (cur_bin_idx != -1) {
		cus_setting_info = &oddmr_data->primary_data->dmr_cus_setting_info;
		if(cus_setting_state == 1 && cur_dbv_mode < cus_setting_info->dbv_mode_num)
			fps_dbv_node = &cus_setting_info->fps_dbv_node[cur_dbv_mode];
		else
			fps_dbv_node = &dmr_cfg_data->fps_dbv_node;
		if(mtk_oddmr_dmr_dbv_lookup(cur_dbv, dmr_cfg_data, fps_dbv_node, &dbv_table_idx, &dbv_node)) {
			PC_ERR("dmr dbv lookup fail\n");
			return;
		}
		if(mtk_oddmr_dmr_fps_lookup(cur_fps, dmr_cfg_data, fps_dbv_node, &fps_table_idx, &fps_node)) {
			PC_ERR("dmr fps lookup fail\n");
			return;
		}
		atomic_set(&oddmr_data->dmr_data.cur_dbv_node, dbv_node);
		atomic_set(&oddmr_data->dmr_data.cur_dbv_table_idx, dbv_table_idx);
		atomic_set(&oddmr_data->dmr_data.cur_fps_node, fps_node);
		atomic_set(&oddmr_data->dmr_data.cur_fps_table_idx, fps_table_idx);
		mtk_oddmr_dmr_static_cfg(comp, handle, &dmr_cfg_data->static_cfg);
		mtk_oddmr_dmr_gain_cfg(comp,
			handle, dbv_node, fps_node, dmr_cfg_data);
		//set dmr table
		addr = oddmr_data->dmr_data.mura_table[cur_bin_idx][dbv_table_idx][fps_table_idx]->dma_addr;
		mtk_oddmr_write(comp, addr >> 4,
			MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_0, handle);
		mtk_oddmr_write(comp, addr >> 20,
			MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_1, handle);
	}
	if (oddmr_data->data->dbi_version== MTK_DBI_V3) {
		mtk_oddmr_write(comp, full_width,
			DISP_ODDMR_REG_DMR_FRAME_WIDTH, handle);
		mtk_oddmr_write(comp, full_width,
			DISP_ODDMR_REG_DMR_REAL_FRAME_WIDTH, handle);
		mtk_oddmr_write(comp, full_height,
			DISP_ODDMR_REG_DMR_REAL_FRAME_HEIGHT, handle);
	}

	/* dmr size config for partial update*/
	if(oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {
		top_overhead_v = (!comp->mtk_crtc->tile_overhead_v.top_overhead_v)
				? 0 : oddmr_data->tile_overhead_v.top_overhead_v;
		bot_overhead_v = (!comp->mtk_crtc->tile_overhead_v.bot_overhead_v)
				? 0 : oddmr_data->tile_overhead_v.bot_overhead_v;
		top_comp_overhead_v = (!top_overhead_v)
				? 0 : oddmr_data->tile_overhead_v.comp_overhead_v;
		bot_comp_overhead_v = (!bot_overhead_v)
				? 0 : oddmr_data->tile_overhead_v.comp_overhead_v;
		crop_height = oddmr_data->roi_height +
					(top_overhead_v - top_comp_overhead_v) +
					(bot_overhead_v - bot_comp_overhead_v);
		dmr_input_height = oddmr_data->roi_height +
					top_overhead_v + bot_overhead_v;
		ODDMRAPI_LOG("log: %s %d overhead_v T:%d comp_overhead_v T:%d\n",
			__func__, __LINE__, top_overhead_v, top_comp_overhead_v);
		ODDMRAPI_LOG("log: %s %d overhead_v B:%d comp_overhead_v B:%d crop_h:%d\n",
			__func__, __LINE__,
			bot_overhead_v, bot_comp_overhead_v, crop_height);
		/* update y ini */
		dmr_y_ini = oddmr_data->dbi_pu_data.dbi_y_ini;
		//ODDMR input size
		mtk_oddmr_write(comp, dmr_input_height,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
		//DBI&DMR input size and pos
		if (oddmr_data->data->dbi_version== MTK_DBI_V3) {
			mtk_oddmr_write(comp, dmr_input_height,
				DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
			mtk_oddmr_write(comp, dmr_y_ini,
				MT6993_DISP_ODDMR_REG_DMR_Y_INI, handle);
		} else {
			mtk_oddmr_write(comp, dmr_input_height,
				MT6991_DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
			mtk_oddmr_write(comp, dmr_y_ini,
				MT6991_DISP_ODDMR_REG_DMR_Y_INI, handle);
		}
		if (is_compression_mode) {
			// align dmr slice size
			for (i = 0; i < dmr_cfg_data->dmr_pu_info.slice_num; i++) {
				slice_size_sum += dmr_cfg_data->dmr_pu_info.slice_size[i];
				slice_height_sum += dmr_cfg_data->dmr_pu_info.slice_height[i];
				if (dmr_y_ini >= slice_height_sum)
					continue;
				if (i == 0) {
					dmr_y_offset = dmr_y_ini;
					dmr_udma_y_ini = 0;
				} else {
					dmr_y_offset = dmr_y_ini -
						(slice_height_sum - dmr_cfg_data->dmr_pu_info.slice_height[i]);
					dmr_udma_y_ini = slice_size_sum -
						dmr_cfg_data->dmr_pu_info.slice_size[i];
				}
				break;
			}
			slice_size_sum = 0;
			slice_height_sum = 0;
			for (i = 0; i < dmr_cfg_data->dmr_pu_info.slice_num; i++) {
				slice_size_sum += dmr_cfg_data->dmr_pu_info.slice_size[i];
				slice_height_sum += dmr_cfg_data->dmr_pu_info.slice_height[i];
				if (dmr_y_ini + dmr_input_height <= slice_height_sum) {
					dmr_udma_height = slice_size_sum - dmr_udma_y_ini;
					break;
				}
			}
			// dmr udma config
			mtk_oddmr_write(comp, dmr_udma_height + 1,
				MT6991_DISP_ODDMR_REG_DMR_UDMA_HEIGHT_OUT, handle);
			mtk_oddmr_write(comp, dmr_udma_y_ini,
				MT6991_DISP_ODDMR_REG_DMR_UDMA_Y_INI, handle);
			mtk_oddmr_write(comp,
				((1 << 31) | (dmr_y_offset << 16) | crop_height),
				MT6991_DISP_ODDMR_REG_V_CROP_EN_R, handle);
			mtk_oddmr_write(comp,
				((1 << 31) | (dmr_y_offset << 16) | crop_height),
				MT6991_DISP_ODDMR_REG_V_CROP_EN_G, handle);
			mtk_oddmr_write(comp,
				((1 << 31) | (dmr_y_offset << 16) | crop_height),
				MT6991_DISP_ODDMR_REG_V_CROP_EN_B, handle);
		}
		//DBI&DMR output size
		mtk_oddmr_write(comp, dmr_input_height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
		mtk_oddmr_write(comp, dmr_input_height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
	} else {
		//ODDMR input size
		mtk_oddmr_write(comp, full_height,
			MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
		//DBI&DMR input pos and size
		if (oddmr_data->data->dbi_version== MTK_DBI_V3) {
			mtk_oddmr_write(comp, full_height,
				DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
			mtk_oddmr_write(comp, 0,
				MT6993_DISP_ODDMR_REG_DMR_Y_INI, handle);
		} else {
			mtk_oddmr_write(comp, full_height,
				MT6991_DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_REG_DMR_Y_INI, handle);
		}
		if (is_compression_mode) {
			for (i = 0; i < dmr_cfg_data->dmr_pu_info.slice_num; i++)
				dmr_udma_height += dmr_cfg_data->dmr_pu_info.slice_size[i];
			mtk_oddmr_write(comp, dmr_udma_height + 1,
				MT6991_DISP_ODDMR_REG_DMR_UDMA_HEIGHT_OUT, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_REG_DMR_UDMA_Y_INI, handle);
			mtk_oddmr_write(comp,
				((0 << 31) | (0 << 16) | full_height),
				MT6991_DISP_ODDMR_REG_V_CROP_EN_R, handle);
			mtk_oddmr_write(comp,
				((0 << 31) | (0 << 16) | full_height),
				MT6991_DISP_ODDMR_REG_V_CROP_EN_G, handle);
			mtk_oddmr_write(comp,
				((0 << 31) | (0 << 16) | full_height),
				MT6991_DISP_ODDMR_REG_V_CROP_EN_B, handle);
		}
		//DBI&DMR output size
		mtk_oddmr_write(comp, full_height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
		mtk_oddmr_write(comp, full_height,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
	}

	/* dmr clk enable */
	if (cur_bin_idx == -1)
		mtk_oddmr_set_dmr_enable(comp, 0, handle);
	else
		mtk_oddmr_set_dmr_enable(comp, oddmr_data->dmr_enable, handle);

	if (!dsi->output_en)
		oddmr_data->primary_data->slc_frame_cnt[DMR_SLC] = 0;
	ODDMRLOW_LOG("slc cnt %d\n", oddmr_data->primary_data->slc_frame_cnt[DMR_SLC]);
	if (!oddmr_data->primary_data->slc_frame_cnt[DMR_SLC])
		mtk_oddmr_dmr_set_slc(comp, handle, 6);
	else
		mtk_oddmr_dmr_set_slc(comp, handle, 2);

	/* dmr register tuning */
	reg_tuning_en = atomic_read(&oddmr_data->reg_tuning_en);
	if (reg_tuning_en == 1)
		mtk_oddmr_tuning_cfg(comp, handle, &oddmr_data->primary_data->oddmr_reg_tuning_info);
}

static void mtk_oddmr_dbi_set_slc(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle, int ar)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int value, mask;

	if (oddmr_data->use_slc[DBI_SLC] && g_slc_state[DBI_SLC] == ODDMR_SLC_VALID) {
		value = 0;
		mask = 0;
		SET_VAL_MASK(value, mask, ar, REG_DBI_SLC_AR);
		if (g_slc_gid[DBI_SLC] > 0)
			SET_VAL_MASK(value, mask, g_slc_gid[DBI_SLC], REG_DBI_SLC_GID);
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DBI_GUSER_CTRL_1, mask, handle);
	}
}

unsigned int mtk_oddmr_dbi_find_start_slice(uint32_t slice_num, uint32_t slice_height, uint32_t start_line)
{
	unsigned int i;

	for(i= 0;i<= slice_num;i++){
		if(i * slice_height > start_line)
			break;
	}
	i--;
	return i;
}

static void mtk_oddmr_dbi_vfree(void *ptr_t)
{
	if(ptr_t)
		vfree(ptr_t);
}

static void *mtk_oddmr_dbi_vmalloc(unsigned int size)
{
	void *ptr_t;

	ptr_t = vmalloc(size);
	if (!ptr_t)
		PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
	return ptr_t;
}

static void mtk_oddmr_dbi_config(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int dbi_fps_node = 0;
	unsigned int dbi_dbv_node = 0;
	int cur_tb;

	struct mtk_drm_dbi_cfg_info *dbi_cfg_data = &oddmr_data->primary_data->dbi_cfg_info;
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data_tb1 = &oddmr_data->primary_data->dbi_cfg_info_tb1;
	unsigned int scale_factor_v = dbi_cfg_data->basic_info.partial_update_scale_factor_v;
	dma_addr_t addr = 0;
	uint32_t dbi_table_size ;
	uint32_t dbi_udma_width ;
	uint32_t dbi_udma_height;

	unsigned int crop_height;
	unsigned int top_overhead_v, bot_overhead_v;
	unsigned int top_comp_overhead_v, bot_comp_overhead_v;
	unsigned int idx;
	unsigned int width,height,reg_val;

	struct mtk_ddp_comp *output_comp = mtk_ddp_comp_request_output(comp->mtk_crtc);
	struct mtk_dsi *dsi = container_of(output_comp, struct mtk_dsi, ddp_comp);

	unsigned int cur_dbv;
	unsigned int cur_fps;
	unsigned int gain_ratio;
	uint32_t value, mask;
	unsigned int dbi_size_as_block = 0;
	unsigned int size;
	void *ptr_t = NULL;

	unsigned int pu_y_ini,pu_height,start_slice_idx,start_slice_offset;

	if (oddmr_data->primary_data->dbi_support && oddmr_data->primary_data->dbi_state == ODDMR_INIT_DONE
		&& atomic_read(&oddmr_data->dbi_data.update_table_done)) {

		gain_ratio = atomic_read(&oddmr_data->dbi_data.gain_ratio);

		mutex_lock(&oddmr_data->primary_data->timing_lock);
		cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
		cur_fps = oddmr_data->primary_data->current_timing.vrefresh;
		mutex_unlock(&oddmr_data->primary_data->timing_lock);

		if(oddmr_data->data->dbi_version == MTK_DBI_V3)
			mtk_oddmr_dbi_common_init(comp, handle);
		else
			mtk_oddmr_dmr_common_init(comp, handle);

		if (!(oddmr_data->spr_enable == 0 || oddmr_data->spr_relay == 1)) {
			if (oddmr_data->data->dbi_version == MTK_DBI_V2 ||
				oddmr_data->data->dbi_version == MTK_DBI_V3) {
				value = 0;
				mask = 0;
				switch(oddmr_data->spr_format) {
				case MTK_PANEL_RGBG_BGRG_TYPE:
				case MTK_PANEL_BGRG_RGBG_TYPE:
					SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_SPR_MODE);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
						mask, handle);
					mtk_oddmr_set_spr2rgb(comp, handle);
					break;
				case MTK_PANEL_RGBRGB_BGRBGR_TYPE:
				case MTK_PANEL_BGRBGR_RGBRGB_TYPE:
				case MTK_PANEL_RGBRGB_BRGBRG_TYPE:
				case MTK_PANEL_BRGBRG_RGBRGB_TYPE:
					SET_VAL_MASK(value, mask, 1, MT6991_REG_SPR2RGB_BYPASS);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS,
						mask, handle);
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_SPR_MODE);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
						mask, handle);
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DELTA_MODE_ODD);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
						mask, handle);
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DELTA_MODE_EVEN);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_REG_DMR_SPR_MODE,
						mask, handle);
					break;
				default:
					break;
				}
			} else {
				mtk_oddmr_set_spr2rgb(comp, handle);
			}
		}

		if (oddmr_data->data->dbi_version >= MTK_DBI_V2)
			mtk_oddmr_dbi_smi(comp, handle);
		else
			mtk_oddmr_dmr_smi(comp, handle);

		if(mtk_oddmr_dbi_dbv_lookup(cur_dbv,
			dbi_cfg_data->fps_dbv_node.DBV_node, dbi_cfg_data->fps_dbv_node.DBV_num, &dbi_dbv_node))
			ODDMRFLOW_LOG("dmr dbv lookup fail\n");
		if(mtk_oddmr_dbi_fps_lookup(cur_fps,
			dbi_cfg_data, &dbi_fps_node))
			ODDMRFLOW_LOG("dmr fps lookup fail\n");
		atomic_set(&oddmr_data->dbi_data.cur_dbv_node, dbi_dbv_node);
		atomic_set(&oddmr_data->dbi_data.cur_fps_node, dbi_fps_node);

		if (dsi->output_en) {
			idx = (unsigned int)atomic_read(&oddmr_data->dbi_data.cur_table_idx);
			addr = oddmr_data->dbi_data.dbi_table[idx]->dma_addr;
		} else {
			mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
			idx = (unsigned int)atomic_read(&oddmr_data->dbi_data.update_table_idx);
			addr = oddmr_data->dbi_data.dbi_table[idx]->dma_addr;
			atomic_set(&oddmr_data->dbi_data.cur_table_idx, atomic_read(
				&oddmr_data->dbi_data.update_table_idx));
			if (oddmr_data->data->dbi_version == MTK_DBI_V2 ||
				oddmr_data->data->dbi_version == MTK_DBI_V3) {
				oddmr_data->dbi_data.table_size = oddmr_data->dbi_data.dbi_table_size[idx];
				dbi_cfg_data->basic_info.partial_update_scale_factor_v =
					oddmr_data->dbi_data.dbi_table_block_v[idx];
				dbi_cfg_data->basic_info.partial_update_scale_factor_h =
					oddmr_data->dbi_data.dbi_table_block_h[idx];
				scale_factor_v = dbi_cfg_data->basic_info.partial_update_scale_factor_v;
				if(oddmr_data->dbi_data.table_format[idx] == DBI_COMP_TABLE_COMPRESSION){
					oddmr_data->dbi_data.curr_table_format = oddmr_data->dbi_data.table_format[idx];
					oddmr_data->dbi_data.curr_slice_height = oddmr_data->dbi_data.slice_height[idx];
					oddmr_data->dbi_data.curr_used_entry = oddmr_data->dbi_data.used_entry[idx];
					if(oddmr_data->dbi_data.curr_slice_num != oddmr_data->dbi_data.slice_num[idx]){
						mtk_oddmr_dbi_vfree(oddmr_data->dbi_data.curr_slice_offset);
						oddmr_data->dbi_data.curr_slice_offset = NULL;
						size = oddmr_data->dbi_data.slice_num[idx] * sizeof(uint32_t);
						ptr_t = mtk_oddmr_dbi_vmalloc(size);
						memcpy(ptr_t, oddmr_data->dbi_data.slice_offset[idx], size);
						oddmr_data->dbi_data.curr_slice_offset= ptr_t;
						oddmr_data->dbi_data.curr_slice_num =
							oddmr_data->dbi_data.table_format[idx];
					}else {
						size = oddmr_data->dbi_data.slice_num[idx] * sizeof(uint32_t);
						memcpy(oddmr_data->dbi_data.curr_slice_offset,
							oddmr_data->dbi_data.slice_offset[idx], size);
					}
				}else
					oddmr_data->dbi_data.curr_table_format = DBI_COMP_TABLE_TRUNC;
			}
			oddmr_data->primary_data->slc_frame_cnt[DBI_SLC] = 0;
			mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		}
		cur_tb = atomic_read(&oddmr_data->dbi_data.cur_table_idx);
		if (cur_tb) {
			mtk_oddmr_dmr_static_cfg(comp, handle, &dbi_cfg_data_tb1->static_cfg);
			mtk_oddmr_dbi_gain_cfg(comp,
				handle, dbi_dbv_node, dbi_fps_node, dbi_cfg_data_tb1 ,gain_ratio);
		} else {
			mtk_oddmr_dmr_static_cfg(comp, handle, &dbi_cfg_data->static_cfg);
			mtk_oddmr_dbi_gain_cfg(comp,
				handle, dbi_dbv_node, dbi_fps_node, dbi_cfg_data,gain_ratio);
		}

		if (oddmr_data->data->dbi_version == MTK_DBI_V2 || oddmr_data->data->dbi_version == MTK_DBI_V3) {
			mtk_oddmr_write(comp, addr >> 4,
				MT6991_DISP_ODDMR_REG_DBI_UDMA_BASE_ADDR_0, handle);
			mtk_oddmr_write(comp, addr >> 20,
				MT6991_DISP_ODDMR_REG_DBI_UDMA_BASE_ADDR_1, handle);
		} else {
			mtk_oddmr_write(comp, addr >> 4, DISP_ODDMR_DMR_UDMA_CTR_4, handle);
			mtk_oddmr_write(comp, addr >> 20, DISP_ODDMR_DMR_UDMA_CTR_5, handle);
		}

		if(oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {
			top_overhead_v = (!comp->mtk_crtc->tile_overhead_v.top_overhead_v)
					? 0 : oddmr_data->tile_overhead_v.top_overhead_v;
			bot_overhead_v = (!comp->mtk_crtc->tile_overhead_v.bot_overhead_v)
					? 0 : oddmr_data->tile_overhead_v.bot_overhead_v;
			top_comp_overhead_v = (!top_overhead_v)
					? 0 : oddmr_data->tile_overhead_v.comp_overhead_v;
			bot_comp_overhead_v = (!bot_overhead_v)
					? 0 : oddmr_data->tile_overhead_v.comp_overhead_v;
			crop_height = oddmr_data->roi_height +
						(top_overhead_v - top_comp_overhead_v) +
						(bot_overhead_v - bot_comp_overhead_v);
			ODDMRAPI_LOG("log: %s %d overhead_v T:%d comp_overhead_v T:%d\n",
				__func__, __LINE__, top_overhead_v, top_comp_overhead_v);
			ODDMRAPI_LOG("log: %s %d overhead_v B:%d comp_overhead_v B:%d crop_h:%d\n",
				__func__, __LINE__,
				bot_overhead_v, bot_comp_overhead_v, crop_height);

			if (oddmr_data->data->dbi_version == MTK_DBI_V2 ||
				oddmr_data->data->dbi_version == MTK_DBI_V3) {
				//ODDMR input size
				mtk_oddmr_write(comp,
					(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
					MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);

				//DBI input size
				if (oddmr_data->data->dbi_version == MTK_DBI_V3) {
					mtk_oddmr_write(comp,
						(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
						DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
					mtk_oddmr_write(comp, oddmr_data->dbi_pu_data.dbi_y_ini,
						MT6993_DISP_ODDMR_REG_DMR_Y_INI, handle);
				} else {
					mtk_oddmr_write(comp,
						(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
						MT6991_DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
					//DBI input pos
					mtk_oddmr_write(comp, oddmr_data->dbi_pu_data.dbi_y_ini,
						MT6991_DISP_ODDMR_REG_DMR_Y_INI, handle);
				}

				if(oddmr_data->dbi_data.curr_table_format == DBI_COMP_TABLE_COMPRESSION){
					pu_y_ini = oddmr_data->dbi_pu_data.dbi_y_ini;
					pu_height = oddmr_data->roi_height + top_overhead_v + bot_overhead_v;
					start_slice_idx =
						mtk_oddmr_dbi_find_start_slice(oddmr_data->dbi_data.curr_slice_num,
						oddmr_data->dbi_data.curr_slice_height, pu_y_ini);
					start_slice_offset = oddmr_data->dbi_data.curr_slice_offset[start_slice_idx];

					dbi_table_size = oddmr_data->dbi_data.curr_used_entry;
					dbi_udma_width =
						oddmr_data->dbi_data.curr_used_entry >= (1<<24)?(1<<12):(1<<11);
					dbi_udma_height = (dbi_table_size + dbi_udma_width -1)/dbi_udma_width;

					mtk_oddmr_write(comp, start_slice_offset/dbi_udma_width,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);
					dbi_udma_height -= start_slice_offset/dbi_udma_width;
					mtk_oddmr_write(comp, dbi_udma_height,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
					mtk_oddmr_write(comp, start_slice_offset%dbi_udma_width,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_X_INI, handle);

					value = 0;mask = 0;
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_R);
					SET_VAL_MASK(value, mask,
						pu_y_ini -start_slice_idx*oddmr_data->dbi_data.curr_slice_height,
						MT6991_REG_DBI_V_ST_R);
					SET_VAL_MASK(value, mask,
						pu_height,
						MT6991_REG_DBI_V_LENGTH_R);
					mtk_oddmr_write(comp, value,
						MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R, handle);

					value = 0;mask = 0;
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_G);
					SET_VAL_MASK(value, mask,
						pu_y_ini -start_slice_idx*oddmr_data->dbi_data.curr_slice_height,
						MT6991_REG_DBI_V_ST_G);
					SET_VAL_MASK(value, mask,
						pu_height,
						MT6991_REG_DBI_V_LENGTH_G);
					mtk_oddmr_write(comp, value,
						MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G, handle);

					value = 0;mask = 0;
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_B);
					SET_VAL_MASK(value, mask,
						pu_y_ini -start_slice_idx*oddmr_data->dbi_data.curr_slice_height,
						MT6991_REG_DBI_V_ST_B);
					SET_VAL_MASK(value, mask,
						pu_height,
						MT6991_REG_DBI_V_LENGTH_B);
					mtk_oddmr_write(comp, value,
						MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B, handle);
				} else {
					scale_factor_v = dbi_cfg_data->basic_info.partial_update_scale_factor_v;
					//DBI udma size
					mtk_oddmr_write(comp, oddmr_data->dbi_pu_data.dbi_y_ini / scale_factor_v,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);

					//DBI table size as block
					dbi_size_as_block = (oddmr_data->roi_height + top_overhead_v +
						bot_overhead_v + scale_factor_v -1) / scale_factor_v;
					if ( (dbi_size_as_block < 0x10) &&
						(oddmr_data->data->dbi_version == MTK_DBI_V2)) {
						dbi_size_as_block = 0x10;
						mtk_oddmr_write(comp, dbi_size_as_block,
							MT6991_DISP_ODDMR_REG_DBI_VSIZE, handle);
						mtk_oddmr_write(comp,
							dbi_size_as_block * scale_factor_v,
							MT6991_DISP_ODDMR_REG_DBI_SCL_VSIZE, handle);
						mtk_oddmr_write(comp, dbi_size_as_block,
							MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
						value = 0;
						mask = 0;
						SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_R);
						SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_V_ST_R);
						SET_VAL_MASK(value, mask, (oddmr_data->roi_height +
							top_overhead_v + bot_overhead_v),
							MT6991_REG_DBI_V_LENGTH_R);
						mtk_oddmr_write(comp, value,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R, handle);
						value = 0;
						mask = 0;
						SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_G);
						SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_V_ST_G);
						SET_VAL_MASK(value, mask, (oddmr_data->roi_height +
							top_overhead_v + bot_overhead_v),
							MT6991_REG_DBI_V_LENGTH_G);
						mtk_oddmr_write(comp, value,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G, handle);
						value = 0;
						mask = 0;
						SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_B);
						SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_V_ST_B);
						SET_VAL_MASK(value, mask, (oddmr_data->roi_height +
							top_overhead_v + bot_overhead_v),
							MT6991_REG_DBI_V_LENGTH_B);
						mtk_oddmr_write(comp, value,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B, handle);
					} else {
						mtk_oddmr_write(comp, dbi_size_as_block,
							MT6991_DISP_ODDMR_REG_DBI_VSIZE, handle);

						//DBI table size as pixel
						mtk_oddmr_write(comp,
							(oddmr_data->roi_height +
							top_overhead_v + bot_overhead_v),
							MT6991_DISP_ODDMR_REG_DBI_SCL_VSIZE, handle);

						dbi_size_as_block = (oddmr_data->roi_height + top_overhead_v
							+ bot_overhead_v + scale_factor_v -1) /
							scale_factor_v;
						mtk_oddmr_write(comp, dbi_size_as_block,
							MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
					}
				}

				//DBI output size
				mtk_oddmr_write(comp,
					(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
					MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
				mtk_oddmr_write(comp,
					(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
					MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
			}

			if (priv->data->mmsys_id == MMSYS_MT6989) {
				/* ODDMR on MT6989 dose not support V crop */
				mtk_oddmr_write(comp, oddmr_data->dbi_pu_data.dbi_y_ini,
					DISP_ODDMR_REG_DMR_Y_INI, handle);
				mtk_oddmr_write(comp, (oddmr_data->roi_height + top_overhead_v +
					bot_overhead_v),
					DISP_ODDMR_FMT_CTR_1, handle); // oddmr input height

				mtk_oddmr_write(comp, oddmr_data->dbi_pu_data.dbi_udma_y_ini,
					DISP_ODDMR_DMR_UDMA_CTR_7, handle);

				mtk_oddmr_write(comp, oddmr_data->dbi_pu_data.y_idx2_ini,
					DISP_ODDMR_REG_Y_IDX2_INI, handle);
				mtk_oddmr_write(comp, oddmr_data->dbi_pu_data.y_remain2_ini,
					DISP_ODDMR_REG_Y_REMAIN2_INI, handle);
			}
		} else {
			if (priv->data->mmsys_id == MMSYS_MT6989) {
				mtk_oddmr_write(comp, 0,
					DISP_ODDMR_REG_DMR_Y_INI, handle);
				mtk_oddmr_write(comp, dbi_cfg_data->basic_info.panel_height,
					DISP_ODDMR_FMT_CTR_1, handle); // oddmr input height

				mtk_oddmr_write(comp, 0,
					DISP_ODDMR_DMR_UDMA_CTR_7, handle);

				mtk_oddmr_write(comp, 0,
					DISP_ODDMR_REG_Y_IDX2_INI, handle);
				mtk_oddmr_write(comp, 0,
					DISP_ODDMR_REG_Y_REMAIN2_INI, handle);
			}

			if (oddmr_data->data->dbi_version == MTK_DBI_V2) {
				width = dbi_cfg_data->basic_info.panel_width;
				mtk_oddmr_write(comp, width,
					MT6991_DISP_ODDMR_REG_ODDMR_FRAME_WIDTH, handle);
				mtk_oddmr_write(comp, width,
					MT6991_DISP_ODDMR_REG_DMR_REAL_FRAME_WIDTH, handle);
				if (oddmr_data->spr_enable == 1 && oddmr_data->spr_relay == 0) {
					mtk_oddmr_write(comp, width,
						MT6991_DISP_ODDMR_REG_DMR_FRAME_WIDTH, handle);
					switch (oddmr_data->spr_format) {
					case MTK_PANEL_RGBG_BGRG_TYPE:
					case MTK_PANEL_BGRG_RGBG_TYPE:
						mtk_oddmr_write(comp, (((width + 1) / 2) * 2),
							MT6991_DISP_ODDMR_REG_DBI_SCL_HSIZE, handle);
						mtk_oddmr_write(comp, (((width + 1) / 2) * 2),
							MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
						break;
					case MTK_PANEL_RGBRGB_BGRBGR_TYPE:
					case MTK_PANEL_BGRBGR_RGBRGB_TYPE:
					case MTK_PANEL_RGBRGB_BRGBRG_TYPE:
					case MTK_PANEL_BRGBRG_RGBRGB_TYPE:
						mtk_oddmr_write(comp, (((width + 3) / 4) * 4),
							MT6991_DISP_ODDMR_REG_DBI_SCL_HSIZE, handle);
						mtk_oddmr_write(comp, (((width + 5) / 6) * 6),
							MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
						break;
					default:
						break;
					}
				} else {
					mtk_oddmr_write(comp, (((width + 1) / 2) * 2),
						MT6991_DISP_ODDMR_REG_DMR_FRAME_WIDTH, handle);
					mtk_oddmr_write(comp, (((width + 1) / 2) * 2),
						MT6991_DISP_ODDMR_REG_DBI_SCL_HSIZE, handle);
					mtk_oddmr_write(comp, (((width + 1) / 2) * 2),
						MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
				}
			}
			if(oddmr_data->data->dbi_version == MTK_DBI_V3){
				height = dbi_cfg_data->basic_info.panel_height;
				scale_factor_v = dbi_cfg_data->basic_info.partial_update_scale_factor_v;

				if(oddmr_data->dbi_data.curr_table_format == DBI_COMP_TABLE_COMPRESSION){
					dbi_table_size = oddmr_data->dbi_data.curr_used_entry;
					dbi_udma_width =
						oddmr_data->dbi_data.curr_used_entry >= (1<<24)?(1<<12):(1<<11);
					dbi_udma_height = (dbi_table_size + dbi_udma_width -1)/dbi_udma_width;

					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);
					mtk_oddmr_write(comp, dbi_udma_height,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_X_INI, handle);
				} else {
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);

					reg_val = (height + scale_factor_v -1) / scale_factor_v;
					mtk_oddmr_write(comp, reg_val,
						MT6991_DISP_ODDMR_REG_DBI_VSIZE, handle);
					//DBI table size as pixel
					mtk_oddmr_write(comp, height,
						MT6991_DISP_ODDMR_REG_DBI_SCL_VSIZE, handle);
					//DBI udma size
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);
					reg_val = (height + scale_factor_v -1) / scale_factor_v;
					mtk_oddmr_write(comp, reg_val,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
				}

				mtk_oddmr_write(comp, height,
					DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
				mtk_oddmr_write(comp, 0,
					MT6993_DISP_ODDMR_REG_DMR_Y_INI, handle);
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R, handle);
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G, handle);
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B, handle);
			}
		}
		if (dbi_cfg_data->dbv_node.DBV_num) {
			if(mtk_oddmr_dbi_dbv_lookup(cur_dbv,
				dbi_cfg_data->dbv_node.DBV_node, dbi_cfg_data->dbv_node.DBV_num, &dbi_dbv_node))
				ODDMRFLOW_LOG("dbi dbv lookup fail\n");
			mtk_oddmr_dbi_dbv_table_cfg(comp,
				handle, dbi_dbv_node, dbi_cfg_data);
		}
		mtk_oddmr_set_dbi_enable(comp, oddmr_data->dbi_enable, handle);
		ODDMRLOW_LOG("slc cnt %d\n", oddmr_data->primary_data->slc_frame_cnt[DBI_SLC]);
		if (!oddmr_data->primary_data->slc_frame_cnt[DBI_SLC])
			mtk_oddmr_dbi_set_slc(comp, handle, 6);
		else
			mtk_oddmr_dbi_set_slc(comp, handle, 2);
	}
}

static void mtk_oddmr_od_config(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	struct cmdq_pkt *cmdq_handle0 = NULL;
	struct cmdq_pkt *cmdq_handle1 = NULL;
	struct cmdq_client *client = NULL;
	bool od_support;
	uint32_t value = 0, mask = 0;


	ODDMRFLOW_LOG("%s+\n", mtk_dump_comp_str(comp));
	if (mtk_crtc->gce_obj.client[CLIENT_PQ])
		client = mtk_crtc->gce_obj.client[CLIENT_PQ];
	else
		client = mtk_crtc->gce_obj.client[CLIENT_CFG];
	od_support = oddmr_data->primary_data->od_support;
	if (od_support == true &&
		oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE) {
		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			SET_VAL_MASK(value, mask, 1, REG_OD_RD_REG_EN); //for sram read
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_UDMA_CTR_0, mask, NULL);
			value = 0; mask = 0;
			mtk_oddmr_set_top_clk_force(comp, 1, NULL); //needed by writing sram and udma init
		}

		if (oddmr_data->data->od_version < MTK_OD_V2) {
			//crop off
			if (comp->mtk_crtc->is_dual_pipe)
				mtk_oddmr_set_crop(comp, NULL);
			else
				mtk_oddmr_write(comp, 1, DISP_ODDMR_TOP_CRP_BYPSS, NULL);
		}

		//write sram
		cmdq_mbox_enable(client->chan);
		cmdq_handle0 =
			oddmr_data->od_data.od_sram_pkgs[oddmr_data->od_data.od_dram_sel[0]][0];
		cmdq_handle1 =
			oddmr_data->od_data.od_sram_pkgs[oddmr_data->od_data.od_dram_sel[1]][1];
		if (cmdq_handle0) {
			CRTC_MMP_MARK(0, oddmr_ctl, comp->id, 0);
			cmdq_pkt_refinalize(cmdq_handle0);
			CRTC_MMP_MARK(0, oddmr_ctl, comp->id, 1);
			cmdq_pkt_flush(cmdq_handle0);
			CRTC_MMP_MARK(0, oddmr_ctl, comp->id, 2);
		}
		if (cmdq_handle1) {
			CRTC_MMP_MARK(0, oddmr_ctl, comp->id, 3);
			cmdq_pkt_refinalize(cmdq_handle1);
			CRTC_MMP_MARK(0, oddmr_ctl, comp->id, 4);
			cmdq_pkt_flush(cmdq_handle1);
			CRTC_MMP_MARK(0, oddmr_ctl, comp->id, 5);
		}
		cmdq_mbox_disable(client->chan);
		ODDMRAPI_LOG("oddmr_config_od_sram, %d\n", oddmr_data->od_data.od_sram_read_sel);
		if (oddmr_data->data->od_version >= MTK_OD_V3) {
			if (oddmr_data->od_data.od_sram_read_sel == 1)
				mtk_oddmr_write(comp, 0xE0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			else
				mtk_oddmr_write(comp, 0xD0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
		} else if (oddmr_data->data->od_version == MTK_OD_V2) {
			if (oddmr_data->od_data.od_sram_read_sel == 1)
				mtk_oddmr_write(comp, 0xA0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			else
				mtk_oddmr_write(comp, 0x90, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
		} else {
			if (oddmr_data->od_data.od_sram_read_sel == 1)
				mtk_oddmr_write(comp, 0x20, DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			else
				mtk_oddmr_write(comp, 0x10, DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
		}

		if (!(oddmr_data->spr_enable == 0 || oddmr_data->spr_relay == 1)) {
			if (oddmr_data->data->od_version >= MTK_OD_V2) { //OD TODO: MT6993 still need?
				switch (oddmr_data->spr_format) {
				case MTK_PANEL_RGBG_BGRG_TYPE:
				case MTK_PANEL_BGRG_RGBG_TYPE:
					SET_VAL_MASK(value, mask, 0, MT6991_REG_OD_SPR_MODE);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_REG_DMR_SPR_MODE, mask, handle);
					mtk_oddmr_set_spr2rgb(comp, handle);
					break;
				case MTK_PANEL_RGBRGB_BGRBGR_TYPE:
				case MTK_PANEL_BGRBGR_RGBRGB_TYPE:
				case MTK_PANEL_RGBRGB_BRGBRG_TYPE:
				case MTK_PANEL_BRGBRG_RGBRGB_TYPE:
					SET_VAL_MASK(value, mask, 1, MT6991_REG_SPR2RGB_BYPASS);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS, mask, handle);
					value = 0; mask = 0;
					SET_VAL_MASK(value, mask, 1, MT6991_REG_OD_SPR_MODE);
					SET_VAL_MASK(value, mask, 1, MT6991_REG_OD_DELTA_MODE_ODD);
					SET_VAL_MASK(value, mask, 1, MT6991_REG_OD_DELTA_MODE_EVEN);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_REG_DMR_SPR_MODE, mask, handle);
					break;
				default:
					break;
				}
			} else {
				mtk_oddmr_set_spr2rgb(comp, handle);
			}
		}
		value = 0; mask = 0;
		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			SET_VAL_MASK(value, mask, 0, MT6991_REG_OD_SPR2RGB_BYPASS); // =1 will cause OD bypass
			mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS, mask, handle);
		}

		uint32_t width = oddmr_data->cfg.width;

		if (oddmr_data->data->od_version == MTK_OD_V2) { //OD TODO: MT6993 no need?
			mtk_oddmr_write(comp, width,
				MT6991_DISP_ODDMR_REG_ODDMR_FRAME_WIDTH, handle);
			if (oddmr_data->spr_enable == 1 && oddmr_data->spr_relay == 0) {
				switch (oddmr_data->spr_format) {
				case MTK_PANEL_RGBG_BGRG_TYPE:
				case MTK_PANEL_BGRG_RGBG_TYPE:
					mtk_oddmr_write(comp, (((width + 1) / 2) * 2),
						MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
					break;
				case MTK_PANEL_RGBRGB_BGRBGR_TYPE:
				case MTK_PANEL_BGRBGR_RGBRGB_TYPE:
				case MTK_PANEL_RGBRGB_BRGBRG_TYPE:
				case MTK_PANEL_BRGBRG_RGBRGB_TYPE:
					mtk_oddmr_write(comp, (((width + 5) / 6) * 6),
						MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
					break;
				default:
					break;
				}
			} else {
				mtk_oddmr_write(comp, (((width + 1) / 2) * 2),
					MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE, handle);
			}
		}

		if (oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {//OD_PU
			unsigned int top_overhead_v =
						(!comp->mtk_crtc->tile_overhead_v.top_overhead_v)
						? 0 : oddmr_data->tile_overhead_v.top_overhead_v;
			unsigned int bot_overhead_v =
						(!comp->mtk_crtc->tile_overhead_v.bot_overhead_v)
						? 0 : oddmr_data->tile_overhead_v.bot_overhead_v;
			ODDMRAPI_LOG("PU=1: roi_height %d, overhead_v T %d B %d\n",
					oddmr_data->roi_height, top_overhead_v, bot_overhead_v);
			if (oddmr_data->data->od_version >= MTK_OD_V2) {
				//ODDMR input size
				mtk_oddmr_write(comp,
					(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
					MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
				//OUTP size
				mtk_oddmr_write(comp,
					(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
					MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
				mtk_oddmr_write(comp,
					(oddmr_data->roi_height + top_overhead_v + bot_overhead_v),
					MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
			}
		}

		mtk_oddmr_od_smi(comp, NULL);
		mtk_oddmr_od_set_dram(comp, NULL);
		mtk_oddmr_od_common_init(comp, NULL);
		mtk_oddmr_od_set_res_udma(comp, NULL);
		if (oddmr_data->data->od_version == MTK_OD_V2 && !oddmr_data->dmr_enable)
			mtk_oddmr_set_top_clk_force(comp, 0, NULL);
		mtk_oddmr_set_od_enable(comp, oddmr_data->od_enable, true, handle);
		//sw bypass first frame od pq
		ODDMRAPI_LOG("oddmr_config_od_enable, %d\n", oddmr_data->od_enable);
	}
}

static void mtk_oddmr_s2r_bypass(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, bool s2r_bypass)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRFLOW_LOG("%s+\n", mtk_dump_comp_str(comp));
	if (s2r_bypass)
		if (oddmr_data->data->od_version >= MTK_OD_V2)
			mtk_oddmr_write(comp, 0, MT6991_DISP_ODDMR_REG_SPR_COMP_EN, handle);
		else
			mtk_oddmr_write(comp, 0, DISP_ODDMR_REG_SPR_COMP_EN, handle);
	else
		mtk_oddmr_set_spr2rgb(comp, handle);
}

static void mtk_oddmr_config(struct mtk_ddp_comp *comp,
		struct mtk_ddp_config *cfg,
		struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	unsigned int postalign_en = 0;
	bool dmr_support, od_support;

	if (!comp->mtk_crtc || !comp->mtk_crtc->panel_ext || oddmr_data == NULL) {
		ODDMRFLOW_LOG("comp is invalid-\n");
		return;
	}
	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	if (comp->mtk_crtc->panel_ext->params)
		postalign_en = comp->mtk_crtc->panel_ext->params->spr_params.postalign_en;

	mtk_oddmr_fill_cfg(comp, cfg);
	mtk_oddmr_top_config(comp, cfg, handle);
	if (od_support || dmr_support) {
		if (oddmr_data->data->od_version < MTK_OD_V2) {
			//crop off
			if (comp->mtk_crtc->is_dual_pipe)
				mtk_oddmr_set_crop(comp, NULL);
			else
				mtk_oddmr_write(comp, 1, DISP_ODDMR_TOP_CRP_BYPSS, NULL);
		}
	}

	mtk_oddmr_od_config(comp, handle);

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	mtk_oddmr_dmr_config(comp, handle);
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

	if (oddmr_data->spr_enable == 1 && oddmr_data->spr_relay == 0 &&
		postalign_en == 0 && mtk_crtc->spr_is_on == 1)
		mtk_oddmr_set_spr2rgb(comp, handle);

	mtk_oddmr_dbi_config(comp,handle);
	mtk_oddmr_remap_config(comp, handle);
}

#define	TAB_MSG_LEN	(OD_GAIN_MAX * 23 + 15)
static void mtk_oddmr_dump_od_table(struct mtk_ddp_comp *comp, int table_idx, bool dump_detail)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	struct mtk_oddmr_od_table *table = od_param->od_tables[table_idx];
	struct mtk_oddmr_od_table_basic_info *info = &table->table_basic_info;
	int i, len = 0, n = 0;
	char msg[TAB_MSG_LEN];

	DDPDUMP("OD Table%d: %ux%u, fps %u(%d-%d), dbv 0x%x(0x%x-0x%x)\n",
			table_idx, info->width, info->height,
			info->fps, info->min_fps, info->max_fps,
			info->dbv, info->min_dbv, info->max_dbv);
	if (!dump_detail)
		return;

	len = snprintf(msg, TAB_MSG_LEN, " fps cnt %d, ", table->fps_cnt);
	if (len < 0) {
		DDPDUMP("%s:%d snprintf failed, %d\n", __func__, __LINE__, len);
		return;
	}
	for (i = 0; i < table->fps_cnt && i < OD_GAIN_MAX; i++) {
		if (oddmr_data->data->od_version >= MTK_OD_V3)
			n = snprintf(msg + len, TAB_MSG_LEN - len, "(%d,%d,%d,%d) ",
				table->fps_table[i].item, table->fps_table[i].value_r,
				table->fps_table[i].value, table->fps_table[i].value_b);
		else
			n = snprintf(msg + len, TAB_MSG_LEN - len, "(%d, %d) ",
				table->fps_table[i].item, table->fps_table[i].value);
		if (n < 0) {
			DDPDUMP("%s:%d snprintf failed, %d\n", __func__, __LINE__, n);
			return;
		}
		len += n;
	}
	DDPDUMP("%s\n", msg);

	len = snprintf(msg, TAB_MSG_LEN, " dbv cnt %d, ", table->bl_cnt);
	if (len < 0) {
		DDPDUMP("%s:%d snprintf failed, %d\n", __func__, __LINE__, len);
		return;
	}
	for (i = 0; i < table->bl_cnt && i < OD_GAIN_MAX; i++) {
		if (oddmr_data->data->od_version >= MTK_OD_V3)
			n = snprintf(msg + len, TAB_MSG_LEN - len, "(%d,%d,%d,%d) ",
				table->bl_table[i].item, table->bl_table[i].value_r,
				table->bl_table[i].value, table->bl_table[i].value_b);
		else
			n = snprintf(msg + len, TAB_MSG_LEN - len, "(%d, %d) ",
				table->bl_table[i].item, table->bl_table[i].value);
		if (n < 0) {
			DDPDUMP("%s:%d snprintf failed, %d\n", __func__, __LINE__, n);
			return;
		}
		len += n;
	}
	DDPDUMP("%s\n", msg);
}

static void mtk_oddmr_dump_od_param(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	struct mtk_oddmr_od_basic_param *basic_param = &od_param->od_basic_info.basic_param;
	int i = 0, cnt = 0;
	char valid_table_str[OD_TABLE_MAX + 1];
	bool dump_detail = true;

	DDPDUMP("OD Basic info:\n");
	for (i = 0; i < OD_TABLE_MAX; i++)
		valid_table_str[i] = od_param->valid_table[i] ? '1' : '0';
	valid_table_str[OD_TABLE_MAX] = '\0';
	DDPDUMP("%d valid tables: %s\n",
			od_param->valid_table_cnt, valid_table_str);
	DDPDUMP("res_switch_mode %d, %u x %u, table cnts %d, od_mode %d\n",
			basic_param->resolution_switch_mode,
			basic_param->panel_width, basic_param->panel_height,
			basic_param->table_cnt, basic_param->od_mode);
	DDPDUMP("dither_sel %d scaling_mode 0x%x\n",
			basic_param->dither_sel, basic_param->scaling_mode);
	if (od_param->valid_table_cnt > 8) {
		dump_detail = false;
		DDPDUMP("too many tables, not dump fps/dbv tables\n");
	}
	for (i = 0; i < basic_param->table_cnt; i++) {
		if (IS_TABLE_VALID_LOW(i, od_param->valid_table)) {
			cnt += 1;
			mtk_oddmr_dump_od_table(comp, i, dump_detail);
		}
		if (cnt == 20) {
			DDPDUMP("too many tables, only dump first 20 valid tables\n");
			return;
		}
	}
}

int mtk_oddmr_analysis(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool dmr_support, od_support, dbi_support;
	unsigned int cur_binset_idx = atomic_read(&oddmr_data->dmr_data.cur_binset_idx);
	int cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);

	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;

	DDPDUMP("== %s ANALYSIS:0x%pa ==\n", mtk_dump_comp_str(comp), &comp->regs_pa);
	DDPDUMP("od_support %d dmr_support %d dbi_support %d\n", od_support, dmr_support, dbi_support);
	DDPDUMP("od_en %d, dmr_en %d, od_state %d, dmr_state %d, dbi_enable %d, dbi_state %d\n",
			oddmr_data->od_enable,
			oddmr_data->dmr_enable,
			oddmr_data->primary_data->od_state,
			oddmr_data->primary_data->dmr_state,
			oddmr_data->dbi_enable,
			oddmr_data->primary_data->dbi_state);
	DDPDUMP("oddmr current bl %u, fps %u, dbv_mode %u, %u x %u\n",
			oddmr_data->primary_data->current_timing.bl_level,
			oddmr_data->primary_data->current_timing.vrefresh,
			oddmr_data->primary_data->current_timing.dbv_mode,
			oddmr_data->primary_data->current_timing.hdisplay,
			oddmr_data->primary_data->current_timing.vdisplay);
	DDPDUMP("OD: r_sel %d, dram_sel %d, dram_sel %d, sram0 %d, sram1 %d\n",
			oddmr_data->od_data.od_sram_read_sel,
			oddmr_data->od_data.od_dram_sel[0],
			oddmr_data->od_data.od_dram_sel[1],
			oddmr_data->od_data.od_sram_table_idx[0],
			oddmr_data->od_data.od_sram_table_idx[1]);
	mtk_oddmr_dump_od_param(comp);
	DDPDUMP("-- DeMura Current info dump --\n");
	DDPDUMP("cur_binset_idx: %u\n", cur_binset_idx);
	DDPDUMP("cur_bin_idx: %d\n", cur_bin_idx);
	DDPDUMP("DMR: cur_dbv_node %d, cur_fps_node %d\n",
			atomic_read(&oddmr_data->dmr_data.cur_dbv_node),
			atomic_read(&oddmr_data->dmr_data.cur_fps_node));
	DDPDUMP("DMR: cur_dbv_table_idx %d, cur_fps_table_idx %d\n",
			atomic_read(&oddmr_data->dmr_data.cur_dbv_table_idx),
			atomic_read(&oddmr_data->dmr_data.cur_fps_table_idx));
	return 0;
}

void mtk_oddmr_dump(struct mtk_ddp_comp *comp)
{
	void __iomem *baddr = comp->regs;
	void __iomem *mbaddr;
	int i;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool od_support = oddmr_data->primary_data->od_support;
	bool dmr_support = oddmr_data->primary_data->dmr_support;
	bool dbi_support = oddmr_data->primary_data->dbi_support;

	if (!(od_support || dmr_support || dbi_support))
		return;

	if (oddmr_data->data->dbi_version < MTK_DBI_V2) {
		DDPDUMP("== %s REGS:%pa ==\n", mtk_dump_comp_str(comp), &comp->regs_pa);
		DDPDUMP("-- Start dump oddmr registers --\n");
		mbaddr = baddr;
		for (i = 0; i < 0x2000; i += 16) {
			DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
				readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
				readl(mbaddr + i + 0xc));
		}
		return;
	}

	if(oddmr_data->data->dbi_version >= MTK_DBI_V2) {
		if (g_oddmr_dump_en == true) {
			/* Full DUMP */
			DDPDUMP("== %s REGS:%pa ==\n", mtk_dump_comp_str(comp), &comp->regs_pa);
			DDPDUMP("-- Start dump oddmr registers --\n");
			mbaddr = baddr;
			for (i = 0; i < 0x1000; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
			for (i = 0x10000; i < 0x11000; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
		} else {
			/* Partial DUMP */
			DDPDUMP("== %s REGS:%pa ==\n", mtk_dump_comp_str(comp), &comp->regs_pa);
			DDPDUMP("-- Start dump oddmr registers --\n");
			mbaddr = baddr;
			/* 1.TOP */
			for (i = 0; i < 0xd0; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
			DDPDUMP("ODDMR+%x: 0x%x\n", 0xf4, readl(mbaddr + 0xf4));
			DDPDUMP("ODDMR+%x: 0x%x\n", 0x100, readl(mbaddr + 0x100));
			for (i = 0x110; i < 0x200; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
			/* 2.DMR SMI */
			for (i = 0xd30; i < 0xdd0; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
			/* 3 DBI SMI */
			for (i = 0xf30; i < 0xfd0; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
			/* 4 DMR Control */
			for (i = 0x10140; i < 0x1015c; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
			/* 5 DBI Control */
			for (i = 0x10700; i < 0x10770; i += 16) {
				DDPDUMP("ODDMR+%x: 0x%x 0x%x 0x%x 0x%x\n", i, readl(mbaddr + i),
					readl(mbaddr + i + 0x4), readl(mbaddr + i + 0x8),
					readl(mbaddr + i + 0xc));
			}
			DDPDUMP("ODDMR+%x: 0x%x 0x%x\n", 0x10ca4,
				readl(mbaddr + 0x10ca4), readl(mbaddr + 0x10ca8));
		}
		return;
	}
	return;
}

void mtk_oddmr_dmr_cusomize_info_dump(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_oddmr_binset_cfg_info *cus_binset = NULL;
	struct mtk_drm_cus_setting_info *cus_setting = NULL;
	unsigned int binset_state = 0;
	unsigned int setting_state = 0;
	unsigned int value, offset;
	unsigned int DBV_num, FPS_num;
	unsigned int i, j, k;
	unsigned int reg_cnt = 0;
	unsigned int dbv_idx, fps_idx;
	char result[512];
	unsigned int result_offset;

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	binset_state = atomic_read(&oddmr_data->dmr_data.cus_binset_state);
	if(binset_state) {
		cus_binset = &oddmr_data->primary_data->dmr_cus_binset_info;
		DDPMSG("-- DeMura Customize binset info dump --\n");
		DDPMSG("binfile_num=%u binset_num=%u\n",
			cus_binset->binfile_num, cus_binset->binset_num);
		for(i = 0; i < cus_binset->binset_num; i++) {
			DDPMSG("binset%u\n", i);
			DDPMSG("dbv_interval_num: %u\n", cus_binset->binset_list[i].dbv_interval_num);
			result_offset = 0;
			for(j = 0; j < cus_binset->binset_list[i].dbv_interval_num; j++)
				result_offset += sprintf(result + result_offset, "%u ",
					cus_binset->binset_list[i].dbv_interval_node[j]);
			DDPMSG("dbv_interval_node: %s\n", result);
			result_offset = 0;
			for(j = 0; j < cus_binset->binset_list[i].dbv_interval_num; j++)
				result_offset += sprintf(result + result_offset, "%d ",
					cus_binset->binset_list[i].dbv_interval_bin_idx[j]);
				DDPMSG("dbv_interval_node: %s\n", result);
		}
		DDPMSG("binset remap_params:");
		DDPMSG("remap_gain_target_code=%u\n",
			cus_binset->remap_params.remap_gain_target_code);
		result_offset = 0;
		for(i = 0; i < cus_binset->remap_params.remap_reduce_offset_num; i++)
			result_offset += sprintf(result + result_offset, "%u ",
					cus_binset->remap_params.remap_reduce_offset_node[i]);
		DDPMSG("remap_reduce_offset_node: %s\n", result);
		result_offset = 0;
		for(i = 0; i < cus_binset->remap_params.remap_reduce_offset_num; i++)
			result_offset += sprintf(result + result_offset, "%u ",
					cus_binset->remap_params.remap_reduce_offset_value[i]);
		DDPMSG("remap_reduce_offset_value: %s\n", result);

		result_offset = 0;
		for(i = 0; i < cus_binset->remap_params.remap_dbv_gain_num; i++)
			result_offset += sprintf(result + result_offset, "%u ",
					cus_binset->remap_params.remap_dbv_gain_node[i]);
		DDPMSG("remap_dbv_gain_node: %s\n", result);
		result_offset = 0;
		for(i = 0; i < cus_binset->remap_params.remap_dbv_gain_num; i++)
			result_offset += sprintf(result + result_offset, "%u ",
					cus_binset->remap_params.remap_dbv_gain_value[i]);
		DDPMSG("remap_dbv_gain_value: %s\n", result);
		DDPMSG("-- DeMura Customize binset info dump End--");
	}

	setting_state = atomic_read(&oddmr_data->dmr_data.cus_setting_state);
	if(setting_state) {
		cus_setting = &oddmr_data->primary_data->dmr_cus_setting_info;
		DDPMSG("-- DeMura Customize setting info dump --\n");
		DDPMSG("dbv_mode_num=%u\n", cus_setting->dbv_mode_num);
		DDPMSG("default_dbv_mode=%u\n", cus_setting->default_dbv_mode);
		for(i = 0; i < cus_setting->dbv_mode_num; i++) {
			DDPMSG("dbv_mode%u:\n", i);
			result_offset = 0;
			for(j = 0; j < cus_setting->fps_dbv_node[i].DBV_num; j++)
				result_offset += sprintf(result + result_offset, "%d ",
					cus_setting->fps_dbv_node[i].DBV_node[j]);
			DDPMSG("DBV_node: %s\n", result);

			result_offset = 0;
			for(j = 0; j < cus_setting->fps_dbv_node[i].FPS_num;j++)
				result_offset += sprintf(result + result_offset, "%d ",
					cus_setting->fps_dbv_node[i].FPS_node[j]);
			DDPMSG("FPS_node: %s\n", result);

			DDPMSG("remap_gain_target_code=%u\n",
				cus_setting->fps_dbv_node[i].remap_gain_target_code);
			result_offset = 0;
			for(j = 0; j < cus_setting->fps_dbv_node[i].remap_reduce_offset_num; j++)
				result_offset += sprintf(result + result_offset, "%u ",
						cus_setting->fps_dbv_node[i].remap_reduce_offset_node[j]);
			DDPMSG("remap_reduce_offset_node: %s\n", result);
			result_offset = 0;
			for(j = 0; j < cus_setting->fps_dbv_node[i].remap_reduce_offset_num; j++)
				result_offset += sprintf(result + result_offset, "%u ",
						cus_setting->fps_dbv_node[i].remap_reduce_offset_value[j]);
			DDPMSG("remap_reduce_offset_value: %s\n", result);

			result_offset = 0;
			for(j = 0; j < cus_setting->fps_dbv_node[i].remap_dbv_gain_num; j++)
				result_offset += sprintf(result + result_offset, "%u ",
						cus_setting->fps_dbv_node[i].remap_dbv_gain_node[j]);
			DDPMSG("remap_dbv_gain_node: %s\n", result);
			result_offset = 0;
			for(j = 0; j < cus_setting->fps_dbv_node[i].remap_dbv_gain_num; j++)
				result_offset += sprintf(result + result_offset, "%u ",
						cus_setting->fps_dbv_node[i].remap_dbv_gain_value[j]);
			DDPMSG("remap_dbv_gain_value: %s\n", result);

			DDPMSG("reg_num=%u reg_total_count=%u\n",
				cus_setting->fps_dbv_change_cfg[i].reg_num,
				cus_setting->fps_dbv_change_cfg[i].reg_total_count);
			DBV_num = cus_setting->fps_dbv_node[i].DBV_num;
			FPS_num = cus_setting->fps_dbv_node[i].FPS_num;
			result_offset = 0;
			for(j = 0; j < DBV_num * FPS_num; j++) {
				dbv_idx = j / FPS_num;
				fps_idx = j % FPS_num;
				DDPMSG("DBV_node[%u]=%u\n",
					dbv_idx, cus_setting->fps_dbv_node[i].DBV_node[dbv_idx]);
				DDPMSG("FPS_node[%u]=%u\n",
					fps_idx, cus_setting->fps_dbv_node[i].FPS_node[fps_idx]);
				reg_cnt = 0;
				for(k = 0; k < cus_setting->fps_dbv_change_cfg[i].reg_num; k++) {
					reg_cnt++;
					offset = j * cus_setting->fps_dbv_change_cfg[i].reg_num + k;
					value = cus_setting->fps_dbv_change_cfg[i].reg_value[offset];
					result_offset += sprintf(result + result_offset, "%d ", value);
					if(reg_cnt % 7 == 0) {
						DDPMSG("%s\n", result);
						result_offset = 0;
					}
				}
				if(reg_cnt % 7 != 0)
					DDPMSG("%s\n", result);
			}
		}
		DDPMSG("-- DeMura Customize setting info dump End --\n");
	}
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
}

void mtk_disp_oddmr_debug(struct drm_crtc *crtc, const char *opt)
{
	struct mtk_drm_crtc *mtk_crtc = to_mtk_crtc(crtc);
	struct mtk_ddp_comp *comp;
	struct mtk_disp_oddmr *oddmr_data;

	comp = mtk_ddp_comp_sel_in_cur_crtc_path(mtk_crtc, MTK_DISP_ODDMR, 0);
	if (!comp) {
		PC_ERR("%s, comp is null!\n", __func__);
		return;
	}
	oddmr_data = comp_to_oddmr(comp);

	ODDMRFLOW_LOG(":%s\n", opt);
	if (strncmp(opt, "flow_log:", 9) == 0) {
		debug_flow_log = strncmp(opt + 9, "1", 1) == 0;
		ODDMRFLOW_LOG("debug_flow_log = %d\n", debug_flow_log);
	} else if (strncmp(opt, "flow_msg:", 9) == 0) {
		debug_flow_msg = strncmp(opt + 9, "1", 1) == 0;
		ODDMRFLOW_LOG("debug_flow_msg = %d\n", debug_flow_msg);
	} else if (strncmp(opt, "api_log:", 8) == 0) {
		debug_api_log = strncmp(opt + 8, "1", 1) == 0;
		ODDMRFLOW_LOG("debug_api_log = %d\n", debug_api_log);
	} else if (strncmp(opt, "low_log:", 8) == 0) {
		debug_low_log = strncmp(opt + 8, "1", 1) == 0;
		ODDMRFLOW_LOG("debug_low_log = %d\n", debug_low_log);
	} else if (strncmp(opt, "dump_en:", 8) == 0) {
		g_oddmr_dump_en = strncmp(opt + 8, "1", 1) == 0;
		ODDMRFLOW_LOG("g_oddmr_dump_en = %d\n", g_oddmr_dump_en);
	} else if (strncmp(opt, "ddren:", 6) == 0) {
		g_oddmr_ddren = strncmp(opt + 6, "1", 1) == 0;
		ODDMRFLOW_LOG("g_oddmr_ddren = %d\n", g_oddmr_ddren);
	} else if (strncmp(opt, "hrt:", 4) == 0) {
		g_oddmr_hrt_en = strncmp(opt + 4, "1", 1) == 0;
		ODDMRFLOW_LOG("g_oddmr_hrt_en = %d\n", g_oddmr_hrt_en);
	} else if (strncmp(opt, "od_support:", 11) == 0) {
		oddmr_data->primary_data->od_support = strncmp(opt + 11, "1", 1) == 0;
		ODDMRFLOW_LOG("od_support = %d\n", oddmr_data->primary_data->od_support);
	} else if (strncmp(opt, "dmr_support:", 12) == 0) {
		oddmr_data->primary_data->dmr_support = strncmp(opt + 12, "1", 1) == 0;
		ODDMRFLOW_LOG("dmr_support = %d\n", oddmr_data->primary_data->dmr_support);
	} else if (strncmp(opt, "check_trigger:", 14) == 0) {
		unsigned int on, ret;

		ret = sscanf(opt, "check_trigger:%u\n", &on);
		if (ret != 1) {
			ODDMRFLOW_LOG("error to parse cmd %s\n", opt);
			return;
		}
		ODDMRFLOW_LOG("check_trigger = %u\n", on);
		g_od_check_trigger = on;
	} else if (strncmp(opt, "od_fps_mode:", 12) == 0) {
		unsigned int on, ret, val;

		ret = sscanf(opt, "od_fps_mode:%u,%u\n", &on, &val);
		if (ret != 2) {
			ODDMRFLOW_LOG("error to parse cmd %s\n", opt);
			return;
		}
		if (oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE &&
				oddmr_data->primary_data->od_fps_mode != on) {
			ODDMRFLOW_LOG("error: need before od init\n");
			return;
		}
		ODDMRFLOW_LOG("od_fps_mode = %u, od_wait_time = %u\n", on, val);
		oddmr_data->primary_data->od_fps_mode = on;
		if (oddmr_data->primary_data->od_fps_mode == 1) {
			//use defuault 1000/od_min_fps if given 0
			if (val == 0 && oddmr_data->primary_data->od_min_fps != 0)
				val = 1000 / oddmr_data->primary_data->od_min_fps;
			oddmr_data->primary_data->od_wait_time = val;
		}
	} else if (strncmp(opt, "od_merge_lines:", 15) == 0) {
		unsigned int lines, ret;

		ret = sscanf(opt, "od_merge_lines:%u\n", &lines);
		if (ret != 1) {
			ODDMRFLOW_LOG("error to parse cmd %s\n", opt);
			return;
		}
		ODDMRFLOW_LOG("od_merge_lines = %u\n", lines);
		g_od_udma_merge_lines = lines;
	} else if (strncmp(opt, "od_sram_check:", 14) == 0) {
		oddmr_data->od_data.od_sram_check = strncmp(opt + 14, "1", 1) == 0;
		ODDMRFLOW_LOG("od_sram_check:%d\n", oddmr_data->od_data.od_sram_check);
	} else if (strncmp(opt, "oddmr_err_trigger:", 18) == 0) {
		unsigned int val, ret;

		ret = sscanf(opt, "oddmr_err_trigger_mask:%u\n", &val);
		if (ret != 1) {
			ODDMRFLOW_LOG("error to parse cmd %s\n", opt);
			return;
		}
		ODDMRFLOW_LOG("oddmr_err_trigger_mask = %u\n", val);
		oddmr_err_trigger_mask = val;
	} else if (strncmp(opt, "slc_en:", 7) == 0) {
		int idx, en, ret;

		ret = sscanf(opt, "slc_en:%d,%d\n", &idx, &en);
		if (ret != 2) {
			PC_ERR("%d error to parse cmd %s\n", __LINE__, opt);
			return;
		}
		ODDMRFLOW_LOG("slc_en:%d,%d\n", idx, en);
		if (en) {
			oddmr_data->use_slc[idx] = 1;
			disp_oddmr_slc_request(comp, idx);
			disp_oddmr_slc_valid(comp, idx);
		} else
			disp_oddmr_slc_invalid(comp, idx);
	} else if (strncmp(opt, "slc_alloc:", 10) == 0) {
		int period, alloc, ret;

		ret = sscanf(opt, "slc_alloc:%d,%d\n", &alloc, &period);
		if (ret != 2) {
			PC_ERR("%d error to parse cmd %s\n", __LINE__, opt);
			return;
		}
		ODDMRFLOW_LOG("slc_alloc:%d/%d\n", alloc, period);
		g_slc_period = period;
		g_slc_read_alloc = alloc;
	} else if (strncmp(opt, "dbi_update:", 11) == 0) {
		int update, ret;

		ret = sscanf(opt, "dbi_update:%d\n", &update);
		if (ret != 1) {
			PC_ERR("%d error to parse cmd %s\n", __LINE__, opt);
			return;
		}
		ODDMRFLOW_LOG("dbi_update:%d\n", update);
		g_dbi_update = update;
	} else if (strncmp(opt, "debugdump:", 10) == 0) {
		ODDMRFLOW_LOG("debug_flow_log = %d\n", debug_flow_log);
		ODDMRFLOW_LOG("debug_api_log = %d\n", debug_api_log);
		ODDMRFLOW_LOG("debug_low_log = %d\n", debug_low_log);
	} else if (strncmp(opt, "dbv_mode:", 9) == 0) {
		unsigned int dbv_mode;
		int ret;

		ret = sscanf(opt, "dbv_mode:%u\n", &dbv_mode);
		if (ret != 1) {
			PC_ERR("%d error to parse cmd %s\n", __LINE__, opt);
			return;
		}
		ODDMRFLOW_LOG("dbv_mode:%u\n", dbv_mode);
		mtk_oddmr_io_cmd(comp, NULL, ODDMR_DBV_MODE_CHG, &dbv_mode);
	} else if (strncmp(opt, "binset:", 7) == 0) {
		unsigned int binset;
		int ret;

		ret = sscanf(opt, "binset:%d\n", &binset);
		if (ret != 1) {
			PC_ERR("%d error to parse cmd %s\n", __LINE__, opt);
			return;
		}
		ODDMRFLOW_LOG("binset:%d\n", binset);
		mtk_oddmr_io_cmd(comp, NULL, ODDMR_BINSET_CHG, &binset);
	} else if (strncmp(opt, "dmr_customized_info_dump", 7) == 0) {
		ODDMRFLOW_LOG("dump demura customize info\n");
		mtk_oddmr_dmr_cusomize_info_dump(comp);
	} else if (strncmp(opt, "dmr_dump_en:", 12) == 0) {
		bool dmr_dump_en;
		int ret;

		ret = sscanf(opt, "dmr_dump_en:%d\n", &dmr_dump_en);
		if (ret != 1) {
			PC_ERR("%d error to parse cmd %s\n", __LINE__, opt);
			return;
		}
		ODDMRFLOW_LOG("dmr_dump_en:%d\n", dmr_dump_en);
		g_dmr_dump_en = dmr_dump_en;
	}
}

static inline int mtk_oddmr_gain_interpolation(int left_item,
		int tmp_item, int right_item, int left_value, int right_value)
{
	int result;

	if (right_item == left_item)
		return left_value;

	result = (100 * (tmp_item - left_item) / (right_item - left_item) *
			(right_value - left_value) + 100 * left_value)/100;
	return result;
}

static void mtk_oddmr_od_free_buffer(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		if (oddmr_data->od_data.channel != NULL) {
			mtk_drm_gem_free_object(&oddmr_data->od_data.channel->base);
			oddmr_data->od_data.channel = NULL;
		}
	} else {
		if (oddmr_data->od_data.r_channel != NULL) {
			mtk_drm_gem_free_object(&oddmr_data->od_data.r_channel->base);
			oddmr_data->od_data.r_channel = NULL;
		}
		if (oddmr_data->od_data.g_channel != NULL) {
			mtk_drm_gem_free_object(&oddmr_data->od_data.g_channel->base);
			oddmr_data->od_data.g_channel = NULL;
		}
		if (oddmr_data->od_data.b_channel != NULL) {
			mtk_drm_gem_free_object(&oddmr_data->od_data.b_channel->base);
			oddmr_data->od_data.b_channel = NULL;
		}
	}
}
/* channel: 0:B 1:G 2:R */
static int mtk_oddmr_od_get_bpc(uint32_t od_mode, uint32_t channel)
{
	int bpc = 0;

	ODDMRAPI_LOG("+\n");
	switch (od_mode) {
	case OD_MODE_TYPE_RGB444:
	case OD_MODE_TYPE_COMPRESS_12:
		bpc = 4;
		break;
	case OD_MODE_TYPE_RGB565:
		if (channel == 1)
			bpc = 6;
		else
			bpc = 5;
		break;
	case OD_MODE_TYPE_COMPRESS_18:
		bpc = 6;
		break;
	case OD_MODE_TYPE_RGB555:
		bpc = 5;
		break;
	case OD_MODE_TYPE_RGB888:
		bpc = 8;
		break;
	default:
		bpc = 4;
		break;
	}
	return bpc;
}

/*
 * hscaling : 1,2,4; vscaling: 1,2
 * Width = align_up(Width, 8)
 * channel size = align_up(Width / hscaling x bpc, 128) x Height / vscaling / 8
 */
static uint32_t mtk_oddmr_od_get_data_size(struct mtk_ddp_comp *comp, uint32_t width, uint32_t height,
		uint32_t scaling_mode, uint32_t od_mode, uint32_t channel)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t hscaling, vscaling, bpc, size, width_up;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		mtk_oddmr_od_bpp_v(comp, od_mode);
		bpc = oddmr_data->od_data.bpp;
	} else
		bpc = mtk_oddmr_od_get_bpc(od_mode, channel);
	mtk_oddmr_od_get_scaling(scaling_mode, &hscaling, &vscaling);
	width_up = DIV_ROUND_UP(width, 8) * 8;
	size = width / hscaling * bpc;
	size = DIV_ROUND_UP(size, OD_H_ALIGN_BITS);
	size = size * OD_H_ALIGN_BITS * height / vscaling / 8;

	ODDMRLOW_LOG("width %u width_up %u hscaling %u vscaling %u bpc %u\n",
		width, width_up, hscaling, vscaling, bpc);
	ODDMRLOW_LOG("table mode %u channel %u data size %u\n", od_mode, channel, size);
	return size;
}

/*
 * hscaling : 1,2,4; vscaling: 1,2
 * dram_ln_beats = roundup(merge_width*bpc/hscaling/128)
 * long_burst = dram_ln_beats / 16
 * short_burst = dram_ln_beats % 16 > 0 ? 1:0
 * short_size = dram_ln_beats % 16
 * 1. Height / vscaling % merge_lines == 0
 * 2. short_size >= 4 long_burst >= 1x16 + 10
 * 3. select merge_lines with max avg effeciency, min lines
 */
static uint32_t mtk_oddmr_od_get_udma_effi(uint32_t dram_ln_beats)
{
	uint32_t effi_avg, effi_long, effi_short, long_burst, short_burst, short_size;

	ODDMRAPI_LOG("+\n");
	effi_long = g_od_udma_effi[MAX_LONG_BURST_SIZE - 1];
	long_burst = dram_ln_beats / MAX_LONG_BURST_SIZE;
	short_burst = dram_ln_beats % MAX_LONG_BURST_SIZE > 0 ? 1 : 0;
	if (short_burst > 0) {
		short_size = dram_ln_beats % 16;
		effi_short = g_od_udma_effi[short_size - 1];
	} else {
		short_size = 0;
		effi_short = 0;
	}
	effi_avg = (effi_long * long_burst + short_burst * effi_short) / (long_burst + short_burst);
	if (short_size < 4 || long_burst < 1 || (long_burst == 1 && short_size < 10)) {
		ODDMRLOW_LOG("beats %u, burst(16x%u+%u) effi %u skip\n",
			dram_ln_beats, long_burst, short_size, effi_avg);
		effi_avg = 0;
	}
	return effi_avg;
}

static uint32_t mtk_oddmr_od_find_merge_lines(struct mtk_ddp_comp *comp, uint32_t width,
	uint32_t height, uint32_t hscaling, uint32_t vscaling, uint32_t bpc)
{
	uint32_t merge_width, dram_ln_beats, merge_lines;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	if (oddmr_data == NULL)
		return 1;
	if (g_od_udma_merge_lines != 0)
		merge_lines = g_od_udma_merge_lines;
	else if (oddmr_data->data->is_od_merge_lines == false)
		merge_lines = 1;
	else {
		int i, lines, min_lines = 1, effi = 0, max_effi = 0;

		for (i = 2; i < sizeof(g_od_udma_merge_lines_cand) / sizeof(uint32_t); i++) {
			lines = g_od_udma_merge_lines_cand[i];
			if (height / vscaling % lines != 0)
				continue;
			merge_width = DIV_ROUND_UP(width * lines, 8) * 8;
			dram_ln_beats = merge_width * bpc / hscaling;
			dram_ln_beats = DIV_ROUND_UP(dram_ln_beats, 128);
			effi = mtk_oddmr_od_get_udma_effi(dram_ln_beats);
			// will choose more lines if effi raise more than 400
			if (max_effi + 400 < effi) {
				max_effi = effi;
				min_lines = lines;
			}
			ODDMRLOW_LOG("merge_width %u beats %u, (%u, %u),max (%u, %u)\n",
				merge_width, dram_ln_beats, lines, effi, min_lines, max_effi);
		}
		merge_lines = min_lines;
		ODDMRAPI_LOG("find merge_lines %u with effi %u\n", min_lines, max_effi);
	}
	return merge_lines;
}

/*
 * Condition 1: (ln_offset*bpc)%(128*16) = 0
 * Condition 2: ln_offset > (merge_width/hscaling)
 * hscaling : 1,2,4; vscaling: 1,2
 * merge_width = align_up((w+gb)*merge_lines, 8)
 * merge_lines = 8,10,20
 * dram_ln_beats = roundup(merge_width*bpc/hscaling/128)
 * dram_ln_beats_aligned = align_up(dram_ln_beats, 16)
 * ln_offset = dram_ln_beats_aligned * 128 / bpc
 * channel size = dram_ln_beats_aligned*128*Height/vscaling/merge_line/8
 * If is_write == 1, write ln_offset, merge_lines, base_line_jump into od_data
 */
static uint32_t mtk_oddmr_od_get_dram_size(struct mtk_ddp_comp *comp, uint32_t width,
		uint32_t height, uint32_t scaling_mode, uint32_t od_mode, uint32_t channel, int is_write)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t hscaling, vscaling, bpc, size, merge_width, merge_lines;
	uint32_t dram_ln_beats, dram_ln_beats_aligned, ln_offset;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data == NULL)
		return 0;
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		mtk_oddmr_od_bpp_v(comp, od_mode);
		bpc = oddmr_data->od_data.bpp;
	} else
		bpc = mtk_oddmr_od_get_bpc(od_mode, channel);
	mtk_oddmr_od_get_scaling(scaling_mode, &hscaling, &vscaling);
	merge_lines = mtk_oddmr_od_find_merge_lines(comp, width, height, hscaling, vscaling, bpc);
	merge_width = DIV_ROUND_UP(width * merge_lines, 8) * 8;
	dram_ln_beats = merge_width * bpc / hscaling;
	dram_ln_beats = DIV_ROUND_UP(dram_ln_beats, 128);
	dram_ln_beats_aligned = DIV_ROUND_UP(dram_ln_beats, 16) * 16;
	while ((dram_ln_beats_aligned * 128) % bpc != 0)
		dram_ln_beats_aligned += 16;
	ln_offset = dram_ln_beats_aligned * 128 / bpc;
	size = dram_ln_beats_aligned * 128 * height / vscaling / merge_lines / 8;

	if (is_write == 1) {
		oddmr_data->od_data.ln_offset = ln_offset;
		oddmr_data->od_data.merge_lines = merge_lines;
		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			oddmr_data->od_data.base_line_jump =
				dram_ln_beats_aligned * 128 / vscaling / merge_lines / 8;
			ODDMRFLOW_LOG("base_line_jump %u\n", oddmr_data->od_data.base_line_jump);
		}
	}

	ODDMRFLOW_LOG("width %u merge_width %u hscaling %u vscaling %u bpc %u\n",
		width, merge_width, hscaling, vscaling, bpc);
	ODDMRFLOW_LOG("table mode %u channel %u dram size %u\n", od_mode, channel, size);
	ODDMRFLOW_LOG("dram_ln_beats %u dram_ln_beats_aligned %u ln_offset %u\n",
		dram_ln_beats, dram_ln_beats_aligned, ln_offset);
	return size;
}
/*
 *od_dummy_0 = bit0~bit4,bit7 always 1
 *hscaling = hsacling_enable ? (h_2x4x_sel ? 4 : 2) : 1
 *hsize_align = hscaling_en ? (h_2x4x_sel ?
 *      DIV_ROUND_UP(width, 8) * 8 : DIV_ROUND_UP(width, 4) * 4) : width;
 *hsize_scale = hsize_align / hscaling
 *od_dummy_1 = hsize_scale * merge_line
 *vsize_scale = height / vscaling;
 *od_dummy_2 = vsize_scale / merge_lines;
 *od_dummy_3 = merge_line - 1
 */
static void mtk_oddmr_od_dummy(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	uint32_t hscaling, h_2x4x_sel, vscaling, hsize_align, hsize_scale, scaling_mode;
	uint32_t hscaling_en, merge_lines, value, mask, width, height, vsize_scale;

	ODDMRAPI_LOG("+\n");
	if (priv->data->mmsys_id != MMSYS_MT6989)
		return;

	if (oddmr_data == NULL)
		return;

	width = oddmr_data->cfg.comp_in_width;
	height = oddmr_data->cfg.height;
	scaling_mode = od_param->od_basic_info.basic_param.scaling_mode;

	ODDMRFLOW_LOG("scaling_mode %u,width %u\n",scaling_mode,width);
	hscaling_en = (scaling_mode & BIT(0)) ? 1 : 0;
	ODDMRFLOW_LOG("hscaling_en %u\n",hscaling_en);
	vscaling = (scaling_mode & BIT(1)) ? 2 : 1;
	h_2x4x_sel = (scaling_mode & BIT(2)) ? 1 : 0;
	hscaling = hscaling_en ? (h_2x4x_sel ? 4 : 2) : 1;

	hsize_align = hscaling_en ?
		(h_2x4x_sel ?
		DIV_ROUND_UP(width, 8) * 8 : DIV_ROUND_UP(width, 4) * 4)
		: width;
	hsize_scale = hsize_align / hscaling;
	merge_lines = oddmr_data->od_data.merge_lines;

	ODDMRFLOW_LOG("hscaling %u h_2x4x_sel %u hsize_align %u hsize_scale %u merge_lines %u\n",
		hscaling, h_2x4x_sel, hsize_align, hsize_scale, merge_lines);
	value = 0;
	mask = 0;
	SET_VAL_MASK(value, mask, 1, REG_CUR_LINE_BUFFER_DE_2P_ALIGN);
	SET_VAL_MASK(value, mask, 1, REG_UDMA_HSIZE_USER_MODE);
	SET_VAL_MASK(value, mask, 1, REG_UDMA_VSIZE_USER_MODE);
	SET_VAL_MASK(value, mask, 1, REG_HVSP2UDMA_W_LAST_MASK);
	SET_VAL_MASK(value, mask, 1, REG_BUF_LV_INVERSE);
	SET_VAL_MASK(value, mask, 1, REG_BYPASS_MIU2SMI_W_BRIDGE);
	mtk_oddmr_write(comp, value, DISP_ODDMR_OD_DUMMY_0, pkg);

	value = hsize_scale * merge_lines;
	mtk_oddmr_write(comp, value, DISP_ODDMR_OD_DUMMY_1, pkg);
	vsize_scale = height / vscaling;
	value = vsize_scale / merge_lines;
	ODDMRFLOW_LOG("vsize_scale %u, vscaling %u\n", vsize_scale, vscaling);
	mtk_oddmr_write(comp, value, DISP_ODDMR_OD_DUMMY_2, pkg);
	value = merge_lines - 1;
	mtk_oddmr_write(comp, value, DISP_ODDMR_OD_DUMMY_3, pkg);
}

static uint32_t mtk_oddmr_od_find_max_dram_size(struct mtk_ddp_comp *comp,
	uint32_t scaling_mode, uint32_t od_mode)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t width = 0, height = 0, tile_overhead, size_max = 0, size;
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;

	ODDMRAPI_LOG("+\n");
	tile_overhead = oddmr_data->cfg.comp_overhead;
	ODDMRAPI_LOG("tile_overhead %d, avail_modes_num %d\n",
			tile_overhead, mtk_crtc->avail_modes_num);
	if (mtk_crtc->avail_modes_num > 0) {
		int i;

		for (i = 0; i < mtk_crtc->avail_modes_num; i++) {
			struct drm_display_mode *mode = &mtk_crtc->avail_modes[i];

			if (mtk_crtc->is_dual_pipe)
				width = mode->hdisplay / 2 + tile_overhead;
			else
				width = mode->hdisplay;
			height = mode->vdisplay;
			size = mtk_oddmr_od_get_dram_size(comp, width, height,
							scaling_mode, od_mode, 1, 0);
			if (size_max < size)
				size_max = size;
		}
	} else {
		size_max = 0;
		DDPMSG("invalid display mode\n");
	}
	ODDMRFLOW_LOG("find size_max %u\n", size_max);
	return size_max;
}
static void mtk_oddmr_od_alloc_dram_dual(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	uint32_t scaling_mode, size_max, od_mode;
	bool secu;

	ODDMRAPI_LOG("+\n");

	scaling_mode = od_param->od_basic_info.basic_param.scaling_mode;
	od_mode = od_param->od_basic_info.basic_param.od_mode;
	size_max = mtk_oddmr_od_find_max_dram_size(comp, scaling_mode, od_mode);
	ODDMRFLOW_LOG("alloc_dram_size_max, %u\n", size_max);
	if (size_max == 0)
		return;
	secu = mtk_oddmr_is_svp_on_mtee();
	//od do not support secu for short of secu mem
	if (oddmr_data->data != NULL && !oddmr_data->data->is_od_support_sec)
		secu = false;
	//TODO check size, should not be too big
	mtk_oddmr_od_free_buffer(comp);
	if (oddmr_data->data != NULL && oddmr_data->data->od_version >= MTK_OD_V2) {
		oddmr_data->od_data.channel =
			mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
	} else {
		oddmr_data->od_data.b_channel =
			mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
		oddmr_data->od_data.g_channel =
			mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
		oddmr_data->od_data.r_channel =
			mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
	}
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;
		struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

		/* non secure */
		mtk_oddmr_od_free_buffer(comp1);
		if (oddmr1_data->data != NULL && oddmr1_data->data->od_version >= MTK_OD_V2) {
			oddmr1_data->od_data.channel =
				mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
		} else {
			oddmr1_data->od_data.b_channel =
				mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
			oddmr1_data->od_data.g_channel =
				mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
			oddmr1_data->od_data.r_channel =
				mtk_oddmr_load_buffer(&comp->mtk_crtc->base, size_max, NULL, secu);
		}
	}
}

static void mtk_oddmr_od_set_dram(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	dma_addr_t addr = 0;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		if (oddmr_data->od_data.channel != NULL) {
			addr = oddmr_data->od_data.channel->dma_addr;
			if (oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {//OD_PU
				if (oddmr_data->od_data.base_line_jump == 0)
					mtk_oddmr_od_get_dram_size(comp, oddmr_data->cfg.width, oddmr_data->cfg.height,
							od_param->od_basic_info.basic_param.scaling_mode,
							od_param->od_basic_info.basic_param.od_mode, 0, 1);
				ODDMRAPI_LOG("PU=1:  partial_roi.y %d, base_line_jump %d\n",
						oddmr_data->roi_y, oddmr_data->od_data.base_line_jump);
				addr += (dma_addr_t)(oddmr_data->od_data.base_line_jump) * (dma_addr_t)(oddmr_data->roi_y);
			}
			mtk_oddmr_write_mask(comp, addr >> 4, MT6991_DISP_ODDMR_OD_BASE_ADDR_LSB,
				REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
			mtk_oddmr_write_mask(comp, addr >> 20, MT6991_DISP_ODDMR_OD_BASE_ADDR_MSB,
				REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
		} else {
			DDPMSG("%s buffer is invalid\n", __func__);
		}
	} else {
		if ((oddmr_data->od_data.r_channel != NULL) &&
				(oddmr_data->od_data.g_channel != NULL) &&
				(oddmr_data->od_data.b_channel != NULL)) {
			addr = oddmr_data->od_data.r_channel->dma_addr;
			mtk_oddmr_write_mask(comp, addr >> 4, DISP_ODDMR_OD_BASE_ADDR_R_LSB,
					REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
			mtk_oddmr_write_mask(comp, addr >> 20, DISP_ODDMR_OD_BASE_ADDR_R_MSB,
					REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
			addr = oddmr_data->od_data.g_channel->dma_addr;
			mtk_oddmr_write_mask(comp, addr >> 4, DISP_ODDMR_OD_BASE_ADDR_G_LSB,
					REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
			mtk_oddmr_write_mask(comp, addr >> 20, DISP_ODDMR_OD_BASE_ADDR_G_MSB,
					REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
			addr = oddmr_data->od_data.b_channel->dma_addr;
			mtk_oddmr_write_mask(comp, addr >> 4, DISP_ODDMR_OD_BASE_ADDR_B_LSB,
					REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
			mtk_oddmr_write_mask(comp, addr >> 20, DISP_ODDMR_OD_BASE_ADDR_B_MSB,
					REG_FLD_MASK(REG_OD_BASE_ADDR), pkg);
		} else {
			DDPMSG("%s buffer is invalid\n", __func__);
		}
	}
}

static void mtk_oddmr_od_set_dram_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	ODDMRAPI_LOG("+\n");
	mtk_oddmr_od_set_dram(comp, pkg);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_od_set_dram(comp1, pkg);
	}
}

static int mtk_oddmr_od_init_sram(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, int table_idx, int sram_idx)
{
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	struct mtk_oddmr_od_table *table;
	struct mtk_oddmr_pq_pair *param_pq;
	uint8_t *raw_table, tmp_data;
	int channel, srams, cols, rows, raw_idx, i, change_channel;
	uint32_t value, mask, tmp_r_sel, tmp_w_sel, table_size;
	uint32_t sram_write_change;

	ODDMRAPI_LOG("+\n");
	if (!IS_TABLE_VALID(table_idx, od_param->valid_table)) {
		PC_ERR("%s table %d is invalid\n", __func__, table_idx);
		return -EFAULT;
	}
	table = od_param->od_tables[table_idx];
	param_pq = table->pq_od.param;
	raw_table = table->raw_table.value;
	table_size = table->raw_table.size;
	ODDMRAPI_LOG("table_index, table_size, %d, %u\n", table_idx, table_size);
	raw_idx = 0;
	if (table_size < 33 * 33 * 3) {
		PC_ERR("%s table%d size %u is too small\n", __func__, table_idx, table_size);
		return -EFAULT;
	}
	ODDMRAPI_LOG("od_init_sram_pq_count, %d\n", table->pq_od.counts);
	for (i = 0; i < table->pq_od.counts; i++) {
		mtk_oddmr_write(comp, param_pq[i].value, param_pq[i].addr, pkg);
		ODDMRAPI_LOG("i %d, 0x%x 0x%x\n", i, param_pq[i].value, param_pq[i].addr);
	}

	if (priv->data->mmsys_id != MMSYS_MT6897)
		sram_write_change = 1;
	else
		sram_write_change = 0;

	/* B:0-bit1, G:1-bit2, R:2-bit3*/
	for (channel = 0; channel < 3; channel++) {
		/* 1: 17x17 2:16x17 3:17x16 4:16x16*/

		//change begin
		//B:0-bit1, G:1-bit2, R:2-bit3 -->> B:2-bit1, G:1-bit2, R:0-bit3
		ODDMRAPI_LOG("channel %d, sram_write_change %d\n", channel, sram_write_change);
		if(sram_write_change)
			change_channel = channel - (channel-1)*2;
		else
			change_channel = channel;
		//change end

		for (srams = 1; srams < 5; srams++) {
			value = 0;
			mask = 0;
			tmp_w_sel = sram_idx;
			tmp_r_sel = !sram_idx;
			SET_VAL_MASK(value, mask, 1 << (change_channel  + 1), REG_WBGR_OD_SRAM_IO_EN);
			SET_VAL_MASK(value, mask, 0, REG_AUTO_SRAM_ADR_INC_EN);
			SET_VAL_MASK(value, mask, tmp_w_sel, REG_OD_SRAM_WRITE_SEL);
			SET_VAL_MASK(value, mask, tmp_r_sel, REG_OD_SRAM_READ_SEL);
			if (oddmr_data->data->od_version >= MTK_OD_V3)
				SET_VAL_MASK(value, mask, 1, REG_OD_SRAM_READ_BACK_SEL);
			if (oddmr_data->data->od_version >= MTK_OD_V2) {
				SET_VAL_MASK(value, mask, 1, REG_OD_TABLE_DB_EFF_EN);
				mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, mask, pkg);
			} else
				mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_SRAM_CTRL_0, mask, pkg);
			rows = (srams < 3) ? 17 : 16;
			cols = (srams % 2 == 1) ? 17 : 16;
			ODDMRFLOW_LOG("channel%d sram%d size %dx%d\n", change_channel , srams, rows, cols);
			for (i = 0; i < rows * cols; i++) {
				tmp_data = raw_table[raw_idx];
				ODDMRAPI_LOG("od_init_sram_tmp_data, %u\n", tmp_data);
				raw_idx++;
				if (oddmr_data->data->od_version >= MTK_OD_V2) {
					mtk_oddmr_write(comp, tmp_data,
						(MT6991_DISP_ODDMR_OD_SRAM_CTRL_2 + 12 * (srams - 1)), pkg);
					mtk_oddmr_write(comp, 0x8000 | (i & 0x1FF),
						(MT6991_DISP_ODDMR_OD_SRAM_CTRL_1 + 12 * (srams - 1)), pkg);
				} else {
					mtk_oddmr_write(comp, tmp_data,
						(DISP_ODDMR_OD_SRAM_CTRL_2 + 12 * (srams - 1)), pkg);
					mtk_oddmr_write(comp, 0x8000 | (i & 0x1FF),
						(DISP_ODDMR_OD_SRAM_CTRL_1 + 12 * (srams - 1)), pkg);
				}
			}
			value = 0;
			mask = 0;
			SET_VAL_MASK(value, mask, 0, REG_WBGR_OD_SRAM_IO_EN);
			SET_VAL_MASK(value, mask, tmp_w_sel, REG_OD_SRAM_WRITE_SEL);
			SET_VAL_MASK(value, mask, tmp_r_sel, REG_OD_SRAM_READ_SEL);
			SET_VAL_MASK(value, mask, 0, REG_AUTO_SRAM_ADR_INC_EN);
			if (oddmr_data->data->od_version >= MTK_OD_V3)
				SET_VAL_MASK(value, mask, 1, REG_OD_SRAM_READ_BACK_SEL);
			if (oddmr_data->data->od_version >= MTK_OD_V2) {
				SET_VAL_MASK(value, mask, 1, REG_OD_TABLE_DB_EFF_EN);
				mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, mask, pkg);
			} else
				mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_SRAM_CTRL_0, mask, pkg);
		}
		//SET_VAL_MASK(value, mask, 0, REG_FLD(1, channel + 1));
		//mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_SRAM_CTRL_0, mask, pkg);
		//mtk_oddmr_write(comp, 0, DISP_ODDMR_OD_SRAM_CTRL_0, pkg);
		value = 0;
		mask = 0;
		SET_VAL_MASK(value, mask, tmp_w_sel, REG_OD_SRAM_WRITE_SEL);
		SET_VAL_MASK(value, mask, tmp_r_sel, REG_OD_SRAM_READ_SEL);
		if (oddmr_data->data->od_version >= MTK_OD_V3)
			SET_VAL_MASK(value, mask, 1, REG_OD_SRAM_READ_BACK_SEL);
		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			SET_VAL_MASK(value, mask, 1, REG_OD_TABLE_DB_EFF_EN);
			mtk_oddmr_write(comp, value, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
		} else
			mtk_oddmr_write(comp, value, DISP_ODDMR_OD_SRAM_CTRL_0, NULL);

	}
	return 0;
}

int mtk_oddmr_od_init_sram_dual(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *pkg, int table_idx, int sram_idx)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int ret;

	ODDMRAPI_LOG("+\n");
	ret = mtk_oddmr_od_init_sram(comp, pkg, table_idx, sram_idx);
	if (ret >= 0)
		oddmr_data->od_data.od_sram_table_idx[sram_idx] = table_idx;
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;
		struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

		ret = mtk_oddmr_od_init_sram(comp1, pkg, table_idx, sram_idx);
		if (ret >= 0)
			oddmr1_data->od_data.od_sram_table_idx[sram_idx] = table_idx;
	}
	ODDMRAPI_LOG("sram_idx %d, table_idx %d\n",
			sram_idx, oddmr_data->od_data.od_sram_table_idx[sram_idx]);
	return ret;
}

/* find max and min fps of all tables */
static void mtk_oddmr_od_table_fps_minmax(struct mtk_disp_oddmr *oddmr_data)
{
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	int idx;
	uint32_t min_fps = 10000;
	uint32_t max_fps = 0;
	uint32_t cnts = od_param->od_basic_info.basic_param.table_cnt;

	for (idx = 0; idx < cnts; idx++) {
		if (IS_TABLE_VALID(idx, od_param->valid_table)) {
			if (min_fps > od_param->od_tables[idx]->table_basic_info.min_fps)
				min_fps = od_param->od_tables[idx]->table_basic_info.min_fps;
			if (max_fps < od_param->od_tables[idx]->table_basic_info.max_fps)
				max_fps = od_param->od_tables[idx]->table_basic_info.max_fps;
			ODDMRAPI_LOG("table_idx %d,min_fps:%d,max_fps:%d\n", idx,
			od_param->od_tables[idx]->table_basic_info.min_fps,
			od_param->od_tables[idx]->table_basic_info.max_fps);
		}
	}
	if (min_fps == 0) {
		ODDMRAPI_LOG("error: od_min_fps=0, use 1 instead");
		min_fps = 1;
	}
	oddmr_data->primary_data->od_min_fps = min_fps;
	oddmr_data->primary_data->od_max_fps = max_fps;
	ODDMRAPI_LOG("od_min_fps %d, od_max_fps %d\n", min_fps, max_fps);
}

static int _mtk_oddmr_od_table_lookup(struct mtk_disp_oddmr *oddmr_data,
		struct mtk_oddmr_timing *cur_timing)
{
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	int idx;
	unsigned int fps = cur_timing->vrefresh;
	unsigned int dbv = cur_timing->bl_level;
	uint32_t cnts = od_param->od_basic_info.basic_param.table_cnt;

	for (idx = 0; idx < cnts; idx++) {
		if ((IS_TABLE_VALID(idx, od_param->valid_table)) &&
			(fps >= od_param->od_tables[idx]->table_basic_info.min_fps) &&
			(fps <= od_param->od_tables[idx]->table_basic_info.max_fps) &&
			(!oddmr_data->data->is_od_table_bl_chg || (oddmr_data->data->is_od_table_bl_chg &&
			(dbv >= od_param->od_tables[idx]->table_basic_info.min_dbv) &&
			(dbv <= od_param->od_tables[idx]->table_basic_info.max_dbv)))) {
			ODDMRFLOW_LOG("table_idx %d,is_4_tab:%d,min_fps:%d,max_fps:%d,min_dbv:%d,max_dbv:%d\n", idx,
			oddmr_data->data->is_od_table_bl_chg,
			od_param->od_tables[idx]->table_basic_info.min_fps,
			od_param->od_tables[idx]->table_basic_info.max_fps,
			od_param->od_tables[idx]->table_basic_info.min_dbv,
			od_param->od_tables[idx]->table_basic_info.max_dbv);
		break;
		}
	}

	if ((idx == cnts) ||
			!IS_TABLE_VALID(idx, od_param->valid_table)) {
		ODDMRFLOW_LOG("not find table!\n");
		idx = -1;
	}
	ODDMRFLOW_LOG("expected table%d\n", idx);
	return idx;
}
/*
 *table_idx: output table_idx found
 *return 0: state cur sram (current sram matches or another sram is still updating)
 *       1: flip sram (another sram matches)
 *		 2: update sram table (both srams do not match)
 *       3: force flip sram (in content fps mode, avoid sram keep updating)
 *       4: table still updating
 */
static int mtk_oddmr_od_table_lookup(struct mtk_disp_oddmr *oddmr_data,
		struct mtk_oddmr_timing *cur_timing, int *table_idx, bool check_force_flip)
{
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	int tmp_table_idx, tmp1_table_idx, tmp_sram_idx, ret;
	int sram_table_idx, sram1_table_idx;

	ODDMRAPI_LOG("fps %u,dbv %d\n", cur_timing->vrefresh, cur_timing->bl_level);
	if (oddmr_data->od_data.od_sram_read_sel < 0 ||
			oddmr_data->od_data.od_sram_table_idx[0] < 0) {
		PC_ERR("%s od is not init properly\n", __func__);
		return -EFAULT;
	}
	// fps quick check
	if (cur_timing->vrefresh < oddmr_data->primary_data->od_min_fps ||
			cur_timing->vrefresh > oddmr_data->primary_data->od_max_fps) {
		ODDMRFLOW_LOG("fps %u out of range\n", cur_timing->vrefresh);
		return -EFAULT;
	}
	tmp_sram_idx = oddmr_data->od_data.od_sram_read_sel;
	ODDMRFLOW_LOG("%d,tmp_sram_idx %d\n", __LINE__,tmp_sram_idx);
	sram_table_idx = oddmr_data->od_data.od_sram_table_idx[!!tmp_sram_idx];
	sram1_table_idx = oddmr_data->od_data.od_sram_table_idx[!tmp_sram_idx];
	ODDMRFLOW_LOG("%d,sram %d,sram1 %d\n", __LINE__,sram_table_idx,sram1_table_idx);
	tmp_table_idx = oddmr_data->od_data.od_dram_sel[sram_table_idx];
	tmp1_table_idx = oddmr_data->od_data.od_dram_sel[sram1_table_idx];
	ODDMRFLOW_LOG("%d,dram %d,dram1 %d\n", __LINE__,tmp_table_idx,tmp1_table_idx);
	/* best stay at current table */
	if ((IS_TABLE_VALID(tmp_table_idx, od_param->valid_table)) &&
	(cur_timing->vrefresh >= od_param->od_tables[tmp_table_idx]->table_basic_info.min_fps) &&
	(cur_timing->vrefresh <= od_param->od_tables[tmp_table_idx]->table_basic_info.max_fps) &&
	(!oddmr_data->data->is_od_table_bl_chg || //if is_od_table_bl_chg = 1, need judge bl_level
	(oddmr_data->data->is_od_table_bl_chg &&
	(cur_timing->bl_level >= od_param->od_tables[tmp_table_idx]->table_basic_info.min_dbv) &&
	(cur_timing->bl_level <= od_param->od_tables[tmp_table_idx]->table_basic_info.max_dbv)))) {
		*table_idx = tmp_table_idx;
		ODDMRFLOW_LOG("No change: use table%d\n", *table_idx);
		return 0;
	}
	//if od in updating, used old table before updata table finish
	if (oddmr_data->primary_data->od_state == ODDMR_TABLE_UPDATING) {
		*table_idx = tmp_table_idx;
		ODDMRFLOW_LOG("TABLE_UPDATING: use table%d\n", *table_idx);
		if (oddmr_data->data->od_version >= MTK_OD_V2)
			oddmr_data->od_update_sram = 1;
		return 4;
	}

	/* second best just flip sram */
	if ((IS_TABLE_VALID(tmp1_table_idx, od_param->valid_table)) &&
	(cur_timing->vrefresh >= od_param->od_tables[tmp1_table_idx]->table_basic_info.min_fps) &&
	(cur_timing->vrefresh <= od_param->od_tables[tmp1_table_idx]->table_basic_info.max_fps) &&
	(!oddmr_data->data->is_od_table_bl_chg || //if is_od_table_bl_chg = 1, need judge bl_level
	(oddmr_data->data->is_od_table_bl_chg &&
	(cur_timing->bl_level >= od_param->od_tables[tmp1_table_idx]->table_basic_info.min_dbv) &&
	(cur_timing->bl_level <= od_param->od_tables[tmp1_table_idx]->table_basic_info.max_dbv)))) {
		*table_idx = tmp1_table_idx;
		ODDMRFLOW_LOG("Flip sram: use table%d\n", *table_idx);
		CRTC_MMP_MARK(0, oddmr_ctl, 0xf, tmp1_table_idx);
		return 1;
	}

	/* worst case should update table */
	ret = _mtk_oddmr_od_table_lookup(oddmr_data,cur_timing);
	if (ret >= 0 && oddmr_data->data->is_od_table_bl_chg) {
		//In content fps mode, force sram flip instead of updating sram again,
		//if sram was just updated previously but now both srams do not match.
		if (check_force_flip) {
			*table_idx = tmp1_table_idx;
			ODDMRFLOW_LOG("Force flip sram: use table%d\n", *table_idx);
			CRTC_MMP_MARK(0, oddmr_ctl, 0xe, tmp1_table_idx);
			return 3;
		}

		*table_idx = tmp_table_idx; //used table not change before updata table finish
		od_param->updata_dram_table = ret;
		ODDMRFLOW_LOG("update table fps %u, vrefresh %u, table_idx %d sram(%d %d); use table%d\n",
				cur_timing->vrefresh, cur_timing->vrefresh,
				ret, oddmr_data->od_data.od_dram_sel[0],
				oddmr_data->od_data.od_dram_sel[1], *table_idx);
		CRTC_MMP_MARK(0, oddmr_ctl, 0xc, tmp_table_idx);
		return 2;
	}
	ODDMRFLOW_LOG("fps %u bl %u out of range\n", cur_timing->vrefresh, cur_timing->bl_level);
	return -EFAULT;
}

static void mtk_oddmr_common_gain_lookup(struct mtk_disp_oddmr *oddmr_data,
	int item, void *table, uint32_t cnt, int *result)
{
	int i, left_value, right_value, left_item, right_item, tmp_item;
	struct mtk_oddmr_table_gain *gain_table;

	ODDMRAPI_LOG("cnt %u\n", cnt);
	gain_table = (struct mtk_oddmr_table_gain *)table;
	tmp_item = item;

	if (oddmr_data->data->od_version >= MTK_OD_V3) {
		if (tmp_item < gain_table[0].item) {
			if (tmp_item != 0)
				ODDMRFLOW_LOG("item %d outof range (%u, %u)\n", tmp_item,
						gain_table[0].item, gain_table[cnt - 1].item);
			result[0] = 0;
			result[1] = 0;
			result[2] = 0;
			return;
		}
		if (tmp_item == gain_table[0].item) {
			result[0] = gain_table[0].value_r;
			result[1] = gain_table[0].value;
			result[2] = gain_table[0].value_b;
			ODDMRFLOW_LOG("R: L:(%d,%d) V:(%d,%d)\n", tmp_item, result[0], tmp_item, result[0]);
			ODDMRFLOW_LOG("G: L:(%d,%d) V:(%d,%d)\n", tmp_item, result[1], tmp_item, result[1]);
			ODDMRFLOW_LOG("B: L:(%d,%d) V:(%d,%d)\n", tmp_item, result[2], tmp_item, result[2]);
			return;
		}
		for (i = 1; i < cnt; i++) {
			if (tmp_item <= gain_table[i].item)
				break;
		}
		if (i >= cnt) {
			result[0] = 0;
			result[1] = 0;
			result[2] = 0;
			ODDMRFLOW_LOG("item %u outof range (%u, %u)\n", tmp_item,
					gain_table[0].item, gain_table[cnt - 1].item);
		} else {
			//to cover negative value in calculate
			left_item = (int)gain_table[i - 1].item;
			right_item = (int)gain_table[i].item;
			//R
			left_value = (int)gain_table[i - 1].value_r;
			right_value = (int)gain_table[i].value_r;
			result[0] = mtk_oddmr_gain_interpolation(left_item, tmp_item, right_item,
					left_value, right_value);
			ODDMRFLOW_LOG("R: idx %d L:(%d,%d),R:(%d,%d) V:(%d,%d)\n", i,
					left_item, left_value, right_item, right_value, tmp_item, result[0]);
			//G
			left_value = (int)gain_table[i - 1].value;
			right_value = (int)gain_table[i].value;
			result[1] = mtk_oddmr_gain_interpolation(left_item, tmp_item, right_item,
					left_value, right_value);
			ODDMRFLOW_LOG("G: idx %d L:(%d,%d),R:(%d,%d) V:(%d,%d)\n", i,
					left_item, left_value, right_item, right_value, tmp_item, result[1]);
			//B
			left_value = (int)gain_table[i - 1].value_b;
			right_value = (int)gain_table[i].value_b;
			result[2] = mtk_oddmr_gain_interpolation(left_item, tmp_item, right_item,
					left_value, right_value);
			ODDMRFLOW_LOG("B: idx %d L:(%d,%d),R:(%d,%d) V:(%d,%d)\n", i,
					left_item, left_value, right_item, right_value, tmp_item, result[2]);
		}
		return;
	}

	if (tmp_item < gain_table[0].item) {
		if (tmp_item != 0)
			ODDMRFLOW_LOG("item %d outof range (%u, %u)\n", tmp_item,
					gain_table[0].item, gain_table[cnt - 1].item);
		result[1] = 0;
		return;
	}
	if (tmp_item == gain_table[0].item) {
		result[1] = gain_table[0].value;
		ODDMRFLOW_LOG("L:(%d,%d) V:(%d,%d)\n",
			gain_table[0].item, gain_table[0].value, tmp_item, result[1]);
		return;
	}
	for (i = 1; i < cnt; i++) {
		if (tmp_item <= gain_table[i].item)
			break;
	}
	if (i >= cnt) {
		result[1] = 0;
		ODDMRFLOW_LOG("item %u outof range (%u, %u)\n", tmp_item,
				gain_table[0].item, gain_table[cnt - 1].item);
	} else {
		//to cover negative value in calculate
		left_value = (int)gain_table[i - 1].value;
		right_value = (int)gain_table[i].value;
		left_item = (int)gain_table[i - 1].item;
		right_item = (int)gain_table[i].item;
		result[1] = mtk_oddmr_gain_interpolation(left_item, tmp_item, right_item,
				left_value, right_value);
		ODDMRFLOW_LOG("idx %d L:(%d,%d),R:(%d,%d) V:(%d,%d)\n", i,
				left_item, left_value, right_item, right_value, tmp_item, result[1]);
	}
	return;
}

static int mtk_oddmr_od_gain_lookup(struct mtk_ddp_comp *comp,
	uint32_t fps, uint32_t dbv, int table_idx, uint32_t *weight)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	int result_fps[3] = {0}, result_dbv[3] = {0}, tmp_item, channel;
	uint32_t cnt, result;
	uint32_t user_gain = oddmr_data->od_user_gain;
	struct mtk_oddmr_table_gain *bl_gain_table;
	struct mtk_oddmr_table_gain *fps_gain_table;

	ODDMRAPI_LOG("fps %u, dbv %u, table%d\n", fps, dbv, table_idx);
	if (!IS_TABLE_VALID(table_idx, od_param->valid_table)) {
		weight[0] = 0;
		weight[1] = 0;
		weight[2] = 0;
		PC_ERR("%s table%d is invalid\n", __func__, table_idx);
		return -EFAULT;
	}
	/*fps*/
	cnt = od_param->od_tables[table_idx]->fps_cnt;
	fps_gain_table = od_param->od_tables[table_idx]->fps_table;
	tmp_item = (int)fps;
	mtk_oddmr_common_gain_lookup(oddmr_data, tmp_item, fps_gain_table, cnt, result_fps);
	/* dbv */
	cnt = od_param->od_tables[table_idx]->bl_cnt;
	bl_gain_table = od_param->od_tables[table_idx]->bl_table;
	tmp_item = (int)dbv;
	mtk_oddmr_common_gain_lookup(oddmr_data, tmp_item, bl_gain_table, cnt, result_dbv);

	for (channel = 0; channel < 3; channel++) {
		if (oddmr_data->data->od_version < MTK_OD_V3 && channel != 1)
			continue;
		result = ((uint32_t)result_dbv[channel] * (uint32_t)result_fps[channel] + 32) / 64;
		result = (result * user_gain + 32) / 64;
		if (result > 255)
			result = 255;
		weight[channel] = result;
		ODDMRAPI_LOG("channel %d: dbv_gain %d, fps_gain %d, user_gain %d weight %d\n",
			channel, result_dbv[channel], result_fps[channel], user_gain, result);
	}
	return 0;
}

static void mtk_oddmr_od_smi(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	uint32_t value, mask, buf_size;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
	if (priv->data->mmsys_id == MMSYS_MT6897 || priv->data->mmsys_id == MMSYS_MT6985)
		return;
	ODDMRAPI_LOG("+\n");
	if (oddmr_data->data->od_version >= MTK_OD_V3) {
		/* odr*/
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 2, REG_ODR_RE_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 1, REG_ODR_STASH_ULTRA_RE_FRCE);
		mtk_oddmr_write_mask(comp, value, MT6993_DISP_ODDMR_SMI_SB_FLG_ODR, mask, pkg);
		/* odw*/
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 2, REG_ODW_WR_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 1, REG_ODW_STASH_ULTRA_WR_FRCE);
		mtk_oddmr_write_mask(comp, value, MT6993_DISP_ODDMR_SMI_SB_FLG_ODW, mask, pkg);
	} else if (oddmr_data->data->od_version == MTK_OD_V2) {
		/* odr*/
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 4, REG_ODR_RE_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 0, MT6991_OD_REG_ODR_POACH_CFG_OFF);
		mtk_oddmr_write_mask(comp, value, MT6991_OD_DISP_ODDMR_SMI_SB_FLG_ODR_8, mask, pkg);
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_READ_IN_PRE_ULTRA,
				MT6991_OD_REG_REQ_PREULTRA_RISE_LV);//read in pre-ultra
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_READ_OUT_PRE_ULTRA,
				MT6991_OD_REG_REQ_PREULTRA_FALL_LV);//read out pre-ultra
		mtk_oddmr_write_mask(comp, value, MT6991_OD_DISP_ODDMR_UDMA_R_CTRL21, mask, pkg);
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_READ_IN_ULTRA,
				MT6991_OD_REG_REQ_ULTRA_RISE_LV);//read in ultra
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_READ_OUT_ULTRA,
				MT6991_OD_REG_REQ_ULTRA_FALL_LV);//read out ultra
		mtk_oddmr_write_mask(comp, value, MT6991_OD_DISP_ODDMR_UDMA_R_CTRL22, mask, pkg);

		/* odw*/
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 4, REG_ODW_WR_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 0, MT6991_OD_REG_ODW_POACH_CFG_OFF);
		mtk_oddmr_write_mask(comp, value, MT6991_OD_DISP_ODDMR_SMI_SB_FLG_ODW_8, mask, pkg);
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_WRITE_IN_PRE_ULTRA,
				MT6991_OD_REG_REQ_PREULTRA_RISE_LV);//write in pre-ultra
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_WRITE_OUT_PRE_ULTRA,
				MT6991_OD_REG_REQ_PREULTRA_FALL_LV);//write out pre-ultra
		mtk_oddmr_write_mask(comp, value, MT6991_OD_DISP_ODDMR_UDMA_W_CTR_15, mask, pkg);
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_WRITE_IN_ULTRA,
				MT6991_OD_REG_REQ_ULTRA_RISE_LV);//write in ultra
		SET_VAL_MASK(value, mask, MT6991_OD_ODDMR_WRITE_OUT_ULTRA,
				MT6991_OD_REG_REQ_ULTRA_FALL_LV);//write out ultra
		mtk_oddmr_write_mask(comp, value, MT6991_OD_DISP_ODDMR_UDMA_W_CTR_16, mask, pkg);
		ODDMRAPI_LOG("od_smi, %u\n", 66);
	} else {
		value = 0;
		mask = 0;
		/* odr*/
		SET_VAL_MASK(value, mask, 4, REG_ODR_RE_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 0, REG_ODR_POACH_CFG_OFF);
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODR_8, mask, pkg);
		buf_size = oddmr_data->data->odr_buffer_size;
		value = ODDMR_READ_IN_PRE_ULTRA(buf_size);//read in pre-ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODR_0, 0xFFFF, pkg);
		value = ODDMR_READ_IN_ULTRA(buf_size);//read in ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODR_4, 0xFFFF, pkg);
		value = ODDMR_READ_OUT_PRE_ULTRA(buf_size);//read out pre-ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODR_2, 0xFFFF, pkg);
		value = ODDMR_READ_OUT_ULTRA(buf_size);//read out ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODR_6, 0xFFFF, pkg);
		value = 0;
		mask = 0;
		/* odw*/
		SET_VAL_MASK(value, mask, 4, REG_ODW_WR_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 0, REG_ODW_POACH_CFG_OFF);
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODW_8, mask, pkg);
		buf_size = oddmr_data->data->odw_buffer_size;
		value = ODDMR_WRITE_IN_PRE_ULTRA(buf_size);//write in pre-ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODW_0, 0xFFFF, pkg);
		value = ODDMR_WRITE_IN_ULTRA(buf_size);//write in ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODW_4, 0xFFFF, pkg);
		value = ODDMR_WRITE_OUT_PRE_ULTRA(buf_size);//write out pre-ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODW_2, 0xFFFF, pkg);
		value = ODDMR_WRITE_OUT_ULTRA(buf_size);//write out ultra
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_SMI_SB_FLG_ODW_6, 0xFFFF, pkg);
	}
}


static void mtk_oddmr_dmr_smi(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	uint32_t value, mask, buf_size, smi_level;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	/* dmr */
	value = 0;
	mask = 0;
	if (oddmr_data->data->dbi_version == MTK_DBI_V3) {
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 2, MT6993_REG_DMR_RE_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 1, MT6993_REG_DMR_STASH_ULTRA_RE_FRCE);
		mtk_oddmr_write_mask(comp, value, MT6993_DISP_ODDMR_SMI_SB_FLG_DMR, mask, pkg);
		return;
	}
	value = 0; mask = 0;
	SET_VAL_MASK(value, mask, 4, MT6991_REG_DMR_RE_ULTRA_MODE);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_SMI_SB_FLG_DMR, mask, pkg);
	buf_size = oddmr_data->data->dmr_buffer_size;
	value = 0; mask = 0;
	smi_level = MT6991_ODDMR_DMR_PRE_ULTRA_RISE_LV(buf_size);//pre-ultra rise level
	SET_VAL_MASK(value, mask, smi_level, MT6991_REG_DMR_REQ_PREULTRA_RISE_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DMR_CTRL21,
		mask, pkg);
	value = 0; mask = 0;
	smi_level = MT6991_ODDMR_DMR_PRE_ULTRA_FAIL_LV(buf_size);//pre-ultra fail level
	SET_VAL_MASK(value, mask, smi_level, MT6991_REG_DMR_REQ_PREULTRA_FAIL_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DMR_CTRL21,
		mask, pkg);
	value = 0; mask = 0;
	smi_level = MT6991_ODDMR_DMR_ULTRA_RISE_LV(buf_size);//ultra rise level
	SET_VAL_MASK(value, mask, smi_level, MT6991_REG_DMR_REQ_ULTRA_RISE_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DMR_CTRL22,
		mask, pkg);
	value = 0; mask = 0;
	smi_level = MT6991_ODDMR_DMR_ULTRA_FAIL_LV(buf_size);//ultra fail level
	SET_VAL_MASK(value, mask, smi_level, MT6991_REG_DMR_REQ_ULTRA_FAIL_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DMR_CTRL22,
		mask, pkg);
	value = 0; mask = 0;
	SET_VAL_MASK(value, mask, 0x8000, MT6991_REG_DMR_GUSER_CTRL_1);
	mtk_oddmr_write_mask(comp, value, MT6991_ODDMR_SMI_SB_FLG_ODR_3,
		mask, pkg);
}

static void mtk_oddmr_dbi_smi(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	uint32_t value, mask, buf_size;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	/* dbir */
	value = 0;
	mask = 0;
	if(oddmr_data->data->dbi_version == MTK_DBI_V3) {
		SET_VAL_MASK(value, mask, 2, MT6993_REG_DBI_RE_ULTRA_MODE);
		SET_VAL_MASK(value, mask, 1, MT6993_REG_DBI_STASH_ULTRA_RE_FRCE);
		mtk_oddmr_write_mask(comp, value, MT6993_DISP_ODDMR_SMI_SB_FLG_DBI, mask, pkg);
	} else {
		SET_VAL_MASK(value, mask, 4, MT6991_REG_DBI_RE_ULTRA_MODE);
		mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_SMI_SB_FLG_DBI, mask, pkg);
	}
	buf_size = oddmr_data->data->dbir_buffer_size;
	value = MT6991_ODDMR_PRE_ULTRA_RISE_LV(buf_size);//pre-ultra rise level
	SET_VAL_MASK(value, mask, value, MT6991_REG_DBI_REQ_PREULTRA_RISE_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DBI_CTRL21,
		mask, pkg);
	value = MT6991_ODDMR_PRE_ULTRA_FAIL_LV(buf_size);//pre-ultra fail level
	SET_VAL_MASK(value, mask, value, MT6991_REG_DBI_REQ_PREULTRA_FAIL_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DBI_CTRL21,
		mask, pkg);
	value = MT6991_ODDMR_ULTRA_RISE_LV(buf_size);//ultra rise level
	SET_VAL_MASK(value, mask, value, MT6991_REG_DBI_REQ_ULTRA_RISE_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DBI_CTRL22,
		mask, pkg);
	value = MT6991_ODDMR_ULTRA_FAIL_LV(buf_size);//ultra fail level
	SET_VAL_MASK(value, mask, value, MT6991_REG_DBI_REQ_ULTRA_FAIL_LV);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_UDMA_DBI_CTRL22,
		mask, pkg);
	value = 0x8000;
	SET_VAL_MASK(value, mask, value, MT6991_REG_DBI_GUSER_CTRL_1);
	mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_SMI_SB_FLG_ODR_1,
			mask, pkg);
}

static void mtk_oddmr_od_smi_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	mtk_oddmr_od_smi(comp, pkg);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_od_smi(comp1, pkg);
	}
}

//static void mtk_oddmr_dmr_smi_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
//{
//	mtk_oddmr_dmr_smi(comp, pkg);
//	if (comp->mtk_crtc->is_dual_pipe) {
//		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
//		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

//		mtk_oddmr_dmr_smi(comp1, pkg);
//	}
//}

//static void mtk_oddmr_dbi_smi_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
//{
//	mtk_oddmr_dbi_smi(comp, pkg);
//	if (comp->mtk_crtc->is_dual_pipe) {
//		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
//		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

//		mtk_oddmr_dbi_smi(comp1, pkg);
//	}
//}

static void mtk_oddmr_od_set_res_udma_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	mtk_oddmr_od_set_res_udma(comp, pkg);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_od_set_res_udma(comp1, pkg);
	}
}

static void mtk_oddmr_dmr_free_table(unsigned int idx,
	struct mtk_ddp_comp *comp, struct mtk_drm_dmr_cfg_info *dmr_cfg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int i, j;

	ODDMRAPI_LOG("+\n");
	for(i = 0; i < DMR_DBV_TABLE_MAX; i++) {
		for(j = 0; j < DMR_FPS_TABLE_MAX; j++) {
			if (oddmr_data->dmr_data.mura_table[idx][i][j] != NULL) {
				mtk_drm_gem_free_object(&oddmr_data->dmr_data.mura_table[idx][i][j]->base);
				oddmr_data->dmr_data.mura_table[idx][i][j] = NULL;
			}
		}
	}
}

static int mtk_oddmr_dmr_alloc_table(struct mtk_ddp_comp *comp, unsigned int idx,
	struct mtk_drm_dmr_cfg_info *dmr_cfg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t size;
	void *addr ;
	int ret = -EFAULT;
	int i,j;
	struct mtk_drm_gem_obj *gem = NULL;
	unsigned int dmr_ln_offset = 2048;
	unsigned int dma_buffer_size = 0;

	ODDMRAPI_LOG("+\n");

	if(!dmr_cfg_info) {
		ODDMRFLOW_LOG("%s alloc dmr table fail\n", __func__);
		return ret;
	}

	size = dmr_cfg_info->table_index.table_byte_num;

	for(i=0;i < dmr_cfg_info->table_index.DBV_table_num ;i++) {
		for(j=0;j<dmr_cfg_info->table_index.FPS_table_num;j++) {
			if(dmr_cfg_info->table_index.DC_table_flag)
				addr = dmr_cfg_info->table_content.table_single_DC + i*j*size +j*size;
			else
				addr = dmr_cfg_info->table_content.table_single + i*j*size +j*size;
			ODDMRFLOW_LOG("load_buffer i:%d, j:%d\n", i,j);
			dmr_ln_offset = dmr_cfg_info->dmr_pu_info.compression_mode_ln_offset;
			dma_buffer_size = size;
			if (dmr_ln_offset != 0 && dma_buffer_size % dmr_ln_offset != 0)
				PC_ERR("%s dmr table size does not align to ln_offset\n", __func__);
			gem = mtk_drm_gem_create(comp->mtk_crtc->base.dev,
				(dma_buffer_size + DMR_LN_OFFSET), true);
			if (!gem) {
				PC_ERR("%s gem create fail\n", __func__);
				return -EFAULT;
			}
			DDPMSG("%s gem create %p iommu %llx user_addr %p dma_buffer_size %u\n", __func__,
				gem->kvaddr, gem->dma_addr, addr, dma_buffer_size);
			if (addr != NULL)
				memcpy(gem->kvaddr, addr, size);
			oddmr_data->dmr_data.mura_table[idx][i][j] = gem;
			if(!(oddmr_data->dmr_data.mura_table[idx][i][j]))
				ODDMRFLOW_LOG("%s alloc dmr table fail dbv:%d,fps:%d\n", __func__, i,j);
		}
	}
	ret = 0;
	return ret;
}

static int mtk_oddmr_dbi_fps_lookup(unsigned int fps, struct mtk_drm_dbi_cfg_info *cfg_info,
	unsigned int *fps_node)
{
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node;
	unsigned int fps_node_tmp;
	int i;

	ODDMRAPI_LOG("+\n");

	if(!cfg_info) {
		ODDMRFLOW_LOG("dmr config info is NULL\n");
		return -1;
	}

	if(!(cfg_info->fps_dbv_node.FPS_node)) {
		ODDMRFLOW_LOG("dmr config info:FPS_node is NULL\n");
		return -1;
	}

	fps_dbv_node = &cfg_info->fps_dbv_node;

	if(fps_dbv_node->FPS_num == 0) {
		ODDMRFLOW_LOG("dmr fps node number is 0\n");
		return -1;
	}

	//dmr fps node lookup
	for(i = 0; i < fps_dbv_node->FPS_num; i++) {
		if(fps < fps_dbv_node->FPS_node[i])
			break;
	}

	if(i >= fps_dbv_node->FPS_num)
		fps_node_tmp = fps_dbv_node->FPS_num -1;
	else
		fps_node_tmp = (i>0)?(i-1):i;

	*fps_node = fps_node_tmp;

	for(i = 0; i < fps_dbv_node->FPS_num; i++)
		ODDMRFLOW_MSG("dbi_node_num:%d, fps_node%d:%d\n",
			fps_dbv_node->FPS_num, i, fps_dbv_node->FPS_node[i]);

	ODDMRFLOW_MSG("dbi_current_fps:%d,fps_node:%d\n",
		fps,*fps_node);

	return 0;
}


static int mtk_oddmr_dmr_fps_lookup(unsigned int fps, struct mtk_drm_dmr_cfg_info *cfg_info,
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node, unsigned int *fps_table_idx,
	unsigned int *fps_node)
{
	struct mtk_drm_dmr_table_index *table_index;
	unsigned int fps_table_idx_tmp;
	unsigned int fps_node_tmp;
	int i;

	ODDMRAPI_LOG("+\n");

	if(!cfg_info) {
		ODDMRFLOW_LOG("dmr config info is NULL\n");
		return -1;
	}

	if(!(cfg_info->table_index.FPS_table_idx)) {
		ODDMRFLOW_LOG("dmr config info:FPS_table_idx is NULL\n");
		return -1;
	}

	table_index = &cfg_info->table_index;
	if(table_index->FPS_table_num == 0) {
		ODDMRFLOW_LOG("dmr fps table number is 0\n");
		return -1;
	}

	if(!fps_dbv_node) {
		ODDMRFLOW_LOG("fps_dbv_node is NULL\n");
		return -1;
	}

	if(fps_dbv_node->FPS_num == 0) {
		ODDMRFLOW_LOG("dmr fps node number is 0\n");
		return -1;
	}

	if(!(fps_dbv_node->FPS_node)) {
		ODDMRFLOW_LOG("FPS_node is NULL\n");
		return -1;
	}

	//dmr fps node lookup
	for(i = 0; i < fps_dbv_node->FPS_num; i++) {
		if(fps < fps_dbv_node->FPS_node[i])
			break;
	}

	if(i >= fps_dbv_node->FPS_num)
		fps_node_tmp = fps_dbv_node->FPS_num -1;
	else
		fps_node_tmp = (i>0)?(i-1):i;

	//dmr fps table lookup
	for(i = 0; i < table_index->FPS_table_num; i++) {
		if(fps < table_index->FPS_table_idx[i])
			break;
	}

	if(i >= table_index->FPS_table_num)
		fps_table_idx_tmp = table_index->FPS_table_num -1;
	else
		fps_table_idx_tmp = (i>0)?(i-1):i;

	*fps_node = fps_node_tmp;
	*fps_table_idx = fps_table_idx_tmp;

	for(i = 0; i < fps_dbv_node->FPS_num; i++)
		ODDMRFLOW_MSG("node_num:%d, fps_node%d:%d\n",
			fps_dbv_node->FPS_num, i, fps_dbv_node->FPS_node[i]);
	for(i = 0; i < table_index->FPS_table_num; i++)
		ODDMRFLOW_MSG("table_num:%d, table_idx%d:%d\n",
			table_index->FPS_table_num, i, table_index->FPS_table_idx[i]);
	ODDMRFLOW_MSG("current_fps:%d,fps_node:%d,fps_table_idx:%d\n",
		fps,*fps_node ,*fps_table_idx);

	return 0;
}

static int mtk_oddmr_dbi_dbv_lookup(unsigned int dbv, unsigned int *dbv_node_array, unsigned int dbv_node_num,
	unsigned int *dbv_node)
{
	unsigned int dbv_node_tmp;
	int i;

	ODDMRAPI_LOG("+\n");

	if(!dbv_node_array) {
		ODDMRFLOW_LOG("dbv_node_array is NULL\n");
		return -1;
	}

	//dbv mode lookup
	if(dbv_node_num == 0) {
		ODDMRFLOW_LOG("dbi dbv node number is 0\n");
		return -1;
	}

	//dbv mode lookup
	for(i = 0; i < dbv_node_num; i++) {
		if(dbv < dbv_node_array[i])
			break;
	}

	if(i >= dbv_node_num)
		dbv_node_tmp = dbv_node_num -1;
	else
		dbv_node_tmp = (i>0)?(i-1):i;

	*dbv_node = dbv_node_tmp;

	for(i = 0; i < dbv_node_num; i++)
		ODDMRFLOW_MSG("dbi_node_num:%d, dbv_node%d:%d\n",
			dbv_node_num, i, dbv_node_array[i]);

	ODDMRFLOW_MSG("dbi_current_dbv:%d,dbv_node:%d\n",
		dbv, *dbv_node);
	return 0;
}


static int mtk_oddmr_dmr_dbv_lookup(unsigned int dbv, struct mtk_drm_dmr_cfg_info *cfg_info,
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node, unsigned int *dbv_table_idx,
	unsigned int *dbv_node)
{
	struct mtk_drm_dmr_table_index *table_index;
	unsigned int dbv_table_idx_tmp;
	unsigned int dbv_node_tmp;
	int i;

	ODDMRAPI_LOG("+\n");

	if(!cfg_info) {
		ODDMRFLOW_LOG("dmr config info is NULL\n");
		return -1;
	}

	if(!(cfg_info->table_index.DBV_table_idx)) {
		ODDMRFLOW_LOG("dmr config info:DBV_table_idx is NULL\n");
		return -1;
	}

	table_index = &cfg_info->table_index;
	if(table_index->DBV_table_num== 0) {
		ODDMRFLOW_LOG("dmr dbv table number is 0\n");
		return -1;
	}

	if(!fps_dbv_node) {
		ODDMRFLOW_LOG("fps_dbv_node is NULL\n");
		return -1;
	}

	if(!(fps_dbv_node->DBV_node)) {
		ODDMRFLOW_LOG("DBV_node is NULL\n");
		return -1;
	}

	if(fps_dbv_node->DBV_num == 0) {
		ODDMRFLOW_LOG("dmr dbv node number is 0\n");
		return -1;
	}

	//dbv node lookup
	for(i = 0; i < fps_dbv_node->DBV_num; i++) {
		if(dbv < fps_dbv_node->DBV_node[i])
			break;
	}

	if(i >= fps_dbv_node->DBV_num)
		dbv_node_tmp = fps_dbv_node->DBV_num -1;
	else
		dbv_node_tmp = (i>0)?(i-1):i;

	//dbv table lookup
	for(i = 0; i < table_index->DBV_table_num; i++) {
		if(dbv < table_index->DBV_table_idx[i])
			break;
	}

	if(i >= table_index->DBV_table_num)
		dbv_table_idx_tmp = table_index->DBV_table_num-1;
	else
		dbv_table_idx_tmp = (i>0)?(i-1):i;

	*dbv_node = dbv_node_tmp;
	*dbv_table_idx = dbv_table_idx_tmp;

	for(i = 0; i < fps_dbv_node->DBV_num; i++)
		ODDMRFLOW_MSG("node_num:%d, dbv_node%d:%d\n",
			fps_dbv_node->DBV_num, i, fps_dbv_node->DBV_node[i]);
	for(i = 0; i < table_index->DBV_table_num; i++)
		ODDMRFLOW_MSG("table_num:%d, table_idx%d:%d\n",
			table_index->DBV_table_num, i, table_index->DBV_table_idx[i]);
	ODDMRFLOW_MSG("current_dbv:%d,dbv_node:%d,dbv_table_idx:%d\n",
		dbv, *dbv_node, *dbv_table_idx);
	return 0;
}

static void mtk_oddmr_dbi_timing_chg_dual(struct mtk_ddp_comp *comp,
	struct mtk_oddmr_timing *timing, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t dbv_node = 0;
	uint32_t fps_node = 0;
	uint32_t fps;
	int cur_tb;
	unsigned int gain_ratio;
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data = &oddmr_data->primary_data->dbi_cfg_info;
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data_tb1 = &oddmr_data->primary_data->dbi_cfg_info_tb1;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->primary_data->dbi_state >= ODDMR_INIT_DONE) {
		fps = timing->vrefresh;
		mtk_oddmr_dbi_fps_lookup(fps, &oddmr_data->primary_data->dbi_cfg_info,&fps_node);
		dbv_node = atomic_read(&oddmr_data->dbi_data.cur_dbv_node);
		gain_ratio = atomic_read(&oddmr_data->dbi_data.gain_ratio);

		cur_tb = atomic_read(&oddmr_data->dbi_data.cur_table_idx);
		if(cur_tb)
			mtk_oddmr_dbi_gain_cfg(comp,
				handle, dbv_node, fps_node,
				dbi_cfg_data_tb1, gain_ratio);
		else
			mtk_oddmr_dbi_gain_cfg(comp,
				handle, dbv_node, fps_node,
				dbi_cfg_data, gain_ratio);
		atomic_set(&oddmr_data->dbi_data.cur_fps_node, fps_node);

		ODDMRFLOW_LOG("dbi gain config: dbv_node:%d, fps_node:%d\n", dbv_node, fps_node);
	}
}


static void mtk_oddmr_dmr_timing_chg_dual(struct mtk_ddp_comp *comp,
	struct mtk_oddmr_timing *timing, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int old_vrefresh, cur_vrefresh;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("%s: dmr bin file loading not finished\n", __func__);
		return;
	}

	mutex_lock(&oddmr_data->primary_data->timing_lock);
	old_vrefresh = oddmr_data->primary_data->current_timing.old_vrefresh;
	cur_vrefresh = oddmr_data->primary_data->current_timing.vrefresh;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);
	if (old_vrefresh != cur_vrefresh) {
		atomic_set(&oddmr_data->dmr_data.dmr_timing_state, 1);
		ODDMRAPI_LOG("dmr fps changed from %d to %d\n", old_vrefresh, cur_vrefresh);
	}
}

static void mtk_oddmr_od_flip(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	int table_idx, tmp_sram_idx;
	uint32_t value, mask, r_sel, w_sel;

	ODDMRAPI_LOG("+\n");
	//flip
	oddmr_data->od_data.od_sram_read_sel = !oddmr_data->od_data.od_sram_read_sel;
	tmp_sram_idx = oddmr_data->od_data.od_sram_read_sel;
	table_idx = oddmr_data->od_data.od_dram_sel[oddmr_data->od_data.od_sram_table_idx[!!tmp_sram_idx]];
	r_sel = oddmr_data->od_data.od_sram_read_sel;
	w_sel = !r_sel;
	value = 0;
	mask = 0;
	SET_VAL_MASK(value, mask, w_sel, REG_OD_SRAM_WRITE_SEL);
	SET_VAL_MASK(value, mask, r_sel, REG_OD_SRAM_READ_SEL);
	if (oddmr_data->data->od_version >= MTK_OD_V3)
		SET_VAL_MASK(value, mask, 1, REG_OD_SRAM_READ_BACK_SEL);
	ODDMRFLOW_LOG("value w_sel %d r_sel %d 0x%x\n", w_sel, r_sel, value);
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		SET_VAL_MASK(value, mask, 1, REG_OD_TABLE_DB_EFF_EN);
		mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, mask, handle);
	} else
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_SRAM_CTRL_0, mask, handle);
	/* od pq */
	if (IS_TABLE_VALID(table_idx, od_param->valid_table))
		mtk_oddmr_set_pq(comp, handle, &od_param->od_tables[table_idx]->pq_od);
}

static void mtk_oddmr_set_od_weight(struct mtk_ddp_comp *comp, uint32_t *weight,
		struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	if (oddmr_data->data->od_version >= MTK_OD_V3) {
		ODDMRAPI_LOG("R %u, G %u, B %u\n", weight[0], weight[1], weight[2]);
		mtk_oddmr_write(comp, weight[0], MT6993_DISP_ODDMR_OD_USER_WEIGHT_R, handle);
		mtk_oddmr_write(comp, weight[1], MT6991_DISP_ODDMR_OD_PQ_0, handle);
		mtk_oddmr_write(comp, weight[2], MT6993_DISP_ODDMR_OD_USER_WEIGHT_B, handle);
	} else if (oddmr_data->data->od_version == MTK_OD_V2) {
		ODDMRAPI_LOG("%u\n", weight[1]);
		mtk_oddmr_write(comp, weight[1], MT6991_DISP_ODDMR_OD_PQ_0, handle);
	} else {
		ODDMRAPI_LOG("%u\n", weight[1]);
		mtk_oddmr_write(comp, weight[1], DISP_ODDMR_OD_PQ_0, handle);
	}
}

static void mtk_oddmr_set_od_weight_dual(struct mtk_ddp_comp *comp, uint32_t *weight,
		struct cmdq_pkt *handle)
{
	ODDMRAPI_LOG("+\n");
	mtk_oddmr_set_od_weight(comp, weight, handle);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_set_od_weight(comp1, weight, handle);
	}
}

static void mtk_oddmr_od_timing_chg_dual(struct mtk_ddp_comp *comp,
	struct mtk_oddmr_timing *timing, struct cmdq_pkt *handle)
{
	uint32_t weight[3] = {0};
	int ret, table_idx;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	struct mtk_ddp_comp *comp1;
	struct mtk_disp_oddmr *oddmr1_data;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE) {
		ret = mtk_oddmr_od_table_lookup(oddmr_data, timing, &table_idx, false);
		if (ret >= 0) {
			if ((timing->mode_chg_index & MODE_DSI_RES) &&
			(od_param->od_basic_info.basic_param.resolution_switch_mode == 1)) {
				/* res switch in ddic */
				atomic_set(&oddmr_data->primary_data->od_weight_trigger, 1);
				mtk_oddmr_od_set_res_udma_dual(comp, handle);
				mtk_oddmr_set_od_weight_dual(comp, weight, handle);
			}
			oddmr_data->od_force_off = false;
		} else
			oddmr_data->od_force_off = true;
		if (comp->mtk_crtc->is_dual_pipe) {
			comp1 = oddmr_data->companion;
			oddmr1_data = comp_to_oddmr(comp1);
			oddmr1_data->od_force_off = oddmr_data->od_force_off;
		}
	}
}


/* call from drm atomic flow */
void mtk_oddmr_timing_chg(struct mtk_ddp_comp *comp, struct mtk_oddmr_timing *timing, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_timing timing_working_copy;
	bool dmr_support, od_support, dbi_support;

	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;
	if (dmr_support || od_support || dbi_support) {
		ODDMRAPI_LOG("+\n");
		mtk_oddmr_copy_oddmr_timg(&timing_working_copy, timing);
		mutex_lock(&oddmr_data->primary_data->timing_lock);
		timing_working_copy.bl_level = oddmr_data->primary_data->current_timing.bl_level;
		oddmr_data->primary_data->current_timing.old_vrefresh =
			oddmr_data->primary_data->current_timing.vrefresh;
		mtk_oddmr_copy_oddmr_timg(&oddmr_data->primary_data->current_timing, &timing_working_copy);
		mutex_unlock(&oddmr_data->primary_data->timing_lock);
		ODDMRFLOW_LOG("w %u, h %u, fps %u, bl %u\n",
				timing_working_copy.hdisplay,
				timing_working_copy.vdisplay,
				timing_working_copy.vrefresh,
				timing_working_copy.bl_level);
		if (timing->mode_chg_index & MODE_DSI_RES)
			mtk_oddmr_set_spr2rgb_dual(comp, handle);
	}
	if (dmr_support && handle != NULL)
		mtk_oddmr_dmr_timing_chg_dual(comp, &timing_working_copy, handle);
	if (od_support && handle != NULL)
		mtk_oddmr_od_timing_chg_dual(comp, &timing_working_copy, handle);
	if (dbi_support && handle != NULL)
		mtk_oddmr_dbi_timing_chg_dual(comp, &timing_working_copy, handle);
}

static unsigned int mtk_oddmr_dmr_binset_check(struct mtk_ddp_comp *comp, unsigned int dmr_binset_idx,
	unsigned int dbv, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data;
	struct mtk_drm_oddmr_binset_info *dmr_binset;
	unsigned int binset_state;
	unsigned int new_bin_idx;
	unsigned int cur_binset_idx;
	int cur_bin_idx;
	unsigned int dmr_ln_offset = 2048;
	unsigned int dma_buffer_size = 0;
	int i = 0, j = 0;
	unsigned int ret = 0;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->dmr_enable) {
		binset_state = atomic_read(&oddmr_data->dmr_data.cus_binset_state);
		cur_binset_idx = atomic_read(&oddmr_data->dmr_data.cur_binset_idx);
		ODDMRFLOW_LOG("cur binset:%d  new binset:%d\n", cur_binset_idx, dmr_binset_idx);
		if (binset_state) {
			if (dmr_binset_idx >= oddmr_data->primary_data->dmr_cus_binset_info.binset_num)
				ODDMRFLOW_LOG("new binset:%d is invalid!\n", dmr_binset_idx);
			else if (cur_binset_idx != dmr_binset_idx) {
				atomic_set(&oddmr_data->dmr_data.cur_binset_idx, dmr_binset_idx);
				cur_binset_idx = dmr_binset_idx;
			}
			dmr_binset =
				&oddmr_data->primary_data->dmr_cus_binset_info.binset_list[cur_binset_idx];
		} else {
			if (dmr_binset_idx >= oddmr_data->primary_data->dmr_binset_cfg_info.binset_num)
				ODDMRFLOW_LOG("new binset:%d is invalid!\n", dmr_binset_idx);
			else if (cur_binset_idx != dmr_binset_idx) {
				atomic_set(&oddmr_data->dmr_data.cur_binset_idx, dmr_binset_idx);
				cur_binset_idx = dmr_binset_idx;
			}
			dmr_binset =
				&oddmr_data->primary_data->dmr_binset_cfg_info.binset_list[cur_binset_idx];
		}

		cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
		//dbv mode lookup
		for(i = 1; i < dmr_binset->dbv_interval_num; i++)
			if(dbv <= dmr_binset->dbv_interval_node[i])
				break;
		i--;
		new_bin_idx = dmr_binset->dbv_interval_bin_idx[i];
		ODDMRFLOW_LOG("old bin:%d, new bin:%d\n", cur_bin_idx, new_bin_idx);
		if (cur_bin_idx != -1) {
			dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
			ODDMRLOW_LOG("%s DBV_table_num:%d FPS_table_num:%d\n", __func__,
						dmr_cfg_data->table_index.DBV_table_num,
						dmr_cfg_data->table_index.FPS_table_num);
			for(i = 0; i < dmr_cfg_data->table_index.DBV_table_num; i++)
				for(j = 0; j < dmr_cfg_data->table_index.FPS_table_num; j++)
					ODDMRLOW_LOG("%s cur_bin_idx:%d i:%d j:%d kvaddr:%p dma_addr:%llx\n", __func__,
						cur_bin_idx, i, j,
						oddmr_data->dmr_data.mura_table[cur_bin_idx][i][j]->kvaddr,
						oddmr_data->dmr_data.mura_table[cur_bin_idx][i][j]->dma_addr);
		}
		if (new_bin_idx != -1) {
			dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[new_bin_idx];
			ODDMRLOW_LOG("%s DBV_table_num:%d FPS_table_num:%d\n", __func__,
						dmr_cfg_data->table_index.DBV_table_num,
						dmr_cfg_data->table_index.FPS_table_num);
			for(i = 0; i < dmr_cfg_data->table_index.DBV_table_num; i++)
				for(j = 0; j < dmr_cfg_data->table_index.FPS_table_num; j++)
					ODDMRLOW_LOG("%s cur_bin_idx:%d i:%d j:%d kvaddr:%p dma_addr:%llx\n", __func__,
						new_bin_idx, i, j,
						oddmr_data->dmr_data.mura_table[new_bin_idx][i][j]->kvaddr,
						oddmr_data->dmr_data.mura_table[new_bin_idx][i][j]->dma_addr);
		}

		// dbv in current bin dbv range, no need change bin
		if (cur_bin_idx == new_bin_idx) {
			ODDMRFLOW_LOG("The bin file has not been changed\n");
			return 0;
		}

		//record new bin index
		atomic_set(&oddmr_data->dmr_data.cur_bin_idx, new_bin_idx);

		//DBV_internal_bin_mapping == -1: in current DBV, DMR should disable
		if (new_bin_idx == -1) {
			ODDMRFLOW_LOG("in current DBV range of binset, DMR should disable");
			return -1;
		}

		dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[new_bin_idx];
		dmr_ln_offset = dmr_cfg_data->dmr_pu_info.compression_mode_ln_offset;
		dma_buffer_size = dmr_cfg_data->table_index.table_byte_num;
		if (dmr_ln_offset != 0 && dma_buffer_size % dmr_ln_offset != 0)
			PC_ERR("%s dmr table size does not align to ln_offset\n", __func__);
		ret = 1;
	}

	return ret;
}

static void mtk_oddmr_dmr_bl_chg(struct mtk_ddp_comp *comp, uint32_t bl_level, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t old_bl_level;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("%s: dmr bin file loading not finished\n", __func__);
		return;
	}

	mutex_lock(&oddmr_data->primary_data->timing_lock);
	old_bl_level = oddmr_data->primary_data->current_timing.old_bl_level;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);
	if (old_bl_level != bl_level) {
		atomic_set(&oddmr_data->dmr_data.dmr_timing_state, 1);
		ODDMRAPI_LOG("dmr dbv changed from %d to %d\n", old_bl_level, bl_level);
	}
}

static void mtk_oddmr_dbi_bl_chg(struct mtk_ddp_comp *comp, uint32_t bl_level, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t dbv_node = 0;
	uint32_t fps_node = 0;
	int cur_tb;
	uint32_t max_time_set_done = 0;
	unsigned int gain_ratio;
	uint32_t remap_enable;

	if (oddmr_data->primary_data->dbi_state >= ODDMR_INIT_DONE) {
		ODDMRAPI_LOG("+\n");
		mtk_oddmr_dbi_dbv_lookup(bl_level, oddmr_data->primary_data->dbi_cfg_info.fps_dbv_node.DBV_node,
			oddmr_data->primary_data->dbi_cfg_info.fps_dbv_node.DBV_num, &dbv_node);
		fps_node = atomic_read(&oddmr_data->dbi_data.cur_fps_node);

		gain_ratio = atomic_read(&oddmr_data->dbi_data.gain_ratio);
		cur_tb = atomic_read(&oddmr_data->dbi_data.cur_table_idx);
		if(cur_tb)
			mtk_oddmr_dbi_gain_cfg(comp,
				handle, dbv_node, fps_node,
				&oddmr_data->primary_data->dbi_cfg_info_tb1, gain_ratio);
		else
			mtk_oddmr_dbi_gain_cfg(comp,
				handle, dbv_node, fps_node,
				&oddmr_data->primary_data->dbi_cfg_info, gain_ratio);
		atomic_set(&oddmr_data->dbi_data.cur_dbv_node, dbv_node);

		if (oddmr_data->primary_data->dbi_cfg_info.dbv_node.DBV_num) {
			if(mtk_oddmr_dbi_dbv_lookup(bl_level,
				oddmr_data->primary_data->dbi_cfg_info.dbv_node.DBV_node,
				oddmr_data->primary_data->dbi_cfg_info.dbv_node.DBV_num, &dbv_node))
				ODDMRFLOW_LOG("dbi dbv lookup fail\n");
			mtk_oddmr_dbi_dbv_table_cfg(comp,
				handle, dbv_node, &oddmr_data->primary_data->dbi_cfg_info);
		}

		max_time_set_done = atomic_read(&oddmr_data->dbi_data.max_time_set_done);
		remap_enable = atomic_read(&oddmr_data->dbi_data.remap_enable);
		if (max_time_set_done && remap_enable == 1) {
			mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
			mtk_oddmr_dbi_change_remap_gain(comp, handle, oddmr_data->dbi_data.cur_max_time);
			mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		}
		ODDMRFLOW_LOG("dbi gain config: dbv_node:%d, fps_node:%d\n", dbv_node, fps_node);
	}
}

static void mtk_oddmr_od_bl_chg(struct mtk_ddp_comp *comp, uint32_t bl_level, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int table_idx, ret;

	if (oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE) {
		ODDMRAPI_LOG("+\n");
		ret = mtk_oddmr_od_table_lookup(oddmr_data, &oddmr_data->primary_data->current_timing,
			&table_idx, false);
		ODDMRAPI_LOG("od_bl_change, %d\n", ret);
		if (ret >= 0)
			oddmr_data->od_force_off = false;
		else
			oddmr_data->od_force_off = true;
		if (comp->mtk_crtc->is_dual_pipe) {
			struct mtk_ddp_comp *comp1 = oddmr_data->companion;
			struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

			oddmr1_data->od_force_off = oddmr_data->od_force_off;
		}
	}
}

void mtk_oddmr_bl_chg(struct mtk_ddp_comp *comp, uint32_t bl_level, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool dmr_support, od_support, dbi_support;

	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;

	ODDMRAPI_LOG("bl_level %u\n", bl_level);
	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	oddmr_data->primary_data->current_timing.old_bl_level =
		oddmr_data->primary_data->current_timing.bl_level;
	oddmr_data->primary_data->current_timing.bl_level = bl_level;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	if (dmr_support && handle != NULL)
		mtk_oddmr_dmr_bl_chg(comp, bl_level, handle);

	if (dbi_support && handle != NULL)
		mtk_oddmr_dbi_bl_chg(comp, bl_level, handle);

	if (od_support && handle != NULL)
		mtk_oddmr_od_bl_chg(comp, bl_level, handle);
}

static void mtk_oddmr_dmr_dbv_mode_chg(struct mtk_ddp_comp *comp,
	uint32_t dbv_mode, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t old_dbv_mode;
	unsigned int cus_setting_state;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("%s: dmr bin file loading not finished\n", __func__);
		return;
	}

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	cus_setting_state = atomic_read(&oddmr_data->dmr_data.cus_setting_state);
	if (cus_setting_state == 1 &&
		dbv_mode > oddmr_data->primary_data->dmr_cus_setting_info.dbv_mode_num) {
		ODDMRFLOW_LOG("%s: dbv_mode:%d is invalid\n", __func__, dbv_mode);
		return;
	}
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

	mutex_lock(&oddmr_data->primary_data->timing_lock);
	old_dbv_mode = oddmr_data->primary_data->current_timing.old_dbv_mode;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);
	if (old_dbv_mode != dbv_mode) {
		DDP_MUTEX_LOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		atomic_set(&oddmr_data->dmr_data.dmr_timing_state, 1);
		DDP_MUTEX_UNLOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		ODDMRAPI_LOG("dmr dbv changed from %d to %d\n", old_dbv_mode, dbv_mode);
	}
}

void mtk_oddmr_dbv_mode_chg(struct mtk_ddp_comp *comp,
	uint32_t dbv_mode, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("dbv_mode %u\n", dbv_mode);
	if(dbv_mode >= MAX_DBV_MODE_NUM) {
		ODDMRFLOW_LOG("%s: dbv_mode:%d is invalid\n", __func__, dbv_mode);
		return;
	}

	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	oddmr_data->primary_data->current_timing.old_dbv_mode =
		oddmr_data->primary_data->current_timing.dbv_mode;
	oddmr_data->primary_data->current_timing.dbv_mode = dbv_mode;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	if(oddmr_data->primary_data->dmr_support)
		mtk_oddmr_dmr_dbv_mode_chg(comp, dbv_mode, handle);
}

static void mtk_oddmr_dmr_binset_idx_chg(struct mtk_ddp_comp *comp,
	uint32_t binset_idx, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t old_binset_idx;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("%s: dmr bin file loading not finished\n", __func__);
		return;
	}

	mutex_lock(&oddmr_data->primary_data->timing_lock);
	old_binset_idx = oddmr_data->primary_data->current_timing.old_binset_idx;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);
	if (old_binset_idx != binset_idx) {
		DDP_MUTEX_LOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		atomic_set(&oddmr_data->dmr_data.dmr_timing_state, 1);
		DDP_MUTEX_UNLOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		ODDMRAPI_LOG("dmr binset idx changed from %d to %d\n", old_binset_idx, binset_idx);
	}
}

void mtk_oddmr_binset_chg(struct mtk_ddp_comp *comp,
	uint32_t binset_idx, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("binset index %u\n", binset_idx);
	if(binset_idx >= MAX_BINSET_NUM) {
		ODDMRFLOW_LOG("%s: binset_idx:%d is invalid\n", __func__, binset_idx);
		return;
	}

	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	oddmr_data->primary_data->current_timing.old_binset_idx =
		oddmr_data->primary_data->current_timing.binset_idx;
	oddmr_data->primary_data->current_timing.binset_idx = binset_idx;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	if(oddmr_data->primary_data->dmr_support)
		mtk_oddmr_dmr_binset_idx_chg(comp, binset_idx, handle);
}

int mtk_oddmr_hrt_cal_notify(struct drm_device *dev, int disp_idx, int *oddmr_hrt)
{
	int sum = 0;
	unsigned long long res_ratio = 1000;
	struct mtk_drm_crtc *mtk_crtc = NULL;
	struct drm_crtc *crtc = NULL;
	struct mtk_ddp_comp *comp;
	struct mtk_disp_oddmr *oddmr_data;
	struct mtk_oddmr_od_param *od_param;
	struct mtk_drm_private *priv;
	int temp_hrt = 0;
	bool dmr_support, od_support, dbi_support, wakeup = false;
	int index;

	ODDMRAPI_LOG("+\n");
	priv = dev->dev_private;
	drm_for_each_crtc(crtc, dev) {
		comp = NULL;
		mtk_crtc = to_mtk_crtc(crtc);
		index = drm_crtc_index(crtc);
		if(index != disp_idx)
			continue;
		comp = mtk_ddp_comp_sel_in_cur_crtc_path(mtk_crtc, MTK_DISP_ODDMR, 0);
		if (!comp)
			continue;
		oddmr_data = comp_to_oddmr(comp);
		od_param = &oddmr_data->primary_data->od_param;
		dmr_support = oddmr_data->primary_data->dmr_support;
		od_support = oddmr_data->primary_data->od_support;
		dbi_support = oddmr_data->primary_data->dbi_support;
		if (od_support || dmr_support || dbi_support) {
			if (atomic_read(&oddmr_data->primary_data->od_hrt_done) == 2) {
				oddmr_data->od_data.hrt_idx = _layering_rule_get_hrt_idx(disp_idx);
				atomic_set(&oddmr_data->primary_data->od_hrt_done, 1);
			}
			if (atomic_read(&oddmr_data->primary_data->dmr_hrt_done) == 2)
				atomic_set(&oddmr_data->primary_data->dmr_hrt_done, 1);
			if (atomic_read(&oddmr_data->primary_data->dbi_hrt_done) == 2)
				atomic_set(&oddmr_data->primary_data->dbi_hrt_done, 1);
			/* OD HRT */
			if (oddmr_data->od_enable_req) {
				if (oddmr_data->data->od_version >= MTK_OD_V2)
					temp_hrt = mtk_oddmr_od_bpp_v(comp,
							od_param->od_basic_info.basic_param.od_mode);
				else
					temp_hrt = mtk_oddmr_od_bpp(comp,
							od_param->od_basic_info.basic_param.od_mode);
				if (oddmr_data->data->is_od_support_stash &&
						oddmr_data->data->od_version >= MTK_OD_V3) {
					/* stash bw = data_bw / 4096 * 16 */
					temp_hrt += temp_hrt / 256;
				}
				sum += temp_hrt;
			}
			/* DMR HRT */
			if (oddmr_data->dmr_enable_req) {
				CRTC_MMP_MARK(0, oddmr_dmr_query_hrt_done, 0, 0);
				temp_hrt = mtk_oddmr_dmr_bpp(comp, true);
				if (oddmr_data->data->is_dmr_support_stash) {
					/* stash bw = data_bw / 4096 * 16 */
					temp_hrt += temp_hrt / 256;
				}
				sum += temp_hrt;
			}
			/* DBI HRT */
			if (oddmr_data->dbi_enable_req) {
				temp_hrt = mtk_oddmr_dbi_bpp(comp);
				if (oddmr_data->data->is_dbi_support_stash) {
					/* stash bw = data_bw / 4096 * 16 */
					temp_hrt += temp_hrt / 256;
				}
				sum += temp_hrt;
			}

			wakeup = true;
			oddmr_data->dmr_enable = oddmr_data->dmr_enable_req;
			oddmr_data->dbi_enable = oddmr_data->dbi_enable_req;
			if (comp->mtk_crtc->is_dual_pipe) {
				struct mtk_ddp_comp *comp1 = oddmr_data->companion;
				struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

				oddmr1_data->dmr_enable = oddmr1_data->dmr_enable_req;
				oddmr1_data->dbi_enable = oddmr1_data->dbi_enable_req;
			}
			mtk_crtc = comp->mtk_crtc;
			if (mtk_crtc->scaling_ctx.scaling_en) {
				res_ratio =
					((unsigned long long)mtk_crtc->scaling_ctx.lcm_width *
					mtk_crtc->scaling_ctx.lcm_height * 1000) /
					((unsigned long long)mtk_crtc->base.state->adjusted_mode.vdisplay *
					mtk_crtc->base.state->adjusted_mode.hdisplay);
			}
			sum = sum * res_ratio / 1000;
			DDPINFO("%s od %d (hrt_idx %d) dmr %d dbi %d sum %d res_ratio %llu\n", __func__,
				oddmr_data->od_enable_req, oddmr_data->od_data.hrt_idx,
				oddmr_data->dmr_enable, oddmr_data->dbi_enable, sum, res_ratio);
		}
	}
	if (wakeup)
		wake_up_all(&g_oddmr_hrt_wq);

	if (g_oddmr_hrt_en == false)
		return 0;
	*oddmr_hrt += sum;
	return sum;
}

static int mtk_oddmr_sum_hrt(struct mtk_ddp_comp *comp, enum CHANNEL_TYPE type, int *oddmr_hrt)
{
	int sum = 0;
	unsigned long long res_ratio = 1000;
	struct mtk_disp_oddmr *oddmr_data;
	struct mtk_oddmr_od_param *od_param;
	struct mtk_drm_crtc *mtk_crtc;
	int temp_hrt = 0;
	bool dmr_support, od_support, dbi_support;
	int od_enable, sec_on;
	unsigned int prop_lye_idx = 0;
	struct drm_crtc *crtc = NULL;
	struct mtk_crtc_state *crtc_state = NULL;

	ODDMRAPI_LOG("+\n");
	if (comp == NULL || comp->mtk_crtc == NULL) {
		PC_ERR("%s no comp or crtc!\n", __func__);
		return 0;
	}
	mtk_crtc = comp->mtk_crtc;
	if (!(mtk_crtc->base.dev && mtk_crtc->base.dev->dev_private)) {
		PC_ERR("%s no drm device!\n", __func__);
		return 0;
	}
	oddmr_data = comp_to_oddmr(comp);
	od_param = &oddmr_data->primary_data->od_param;
	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;

	if (!od_support && !dmr_support && !dbi_support)
		return 0;
	if (g_oddmr_hrt_en == false)
		return 0;

	if (atomic_read(&oddmr_data->primary_data->od_hrt_done) == 1) {
		crtc = &mtk_crtc->base;
		crtc_state = to_mtk_crtc_state(crtc->state);
		prop_lye_idx = crtc_state->prop_val[CRTC_PROP_LYE_IDX];
		DDPINFO("%s, hrt_idx %d, prop_lye_idx %d, od_enable_req %d, pq_od_bypass %d\n",
			__func__, oddmr_data->od_data.hrt_idx, prop_lye_idx,
			oddmr_data->od_enable_req, oddmr_data->pq_od_bypass);
		if (prop_lye_idx >= oddmr_data->od_data.hrt_idx) {
			atomic_set(&oddmr_data->primary_data->od_hrt_done, 0);
			oddmr_data->od_enable = oddmr_data->od_enable_req && !oddmr_data->pq_od_bypass;
			if (comp->mtk_crtc->is_dual_pipe) {
				struct mtk_ddp_comp *comp1 = oddmr_data->companion;
				struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

				oddmr1_data->od_enable = oddmr1_data->od_enable_req && !oddmr_data->pq_od_bypass;
			}
			if (atomic_read(&oddmr_data->primary_data->od_deinit) == 1)
				wake_up_interruptible(&oddmr_data->primary_data->od_deinit_wq);
		}
	}

	sec_on = comp->mtk_crtc->sec_on;
	od_enable = oddmr_data->od_enable && (!sec_on);
	if (type == CHANNEL_HRT_WRITE) {
		if (od_enable) {
			//mtk_oddmr_od_bpp_v return R+W bpp
			if (oddmr_data->data->od_version >= MTK_OD_V2) {
				temp_hrt = mtk_oddmr_od_bpp_v(comp, od_param->od_basic_info.basic_param.od_mode);
				temp_hrt = DIV_ROUND_UP(temp_hrt, 2);
			}
			if (oddmr_data->data->is_od_support_stash &&
					oddmr_data->data->od_version >= MTK_OD_V3) {
				/* stash bw = data_bw / 4096 * 16 */
				temp_hrt += temp_hrt / 256;
			}
			sum += temp_hrt;
		}
	} else {
		if (od_enable) {
			//mtk_oddmr_od_bpp_v return R+W bpp
			if (oddmr_data->data->od_version >= MTK_OD_V2) {
				temp_hrt = mtk_oddmr_od_bpp_v(comp, od_param->od_basic_info.basic_param.od_mode);
				temp_hrt = DIV_ROUND_UP(temp_hrt, 2);
			} else
				temp_hrt = mtk_oddmr_od_bpp(comp, od_param->od_basic_info.basic_param.od_mode);
			if (oddmr_data->data->is_od_support_stash &&
					oddmr_data->data->od_version >= MTK_OD_V3) {
				/* stash bw = data_bw / 4096 * 16 */
				temp_hrt += temp_hrt / 256;
			}
			sum += temp_hrt;
		}
		/* DMR HRT */
		if (oddmr_data->dmr_enable) {
			temp_hrt = mtk_oddmr_dmr_bpp(comp, false);
			if (oddmr_data->data->is_dmr_support_stash) {
				/* stash bw = data_bw / 4096 * 16 */
				temp_hrt += temp_hrt / 256;
			}
			sum += temp_hrt;
		}
		/* DBI HRT */
		if (oddmr_data->dbi_enable) {
			temp_hrt = mtk_oddmr_dbi_bpp(comp);
			if (oddmr_data->data->is_dbi_support_stash) {
				/* stash bw = data_bw / 4096 * 16 */
				temp_hrt += temp_hrt / 256;
			}
			sum += temp_hrt;
		}
	}
	if (mtk_crtc->scaling_ctx.scaling_en) {
		res_ratio =
			((unsigned long long)mtk_crtc->scaling_ctx.lcm_width *
			mtk_crtc->scaling_ctx.lcm_height * 1000) /
			((unsigned long long)mtk_crtc->base.state->adjusted_mode.vdisplay *
			mtk_crtc->base.state->adjusted_mode.hdisplay);
	}
	sum = sum * res_ratio / 1000;
	DDPINFO("type:%d, od %d dmr %d dbi %d sum %d res_ratio %llu\n",
			type, od_enable, oddmr_data->dmr_enable,
			oddmr_data->dbi_enable, sum, res_ratio);

	if (oddmr_hrt)
		*oddmr_hrt += sum;
	return sum;
}

void mtk_oddmr_od_sec_bypass(struct mtk_ddp_comp *comp, uint32_t sec_on, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t enable;
	bool od_support;

	ODDMRAPI_LOG("+\n");
	od_support = oddmr_data->primary_data->od_support;
	if (od_support) {
		enable = oddmr_data->od_enable && (!sec_on);
		mtk_oddmr_set_od_enable_dual(comp, enable, false, handle);
	}
}
void mtk_oddmr_ddren(struct cmdq_pkt *cmdq_handle,
	struct drm_crtc *crtc, int en)
{
	struct mtk_drm_crtc *mtk_crtc = to_mtk_crtc(crtc);
	struct mtk_drm_private *priv = crtc->dev->dev_private;
	unsigned long crtc_id = (unsigned long)drm_crtc_index(crtc);
	struct mtk_ddp_comp *comp;
	const u16 reg_jump = CMDQ_THR_SPR_IDX1;
	const u16 var1 = CMDQ_THR_SPR_IDX2;
	struct cmdq_operand lop, rop;
	u32 inst_condi_jump;
	u64 *inst, jump_pa;
	resource_size_t pa;
	unsigned int mmsys_sodi_req_mask, sodi_req_sel_val_sw;

	if (priv->data->mmsys_id != MMSYS_MT6985 || g_oddmr_ddren == false)
		return;
	if (crtc_id != 0)
		return;
	comp = mtk_ddp_comp_sel_in_cur_crtc_path(mtk_crtc, MTK_DISP_ODDMR, 0);
	if (!comp)
		return;
	mmsys_sodi_req_mask = 0xF4;
	sodi_req_sel_val_sw = 0x4100;
	pa = 0x14013000;
	if (comp)
		pa = comp->regs_pa;
	if (en) {
		/* 1. get od status */
		lop.reg = true;
		lop.idx = CMDQ_THR_SPR_IDX2;
		rop.reg = false;
		rop.value = 1;
		cmdq_pkt_read(cmdq_handle, NULL,
					pa + DISP_ODDMR_OD_CTRL_EN, var1);
		cmdq_pkt_logic_command(cmdq_handle, CMDQ_LOGIC_AND, var1, &lop, &rop);
		/* 2. set ddren if od is enabled*/
		lop.reg = true;
		lop.idx = CMDQ_THR_SPR_IDX2;
		rop.reg = false;
		rop.value = 1;

		/*mark condition jump */
		inst_condi_jump = cmdq_handle->cmd_buf_size;
		cmdq_pkt_assign_command(cmdq_handle, reg_jump, 0);

		cmdq_pkt_cond_jump_abs(cmdq_handle, reg_jump, &lop, &rop,
			CMDQ_NOT_EQUAL);

		/* if condition false, will jump here */
		{
			cmdq_pkt_write(cmdq_handle, mtk_crtc->gce_obj.base,
				mtk_crtc->config_regs_pa + mmsys_sodi_req_mask,
				sodi_req_sel_val_sw, sodi_req_sel_val_sw);
		}

		/* if condition true, will jump curreent postzion */
		inst = cmdq_pkt_get_va_by_offset(cmdq_handle,  inst_condi_jump);
		jump_pa = cmdq_pkt_get_pa_by_offset(cmdq_handle,
					cmdq_handle->cmd_buf_size);
		*inst = *inst | CMDQ_REG_SHIFT_ADDR(jump_pa);

	} else
		cmdq_pkt_write(cmdq_handle, mtk_crtc->gce_obj.base,
			mtk_crtc->config_regs_pa + mmsys_sodi_req_mask,
			0x4000, sodi_req_sel_val_sw);
}

static void mtk_cal_oddmr_valid_partial_roi(struct mtk_ddp_comp *comp,
				struct mtk_rect *partial_roi)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data = &oddmr_data->primary_data->dbi_cfg_info;
	unsigned int scale_factor_v = 4;
	unsigned int dbi_y_diff = 0;
	bool od_en, od_en_last;
	unsigned int y1, y2, y2_last, y2_cur, roi_y_cur, roi_height_cur;

	ODDMRLOW_LOG("%s line: %d before partial_y:%d partial_height:%d\n",
		__func__, __LINE__, partial_roi->y, partial_roi->height);

	if (oddmr_data->primary_data->od_support &&
		(oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE ||
		oddmr_data->od_data.od_sram_reading) &&
		oddmr_data->data->od_version >= MTK_OD_V2) {
		od_en = oddmr_data->od_enable && !comp->mtk_crtc->sec_on;
		od_en_last = oddmr_data->od_enable_last;
		roi_y_cur = partial_roi->y;
		roi_height_cur = partial_roi->height;
		/* When OD on, 1st frame needs full frame */
		if ((!od_en_last && od_en) || oddmr_data->od_data.od_sram_reading) {
			//update current roi y, height
			partial_roi->y = 0;
			partial_roi->height = mtk_crtc_get_height_by_comp(__func__,
				&comp->mtk_crtc->base, comp, true);
			ODDMRLOW_LOG("%s line: %d, OD en_last %d en %d, change roi to full (%d, %d)\n",
				__func__, __LINE__, od_en_last, od_en, partial_roi->y, partial_roi->height);
			ODDMRLOW_LOG("%s line: %d end partial_y:%d partial_height:%d\n",
				__func__, __LINE__, partial_roi->y, partial_roi->height);
			//record original roi y, height for next frame
			oddmr_data->roi_y_last = roi_y_cur;
			oddmr_data->roi_height_last = roi_height_cur;
			return;
		}
		/* 2nd and following frames need union of previous and current origianl roi */
		if (od_en_last && od_en) {
			//y1 = min(cur y, last y)
			y1 = (roi_y_cur < oddmr_data->roi_y_last) ?
				roi_y_cur : oddmr_data->roi_y_last;
			y2_last = oddmr_data->roi_y_last + oddmr_data->roi_height_last;
			y2_cur = roi_y_cur + roi_height_cur;
			//y2 = max(cur y+height, last y+height)
			y2 = (y2_cur > y2_last) ? y2_cur : y2_last;
			ODDMRLOW_LOG("%s line: %d, last original roi (%d, %d)\n",
				__func__, __LINE__, oddmr_data->roi_y_last, oddmr_data->roi_height_last);
			//update current roi y, height
			partial_roi->y = y1;
			partial_roi->height = y2 - y1;
			ODDMRLOW_LOG("%s line: %d, OD en_last %d en %d, change roi to union (%d, %d)\n",
				__func__, __LINE__, od_en_last, od_en, partial_roi->y, partial_roi->height);
		}
		//record original roi y, height for next frame
		oddmr_data->roi_y_last = roi_y_cur;
		oddmr_data->roi_height_last = roi_height_cur;
	}

	if (comp->mtk_crtc->panel_ext->params->is_support_dbi == true &&
		oddmr_data->primary_data->dbi_state == ODDMR_INIT_DONE) {
		scale_factor_v = dbi_cfg_data->basic_info.partial_update_scale_factor_v;
		if(oddmr_data->data->dbi_version >= MTK_DBI_V3)
			scale_factor_v = 4;
		/* align to scale factor v*/
		if (partial_roi->y % scale_factor_v != 0) {
			dbi_y_diff =
				partial_roi->y - (partial_roi->y / scale_factor_v) * scale_factor_v;
			partial_roi->y -= dbi_y_diff;
		}
		partial_roi->height += dbi_y_diff;
	}
	ODDMRLOW_LOG("%s line: %d end partial_y:%d partial_height:%d scale_v %d\n",
		__func__, __LINE__, partial_roi->y, partial_roi->height, scale_factor_v);
}

static void disp_oddmr_primary_data_init(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_disp_oddmr *companion_oddmr_data = comp_to_oddmr(oddmr_data->companion);
	struct mtk_disp_oddmr_primary *primary_data;
	struct drm_display_mode *mode;
	struct mtk_ddp_comp *out_comp = NULL;
	int crtc_idx;
	char thread_name[20] = "oddmr_sof_0";
	struct sched_param param = {.sched_priority = 85 };
	struct cpumask mask;

	if (oddmr_data->is_right_pipe) {
		kfree(oddmr_data->primary_data);
		oddmr_data->primary_data = NULL;
		oddmr_data->primary_data = companion_oddmr_data->primary_data;
		return;
	}

	primary_data = oddmr_data->primary_data;

	init_waitqueue_head(&primary_data->sof_irq_wq);
	init_waitqueue_head(&primary_data->hrt_wq);
	init_waitqueue_head(&primary_data->od_sram_wq);
	init_waitqueue_head(&primary_data->od_deinit_wq);
	init_waitqueue_head(&primary_data->frame_dirty_wq);
	init_waitqueue_head(&primary_data->dmr_switch_wq);
	init_waitqueue_head(&primary_data->dmr_enable_wq);
	mutex_init(&primary_data->clock_lock);
	mutex_init(&primary_data->timing_lock);
	mutex_init(&primary_data->dbi_data_lock);
	mutex_init(&primary_data->dmr_data_lock);
	mutex_init(&primary_data->od_load_param_lock);

	primary_data->dmr_support = comp->mtk_crtc->panel_ext->params->is_support_dmr;
	primary_data->od_support = comp->mtk_crtc->panel_ext->params->is_support_od;
	primary_data->dbi_support = comp->mtk_crtc->panel_ext->params->is_support_dbi;
	atomic_set(&primary_data->od_weight_trigger, 0);
	atomic_set(&primary_data->frame_dirty, 0);
	atomic_set(&primary_data->sof_irq_available, 0);
	atomic_set(&primary_data->sof_irq_for_od_sram, 0);
	atomic_set(&primary_data->dmr_hrt_done, 0);
	atomic_set(&primary_data->dbi_hrt_done, 0);
	atomic_set(&primary_data->od_hrt_done, 0);
	atomic_set(&primary_data->od_deinit, 0);

	crtc_idx = drm_crtc_index(&comp->mtk_crtc->base);
	out_comp = mtk_ddp_comp_request_output(comp->mtk_crtc);
	if (out_comp && (primary_data->dmr_support|| primary_data->od_support))
		out_comp->funcs->io_cmd(out_comp, NULL, DSI_READ_PANELID, &primary_data->panelid);
	mutex_lock(&primary_data->timing_lock);
	mode = mtk_crtc_get_display_mode_by_comp(__func__, &comp->mtk_crtc->base, comp, false);
	mtk_oddmr_drm_mode_to_oddmr_timg(mode, &primary_data->current_timing);
	mutex_unlock(&primary_data->timing_lock);

	if (oddmr_data->data->is_od_table_bl_chg)
		mtk_oddmr_create_workqueue(oddmr_data);
	// start thread for oddmr sof
	sprintf(thread_name, "oddmr_sof_%d", comp->id);
	primary_data->sof_irq_event_task = kthread_create(disp_oddmr_sof_kthread, comp, thread_name);
	cpumask_setall(&mask);
	cpumask_clear_cpu(0, &mask);
	set_cpus_allowed_ptr(primary_data->sof_irq_event_task, &mask);
	if (sched_setscheduler(primary_data->sof_irq_event_task, SCHED_RR, &param))
		pr_notice("oddmr sof_irq_event_task setschedule fail");
	wake_up_process(primary_data->sof_irq_event_task);
}

static void mtk_oddmr_dmr_state_chg(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, unsigned int dmr_timing_state)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data;
	struct mtk_drm_cus_setting_info *cus_setting_info = NULL;
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node = NULL;
	unsigned int cur_dbv, cur_fps, cur_dbv_mode, dmr_binset_idx;
	int cur_bin_idx;
	unsigned int cus_setting_state = 0;
	unsigned int bin_idx_chg = 0;
	unsigned int dbv_table_idx = 0;
	unsigned int dbv_node = 0;
	unsigned int fps_table_idx = 0;
	unsigned int fps_node = 0;
	dma_addr_t addr = 0;

	/* get current binset idx, dvb, fps and dbv_mode */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
	cur_fps = oddmr_data->primary_data->current_timing.vrefresh;
	cur_dbv_mode = oddmr_data->primary_data->current_timing.dbv_mode;
	dmr_binset_idx = oddmr_data->primary_data->current_timing.binset_idx;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	bin_idx_chg = mtk_oddmr_dmr_binset_check(comp, dmr_binset_idx, cur_dbv, handle);
	if (bin_idx_chg) {
		/* update dmr table and hw settings */
		mtk_oddmr_dmr_config(comp, handle);
	} else {
		/* update dmr gain config */
		cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
		cus_setting_state = atomic_read(&oddmr_data->dmr_data.cus_setting_state);
		if (cur_bin_idx != -1) {
			dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
			cus_setting_info = &oddmr_data->primary_data->dmr_cus_setting_info;
			if(cus_setting_state == 1) {
				if(cur_dbv_mode >= cus_setting_info->dbv_mode_num) {
					ODDMRFLOW_LOG("current dbv_mode:%d out of range\n", cur_dbv_mode);
					return;
				}
				fps_dbv_node = &cus_setting_info->fps_dbv_node[cur_dbv_mode];
			} else {
				fps_dbv_node = &dmr_cfg_data->fps_dbv_node;
			}
			if(mtk_oddmr_dmr_dbv_lookup(cur_dbv, dmr_cfg_data, fps_dbv_node, &dbv_table_idx, &dbv_node)) {
				PC_ERR("dmr dbv lookup fail\n");
				return;
			}
			if(mtk_oddmr_dmr_fps_lookup(cur_fps, dmr_cfg_data, fps_dbv_node, &fps_table_idx, &fps_node)) {
				PC_ERR("dmr fps lookup fail\n");
				return;
			}
			atomic_set(&oddmr_data->dmr_data.cur_dbv_node, dbv_node);
			atomic_set(&oddmr_data->dmr_data.cur_dbv_table_idx, dbv_table_idx);
			atomic_set(&oddmr_data->dmr_data.cur_fps_node, fps_node);
			atomic_set(&oddmr_data->dmr_data.cur_fps_table_idx, fps_table_idx);
			mtk_oddmr_dmr_gain_cfg(comp, handle, dbv_node, fps_node, dmr_cfg_data);
			//set dmr table
			addr = oddmr_data->dmr_data.mura_table[cur_bin_idx][dbv_table_idx][fps_table_idx]->dma_addr;
			mtk_oddmr_write(comp, addr >> 4,
				MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_0, handle);
			mtk_oddmr_write(comp, addr >> 20,
				MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_1, handle);
			mtk_oddmr_dmr_srt_cal(comp, oddmr_data->dmr_enable);
		}
	}
	/* update remap gain */
	mtk_oddmr_dmr_change_remap_gain(comp, handle);
}

static void mtk_oddmr_get_dmr_cus_own_data(struct mtk_ddp_comp *comp,
	struct cus_own_data *cus_data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool dmr_support = oddmr_data->primary_data->dmr_support;
	unsigned int cus_data_state;
	unsigned int size = 0;

	ODDMRAPI_LOG("+\n");
	if (!dmr_support) {
		ODDMRFLOW_LOG("%s: dmr is not support\n", __func__);
		return;
	}
	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("%s: dmr bin file loading not finished\n", __func__);
		return;
	}
	if (!oddmr_data->dmr_enable) {
		ODDMRFLOW_LOG("%s: dmr is disabled\n", __func__);
		return;
	}
	if(!cus_data_state) {
		ODDMRFLOW_LOG("%s: dmr customer own data not be loaded\n", __func__);
		return;
	}

	mutex_lock(&oddmr_data->primary_data->dmr_cus_own_data_lock);
	cus_data_state = atomic_read(&oddmr_data->dmr_data.cus_own_data_state);
	size = oddmr_data->primary_data->dmr_cus_own_data.size;
	if(size > 0 && cus_data && cus_data->data) {
		cus_data->size = size;
		memcpy(cus_data->data, oddmr_data->primary_data->dmr_cus_own_data.data, size);
	}
	mutex_unlock(&oddmr_data->primary_data->dmr_cus_own_data_lock);
}

int mtk_oddmr_io_cmd(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle,
		enum mtk_ddp_io_cmd cmd, void *params)
{
	struct mtk_drm_private *priv;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRLOW_LOG("cmd %d+\n", cmd);
	if (!(comp->mtk_crtc && comp->mtk_crtc->base.dev)) {
		ODDMRFLOW_LOG("%s %u has invalid CRTC or device\n", mtk_dump_comp_str(comp), cmd);
		return -INVALID;
	}

	priv = comp->mtk_crtc->base.dev->dev_private;

	switch (cmd) {
	case PQ_FILL_COMP_PIPE_INFO:
	{
		bool *is_right_pipe = &oddmr_data->is_right_pipe;
		int ret, *path_order = &oddmr_data->path_order;
		struct mtk_ddp_comp **companion = &oddmr_data->companion;
		struct mtk_disp_oddmr *companion_data;
	
		if (atomic_read(&comp->mtk_crtc->pq_data->pipe_info_filled) == 1)
			break;
		ret = disp_pq_helper_fill_comp_pipe_info(comp, path_order, is_right_pipe, companion);
		if (!ret && comp->mtk_crtc->is_dual_pipe && oddmr_data->companion) {
			companion_data = comp_to_oddmr(oddmr_data->companion);
			companion_data->path_order = oddmr_data->path_order;
			companion_data->is_right_pipe = !oddmr_data->is_right_pipe;
			companion_data->companion = comp;
		}
		//disp_oddmr_data_init(comp);
		disp_oddmr_primary_data_init(comp);
		if (comp->mtk_crtc->is_dual_pipe && oddmr_data->companion) {
			//disp_oddmr_data_init(data->companion);
			disp_oddmr_primary_data_init(oddmr_data->companion);
		}
	}
		break;
	case FRAME_DIRTY:
	{
		if (oddmr_data->is_right_pipe)
			break;
		if (!atomic_read(&oddmr_data->primary_data->frame_dirty)) {
			atomic_set(&oddmr_data->primary_data->frame_dirty, 1);
			wake_up_interruptible(&oddmr_data->primary_data->frame_dirty_wq);
		}
	}
		break;
	case ODDMR_TRIG_CTL:
	{
		uint32_t on = *(uint32_t *)params;

		if (oddmr_data->is_right_pipe)
			break;
		g_od_check_trigger = on;
	}
		break;
	case DISP_BL_CHG:
	{
		uint32_t bl_level = *(uint32_t *)params;

		if (oddmr_data->is_right_pipe)
			break;
		mtk_oddmr_bl_chg(comp, bl_level, handle);
	}
		break;
	case ODDMR_TIMING_CHG:
	{
		struct mtk_oddmr_timing *timing = (struct mtk_oddmr_timing *)params;

		if (oddmr_data->is_right_pipe)
			break;
		mtk_oddmr_timing_chg(comp, timing, handle);
	}
		break;
	case ODDMR_DBV_MODE_CHG:
	{
		uint32_t dbv_mode = *(uint32_t *)params;

		if (oddmr_data->is_right_pipe)
			break;
		mtk_oddmr_dbv_mode_chg(comp, dbv_mode, handle);
	}
		break;
	case ODDMR_BINSET_CHG:
	{
		uint32_t dmr_binset_idx = *(uint32_t *)params;
		bool dmr_support;

		if (oddmr_data->is_right_pipe)
			break;
		mtk_oddmr_binset_chg(comp, dmr_binset_idx, handle);
	}
		break;
	case COMP_ODDMR_CFG:
	{
		bool sec_on = *(bool *)params;
		int cnt;
		int slc_alloc, slc_period;
		static int dmr_enable;
		static int dbi_enable;
		unsigned int remap_enable;
		unsigned int dmr_timing_state = 0;
		unsigned int cur_dbv, cur_binset;
		unsigned int reg_tuning_chg, reg_tuning_en;

		slc_alloc = oddmr_data->data->slc_read_alloc;
		slc_period = oddmr_data->data->slc_period;
		if (g_slc_period) {
			slc_alloc = g_slc_read_alloc;
			slc_period = g_slc_period;
		}
		if (oddmr_data->is_right_pipe)
			break;
		mtk_oddmr_od_sec_bypass(comp, sec_on, handle);

		if (oddmr_data->primary_data->dmr_support) {
			if (atomic_read(&oddmr_data->dmr_data.dmr_cfg_done) == 2)
				atomic_set(&oddmr_data->dmr_data.dmr_cfg_done, 1);
			wake_up_all(&oddmr_data->primary_data->dmr_enable_wq);
		}

		mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
		dmr_timing_state = atomic_read(&oddmr_data->dmr_data.dmr_timing_state);
		if(dmr_enable != oddmr_data->dmr_enable) {
			CRTC_MMP_MARK(0, oddmr_dmr_cfg_done, 0, 0);
			oddmr_data->primary_data->slc_frame_cnt[DMR_SLC] = 0;
			if (oddmr_data->dmr_enable == 0)
				mtk_oddmr_set_dmr_enable(comp, 0, handle);
			else {
				/* get current binset idx, dvb, fps and dbv_mode */
				mutex_lock(&oddmr_data->primary_data->timing_lock);
				cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
				cur_binset = oddmr_data->primary_data->current_timing.binset_idx;
				mutex_unlock(&oddmr_data->primary_data->timing_lock);
				mtk_oddmr_dmr_binset_check(comp, cur_binset, cur_dbv, handle);
				mtk_oddmr_dmr_config(comp, handle);
			}
			dmr_enable = oddmr_data->dmr_enable;
			atomic_set(&oddmr_data->dmr_data.remap_enable, dmr_enable);
			if (dmr_enable == 1) {
				mtk_oddmr_dmr_change_remap_gain(comp, handle);
				mtk_oddmr_remap_set_enable(comp, handle, true);
			} else {
				remap_enable = atomic_read(&oddmr_data->dbi_data.remap_enable);
				if (remap_enable == 0)
					mtk_oddmr_remap_set_enable(comp, handle, false);
			}
		} else if (oddmr_data->dmr_enable) {
			if (dmr_timing_state) {
				CRTC_MMP_MARK(0, oddmr_dmr_timing_state_chg, 0, 0);
				mtk_oddmr_dmr_state_chg(comp, handle, dmr_timing_state);
				atomic_set(&oddmr_data->dmr_data.dmr_timing_state, 0);
				wake_up_all(&oddmr_data->primary_data->dmr_switch_wq);
			}
			/* dmr register tuning */
			reg_tuning_chg = atomic_read(&oddmr_data->dmr_data.reg_tuning_chg);
			reg_tuning_en = atomic_read(&oddmr_data->reg_tuning_en);
			if (reg_tuning_en && reg_tuning_chg) {
				mtk_oddmr_tuning_cfg(comp, handle, &oddmr_data->primary_data->oddmr_reg_tuning_info);
				atomic_set(&oddmr_data->dmr_data.reg_tuning_chg, 0);
			}
			cnt = oddmr_data->primary_data->slc_frame_cnt[DMR_SLC];
			if (cnt < slc_alloc)
				mtk_oddmr_dmr_set_slc(comp, handle, 6);
			if (cnt >= slc_alloc && cnt < slc_alloc + 2)
				mtk_oddmr_dmr_set_slc(comp, handle, 2);
			oddmr_data->primary_data->slc_frame_cnt[DMR_SLC] = (cnt + 1) % slc_period;
			ODDMRLOW_LOG("dmr slc cnt %d, alloc %d, period %d\n", cnt, slc_alloc, slc_period);
		}
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

		mtk_oddmr_dbi_srt_cal(comp, oddmr_data->dbi_enable);

		if(dbi_enable != oddmr_data->dbi_enable || g_dbi_update) {
			oddmr_data->primary_data->slc_frame_cnt[DBI_SLC] = 0;
			g_dbi_update = 0;
			mtk_oddmr_dbi_config(comp,handle);
			dbi_enable = oddmr_data->dbi_enable;
		} else if (oddmr_data->dbi_enable) {
			cnt = oddmr_data->primary_data->slc_frame_cnt[DBI_SLC];
			if (cnt < slc_alloc)
				mtk_oddmr_dbi_set_slc(comp, handle, 6);
			if (cnt >= slc_alloc && cnt < slc_alloc + 2)
				mtk_oddmr_dbi_set_slc(comp, handle, 2);
			oddmr_data->primary_data->slc_frame_cnt[DBI_SLC] = (cnt + 1) % slc_period;
			ODDMRLOW_LOG("dbi slc cnt %d, alloc %d, period %d\n", cnt, slc_alloc, slc_period);
		}
		break;
	}
	case PMQOS_GET_LARB_PORT_HRT_BW: {
		struct mtk_larb_port_bw *data = (struct mtk_larb_port_bw *)params;
		int weight = 0;
		unsigned int bw_base = data->bw_base;

		data->larb_id = -1;
		data->bw = 0;
		if (data->type != CHANNEL_HRT_RW && data->type != CHANNEL_HRT_WRITE)
			break;

		if (comp->larb_num == 1)
			data->larb_id = comp->larb_id;
		else if (comp->larb_num > 1)
			data->larb_id = comp->larb_ids[0];

		if (data->larb_id < 0)
			break;

		mtk_oddmr_sum_hrt(comp, data->type, &weight);
		if (weight > 0) {
			if (!bw_base)
				bw_base = mtk_drm_primary_frame_bw(&comp->mtk_crtc->base);
			data->bw = bw_base * weight / 400;
			DDPINFO("%s, oddmr comp:%d, larb:%d, type:%d, bw:%d, weight:%d\n",
				__func__, comp->id, data->larb_id, data->type, data->bw, weight);
		}
		break;
	}
	case PMQOS_UPDATE_BW:
	{
		struct mtk_drm_private *priv =
			comp->mtk_crtc->base.dev->dev_private;
		unsigned int force_update = 0; /* force_update repeat last qos BW */
		unsigned int update_pending = 0;
		unsigned int crtc_idx, channel_id = 0;
		struct drm_crtc *crtc;
		struct mtk_drm_crtc *mtk_crtc;

		if (!mtk_drm_helper_get_opt(priv->helper_opt,
				MTK_DRM_OPT_MMQOS_SUPPORT))
			break;

		mtk_crtc = comp->mtk_crtc;
		crtc = &mtk_crtc->base;
		crtc_idx = drm_crtc_index(crtc);

		if (priv->data->mmsys_id == MMSYS_MT6991)
			channel_id = 3;
		else if (priv->data->mmsys_id == MMSYS_MT6993)
			channel_id = 2;

		ODDMRLOW_LOG("srt odr(%u,%u),odw(%u,%u),dmrr(%u,%u) dbi(%u,%u)\n",
			oddmr_data->last_qos_srt_odr, oddmr_data->qos_srt_odr,
			oddmr_data->last_qos_srt_odw, oddmr_data->qos_srt_odw,
			oddmr_data->last_qos_srt_dmrr, oddmr_data->qos_srt_dmrr,
			oddmr_data->last_qos_srt_dbir, oddmr_data->qos_srt_dbir);

		if (params) {
			force_update = *(unsigned int *)params;
			update_pending = (force_update == DISP_BW_UPDATE_PENDING);
			force_update = (force_update == DISP_BW_FORCE_UPDATE) ? 1 : 0;
		}

		if (!force_update && !update_pending) {
			mtk_crtc->total_srt += oddmr_data->qos_srt_odr;
			if (channel_id < 4)
				priv->srt_channel_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_odr;

			mtk_crtc->total_srt += oddmr_data->qos_srt_odw;
			if (channel_id < 4)
				priv->srt_channel_write_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_odw;

			mtk_crtc->total_srt += oddmr_data->qos_srt_dmrr;
			if (channel_id < 4)
				priv->srt_channel_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_dmrr;

			mtk_crtc->total_srt += oddmr_data->qos_srt_dbir;
			if (channel_id < 4)
				priv->srt_channel_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_dbir;
		}

		/* process normal */
		if (force_update || oddmr_data->last_qos_srt_odr != oddmr_data->qos_srt_odr) {
			__mtk_disp_set_module_srt(oddmr_data->qos_req_odr, comp->id,
				oddmr_data->qos_srt_odr, 0, DISP_BW_NORMAL_MODE,
				priv->data->real_srt_ostdl);
			oddmr_data->last_qos_srt_odr = oddmr_data->qos_srt_odr;
			if (!force_update && update_pending) {
				comp->mtk_crtc->total_srt += oddmr_data->qos_srt_odr;
				if (channel_id < 4)
					priv->srt_channel_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_odr;
			}
		}
		if (force_update || oddmr_data->last_qos_srt_odw != oddmr_data->qos_srt_odw) {
			__mtk_disp_set_module_srt(oddmr_data->qos_req_odw, comp->id,
				oddmr_data->qos_srt_odw, 0, DISP_BW_NORMAL_MODE,
				priv->data->real_srt_ostdl);
			oddmr_data->last_qos_srt_odw = oddmr_data->qos_srt_odw;
			if (!force_update && update_pending) {
				comp->mtk_crtc->total_srt += oddmr_data->qos_srt_odw;
				if (channel_id < 4)
					priv->srt_channel_write_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_odw;
			}
		}
		if (force_update || oddmr_data->last_qos_srt_dmrr != oddmr_data->qos_srt_dmrr) {
			__mtk_disp_set_module_srt(oddmr_data->qos_req_dmrr, comp->id,
				oddmr_data->qos_srt_dmrr, 0, DISP_BW_NORMAL_MODE,
				priv->data->real_srt_ostdl);
			oddmr_data->last_qos_srt_dmrr = oddmr_data->qos_srt_dmrr;
			if (!force_update && update_pending) {
				comp->mtk_crtc->total_srt += oddmr_data->qos_srt_dmrr;
				if (channel_id < 4)
					priv->srt_channel_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_dmrr;
			}
		}
		if (force_update || oddmr_data->last_qos_srt_dbir != oddmr_data->qos_srt_dbir) {
			__mtk_disp_set_module_srt(oddmr_data->qos_req_dbir, comp->id,
				oddmr_data->qos_srt_dbir, 0, DISP_BW_NORMAL_MODE,
				priv->data->real_srt_ostdl);
			oddmr_data->last_qos_srt_dbir = oddmr_data->qos_srt_dbir;
			if (!force_update && update_pending) {
				comp->mtk_crtc->total_srt += oddmr_data->qos_srt_dbir;
				if (channel_id < 4)
					priv->srt_channel_bw_sum[crtc_idx][channel_id] += oddmr_data->qos_srt_dbir;
			}
		}
	}
		break;
	case PMQOS_SET_HRT_BW:
	{
		int od_enable, dmr_enable, dbi_enable, sec_on;
		u32 bw_val, bw_base = *(unsigned int *)params;
		struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
		u32 layer_num = 0;
		u32 stash_bw = 0;
		int cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
		struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;

		if (!mtk_drm_helper_get_opt(priv->helper_opt, MTK_DRM_OPT_MMQOS_SUPPORT))
			break;
		sec_on = comp->mtk_crtc->sec_on;
		od_enable = oddmr_data->od_enable && (!sec_on);
		dmr_enable = oddmr_data->dmr_enable;
		dbi_enable = oddmr_data->dbi_enable;
		od_enable = !!bw_base && od_enable;
		dmr_enable = !!bw_base && dmr_enable;
		dbi_enable = !!bw_base && dbi_enable;

		if (priv->data->respective_ostdl) {
			/* DMR outstanding */
			if (cur_bin_idx == -1)
				dmr_enable = 0;
			layer_num = mtk_oddmr_dmr_bpp(comp, false);
			bw_val = (layer_num * bw_base / 400) * dmr_enable;
			/* stash bw = data_bw / 4096 * 16 */
			if (oddmr_data->data->is_dmr_support_stash) {
				stash_bw = bw_val / 256;
				stash_bw = stash_bw > oddmr_data->data->min_stash_port_bw ?
					stash_bw : oddmr_data->data->min_stash_port_bw; //set low bound
				if (oddmr_data->data->dbi_version == MTK_DBI_V3) {
					stash_bw = stash_bw * dmr_enable;
					__mtk_disp_set_module_hrt(oddmr_data->qos_req_dmrr_stash_hrt,
						comp->id, stash_bw, priv->data->respective_ostdl);
				} else {
					bw_val += (stash_bw * dmr_enable);
				}
			}
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dmrr_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			oddmr_data->last_hrt_dmrr = bw_val;
			oddmr_data->last_hrt_dmrr_stash = stash_bw;

			/* DBI outstanding */
			layer_num = mtk_oddmr_dbi_bpp(comp);
			bw_val = (layer_num * bw_base) / 400;
			if (oddmr_data->data->is_dbi_support_stash && oddmr_data->data->dbi_version != MTK_DBI_V3) {
				/* stash bw = data_bw / 4096 * 16 */
				bw_val += (bw_val / 256 > 17) ? (bw_val / 256) : 17;
			}
			bw_val *= (dbi_enable > 0) ? 1 : 0;
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			if(oddmr_data->data->is_dbi_support_stash && oddmr_data->data->dbi_version == MTK_DBI_V3){
				if(bw_val) {
					stash_bw = ((bw_val / 256) > oddmr_data->data->min_stash_port_bw ?
						((bw_val / 256)) : oddmr_data->data->min_stash_port_bw);
					__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_stash_hrt,
							comp->id, stash_bw, priv->data->respective_ostdl);
				} else
					__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_stash_hrt,
							comp->id, 0, priv->data->respective_ostdl);
			}
			oddmr_data->last_hrt_dbir = bw_val;

			/* OD outstanding */
			if (od_enable) {
				/* OD R/W data bw = bpp * base_bw / 400 */
				//mtk_oddmr_od_bpp_v return R+W bpp
				if (oddmr_data->data->od_version >= MTK_OD_V2)
					layer_num = mtk_oddmr_od_bpp_v(comp,
						od_param->od_basic_info.basic_param.od_mode);
				else
					layer_num = mtk_oddmr_od_bpp(comp,
						od_param->od_basic_info.basic_param.od_mode);
				bw_val = DIV_ROUND_UP(layer_num * bw_base, 2 * 400);
				/* OD R/W stash bw = data_bw / 4096 * 16 */
				if (oddmr_data->data->is_od_support_stash &&
						oddmr_data->data->od_version >= MTK_OD_V3) {
					stash_bw = bw_val / 256;
					stash_bw = stash_bw > oddmr_data->data->min_stash_port_bw ?
						stash_bw : oddmr_data->data->min_stash_port_bw; //set low bound
				}
			} else {
				bw_val = 0;
				stash_bw = 0;
			}
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odr_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odw_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			oddmr_data->last_hrt_odrw = bw_val;
			if (oddmr_data->data->is_od_support_stash &&
					oddmr_data->data->od_version >= MTK_OD_V3) {
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_odr_stash_hrt, comp->id, stash_bw,
					priv->data->respective_ostdl);
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_odw_stash_hrt, comp->id, stash_bw,
					priv->data->respective_ostdl);
				oddmr_data->last_hrt_odrw_stash = stash_bw;
			}
		} else {
			oddmr_data->last_hrt_dmrr = dmr_enable;
			oddmr_data->last_hrt_dbir = dbi_enable;
			oddmr_data->last_hrt_odrw = od_enable;
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dmrr_hrt, comp->id, dmr_enable,
				priv->data->respective_ostdl);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_hrt, comp->id, dbi_enable,
				priv->data->respective_ostdl);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odr_hrt, comp->id, od_enable,
				priv->data->respective_ostdl);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odw_hrt, comp->id, od_enable,
				priv->data->respective_ostdl);
		}
		ODDMRLOW_LOG("hrt od %d dmr %d\n", od_enable, dmr_enable);
	}
		break;
	case PMQOS_SET_HRT_BW_DELAY:
	{
		int od_enable, dmr_enable, dbi_enable, sec_on;
		u32 bw_val, bw_base = *(unsigned int *)params;
		struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
		struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
		u32 layer_num = 0;
		u32 stash_bw = 0;
		int cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
		struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;

		if (!mtk_drm_helper_get_opt(priv->helper_opt, MTK_DRM_OPT_MMQOS_SUPPORT))
			break;
		if (!priv->data->respective_ostdl) {
			PC_ERR("respective_ostdl do not set\n");
			break;
		}
		if (!handle) {
			PC_ERR("no cmdq handle\n");
			break;
		}

		sec_on = comp->mtk_crtc->sec_on;
		od_enable = oddmr_data->od_enable && (!sec_on);
		dmr_enable = oddmr_data->dmr_enable;
		dbi_enable = oddmr_data->dbi_enable;
		od_enable = !!bw_base && od_enable;
		dmr_enable = !!bw_base && dmr_enable;
		dbi_enable = !!bw_base && dbi_enable;

		/* DMR outstanding */
		if (cur_bin_idx == -1)
			dmr_enable = 0;
		layer_num = mtk_oddmr_dmr_bpp(comp, false);
		bw_val = (layer_num * bw_base / 400) * dmr_enable;
		if (oddmr_data->data->is_dmr_support_stash) {
			/* stash bw = data_bw / 4096 * 16 */
			stash_bw = bw_val / 256;
			stash_bw = stash_bw > oddmr_data->data->min_stash_port_bw ?
				stash_bw : oddmr_data->data->min_stash_port_bw; //set low bound
			if (oddmr_data->data->dbi_version == MTK_DBI_V3)
				stash_bw = stash_bw * dmr_enable;
			else
				bw_val += (stash_bw * dmr_enable);
		}
		if (bw_val > oddmr_data->last_hrt_dmrr) {
			ODDMRLOW_LOG("dmrr bw_val fast up %u -> %u\n", oddmr_data->last_hrt_dmrr, bw_val);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dmrr_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
				mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_DMRR),
				NO_PENDING_HRT, ~0);
			if (oddmr_data->data->dbi_version >= MTK_DBI_V3) {
				ODDMRLOW_LOG("dmrr stash_bw fast up %u -> %u\n",
					oddmr_data->last_hrt_dmrr_stash, stash_bw);
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_dmrr_stash_hrt,
					comp->id, stash_bw, priv->data->respective_ostdl);
				cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
					mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_DMRR_STASH),
					NO_PENDING_HRT, ~0);
			}
		} else if (bw_val < oddmr_data->last_hrt_dmrr) {
			ODDMRLOW_LOG("dmrr bw_val will slow down %u -> %u\n",
				oddmr_data->last_hrt_dmrr, bw_val);
			cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
				mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_DMRR),
				bw_val, ~0);
			if (oddmr_data->data->dbi_version >= MTK_DBI_V3) {
				ODDMRLOW_LOG("dmrr stash_bw will slow down %u -> %u\n",
					oddmr_data->last_hrt_dmrr_stash, stash_bw);
				cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
					mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_DMRR_STASH),
					stash_bw, ~0);
			}
		}
		oddmr_data->last_hrt_dmrr = bw_val;
		oddmr_data->last_hrt_dmrr_stash = stash_bw;

		/* DBI outstanding */
		layer_num = mtk_oddmr_dbi_bpp(comp);
		bw_val = (layer_num * bw_base) / 400;
		if (oddmr_data->data->is_dbi_support_stash && oddmr_data->data->dbi_version != MTK_DBI_V3) {
			/* stash bw = data_bw / 4096 * 16 */
			bw_val += (bw_val / 256 > 17) ? (bw_val / 256) : 17;
		}
		bw_val *= (dbi_enable > 0) ? 1 : 0;
		if (bw_val > oddmr_data->last_hrt_dbir) {
			ODDMRLOW_LOG("dbir bw_val fast up %u -> %u\n", oddmr_data->last_hrt_dbir, bw_val);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
				mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_DBIR),
				NO_PENDING_HRT, ~0);
			if(oddmr_data->data->is_dbi_support_stash && oddmr_data->data->dbi_version == MTK_DBI_V3){
				if(bw_val) {
					stash_bw = ((bw_val / 256) > oddmr_data->data->min_stash_port_bw ?
						((bw_val / 256)) : oddmr_data->data->min_stash_port_bw);
					__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_stash_hrt,
							comp->id, stash_bw, priv->data->respective_ostdl);
				} else
					__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_stash_hrt,
							comp->id, 0, priv->data->respective_ostdl);
			}
		} else if (bw_val < oddmr_data->last_hrt_dbir) {
			ODDMRLOW_LOG("dbir bw_val will slow down %u -> %u\n",
				oddmr_data->last_hrt_dbir, bw_val);
			cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
				mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_DBIR),
				bw_val, ~0);
		}
		oddmr_data->last_hrt_dbir = bw_val;

		/* OD outstanding */
		if (od_enable) {
			/* OD R/W data bw = bpp * base_bw / 400 */
			//mtk_oddmr_od_bpp_v return R+W bpp
			if (oddmr_data->data->od_version >= MTK_OD_V2)
				layer_num = mtk_oddmr_od_bpp_v(comp,
					od_param->od_basic_info.basic_param.od_mode);
			else
				layer_num = mtk_oddmr_od_bpp(comp,
					od_param->od_basic_info.basic_param.od_mode);
			bw_val = DIV_ROUND_UP(layer_num * bw_base, 2 * 400);
			/* OD R/W stash bw = data_bw / 4096 * 16 */
			if (oddmr_data->data->is_od_support_stash &&
					oddmr_data->data->od_version >= MTK_OD_V3) {
				stash_bw = bw_val / 256;
				stash_bw = stash_bw > oddmr_data->data->min_stash_port_bw ?
					stash_bw : oddmr_data->data->min_stash_port_bw; //set low bound
			}
		} else {
			bw_val = 0;
			stash_bw = 0;
		}
		if (bw_val > oddmr_data->last_hrt_odrw) {
			ODDMRLOW_LOG("odrw bw_val fast up %u -> %u\n", oddmr_data->last_hrt_odrw, bw_val);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odr_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odw_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
				mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_ODRW),
				NO_PENDING_HRT, ~0);
			if (oddmr_data->data->is_od_support_stash &&
					oddmr_data->data->od_version >= MTK_OD_V3) {
				ODDMRLOW_LOG("odrw stash_bw fast up %u -> %u\n",
					oddmr_data->last_hrt_odrw_stash, stash_bw);
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_odr_stash_hrt, comp->id, stash_bw,
					priv->data->respective_ostdl);
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_odw_stash_hrt, comp->id, stash_bw,
					priv->data->respective_ostdl);
				cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
					mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_ODRW_STASH),
					NO_PENDING_HRT, ~0);
			}
		} else if (bw_val < oddmr_data->last_hrt_odrw) {
			ODDMRLOW_LOG("odrw bw_val will slow down %u -> %u\n",
				oddmr_data->last_hrt_odrw, bw_val);
			cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
				mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_ODRW),
				bw_val, ~0);
			if (oddmr_data->data->is_od_support_stash &&
					oddmr_data->data->od_version >= MTK_OD_V3) {
				ODDMRLOW_LOG("odrw stash_bw will slow down %u -> %u\n",
					oddmr_data->last_hrt_odrw_stash, stash_bw);
				cmdq_pkt_write(handle, mtk_crtc->gce_obj.base,
					mtk_get_gce_backup_slot_pa(mtk_crtc, DISP_SLOT_CUR_HRT_VAL_ODRW_STASH),
					stash_bw, ~0);
			}
		}
		oddmr_data->last_hrt_odrw = bw_val;
		if (oddmr_data->data->is_od_support_stash &&
				oddmr_data->data->od_version >= MTK_OD_V3)
			oddmr_data->last_hrt_odrw_stash = stash_bw;

		ODDMRLOW_LOG("hrt dmrr %d dbir %d odrw %d\n",
			oddmr_data->last_hrt_dmrr, oddmr_data->last_hrt_dbir, oddmr_data->last_hrt_odrw);
	}
		break;
	case PMQOS_SET_HRT_BW_DELAY_POST:
	{
		u32 bw_val = 0;
		u32 stash_bw = 0;
		struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
		struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;

		if (!mtk_drm_helper_get_opt(priv->helper_opt, MTK_DRM_OPT_MMQOS_SUPPORT))
			break;

		if (!priv->data->respective_ostdl) {
			PC_ERR("respective_ostdl do not set\n");
			break;
		}

		/* DMR outstanding */
		bw_val = *(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
			DISP_SLOT_CUR_HRT_VAL_DMRR);
		stash_bw = *(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
			DISP_SLOT_CUR_HRT_VAL_DMRR_STASH);
		if (bw_val != NO_PENDING_HRT && bw_val >= oddmr_data->last_hrt_dmrr) {
			ODDMRLOW_LOG("dmrr bw_val final down to %u,last:%u\n", bw_val, oddmr_data->last_hrt_dmrr);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dmrr_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			*(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
				DISP_SLOT_CUR_HRT_VAL_DMRR) = NO_PENDING_HRT;
			if (oddmr_data->data->dbi_version >= MTK_DBI_V3) {
				ODDMRLOW_LOG("dmrr stash bw final down to %u,last:%u\n",
					stash_bw, oddmr_data->last_hrt_dmrr_stash);
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_dmrr_stash_hrt,
					comp->id, stash_bw, priv->data->respective_ostdl);
				*(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
					DISP_SLOT_CUR_HRT_VAL_DMRR_STASH) = NO_PENDING_HRT;
			}
		}

		/* DBI outstanding */
		bw_val = *(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
			DISP_SLOT_CUR_HRT_VAL_DBIR);
		if (bw_val != NO_PENDING_HRT && bw_val >= oddmr_data->last_hrt_dbir) {
			ODDMRLOW_LOG("dbir bw_val final down to %u,last:%u\n", bw_val, oddmr_data->last_hrt_dbir);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			*(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
				DISP_SLOT_CUR_HRT_VAL_DBIR) =	NO_PENDING_HRT;
			if(oddmr_data->data->is_dbi_support_stash && oddmr_data->data->dbi_version == MTK_DBI_V3){
				if(bw_val) {
					stash_bw = ((bw_val / 256) > oddmr_data->data->min_stash_port_bw ?
						((bw_val / 256)) : oddmr_data->data->min_stash_port_bw);
					__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_stash_hrt,
							comp->id, stash_bw, priv->data->respective_ostdl);
				} else
					__mtk_disp_set_module_hrt(oddmr_data->qos_req_dbir_stash_hrt,
							comp->id, 0, priv->data->respective_ostdl);
			}
		}

		/* OD outstanding */
		bw_val = *(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
			DISP_SLOT_CUR_HRT_VAL_ODRW);
		if (bw_val != NO_PENDING_HRT && bw_val >= oddmr_data->last_hrt_odrw) {
			ODDMRLOW_LOG("odrw bw_val final down to %u,last:%u\n", bw_val, oddmr_data->last_hrt_odrw);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odr_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			__mtk_disp_set_module_hrt(oddmr_data->qos_req_odw_hrt, comp->id, bw_val,
				priv->data->respective_ostdl);
			*(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
				DISP_SLOT_CUR_HRT_VAL_ODRW) =	NO_PENDING_HRT;
			if (oddmr_data->data->is_od_support_stash &&
					oddmr_data->data->od_version >= MTK_OD_V3) {
				stash_bw = *(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
					DISP_SLOT_CUR_HRT_VAL_ODRW_STASH);
				ODDMRLOW_LOG("odrw stash_bw final down to %u,last:%u\n",
					stash_bw, oddmr_data->last_hrt_odrw_stash);
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_odr_stash_hrt, comp->id, stash_bw,
					priv->data->respective_ostdl);
				__mtk_disp_set_module_hrt(oddmr_data->qos_req_odw_stash_hrt, comp->id, stash_bw,
					priv->data->respective_ostdl);
				*(unsigned int *)mtk_get_gce_backup_slot_va(mtk_crtc,
					DISP_SLOT_CUR_HRT_VAL_ODRW_STASH) =	NO_PENDING_HRT;
			}
		}
	}
		break;
	case GET_VALID_PARTIAL_ROI:
	{
		struct mtk_rect *partial_roi = NULL;

		partial_roi = (struct mtk_rect *)params;
		mtk_cal_oddmr_valid_partial_roi(comp, partial_roi);
	}
		break;
	case BYPASS_SPR2RGB:
	{
		bool s2r_bypass = *(bool *)params;

		mtk_oddmr_s2r_bypass(comp, handle, s2r_bypass);
	}
		break;
	case GET_ODDMR_CUS_OWN_DATA:
	{
		struct cus_own_data *cus_data = NULL;

		ODDMRLOW_LOG("+\n");
		if (oddmr_data->is_right_pipe)
			break;
		cus_data = (struct cus_own_data *)params;
		mtk_oddmr_get_dmr_cus_own_data(comp, cus_data);
	}
		break;
	default:
		break;
	}
	return 0;
}

static void mtk_oddmr_od_bypass(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRLOW_LOG("+\n");
	mtk_oddmr_write(comp, 1,
			DISP_ODDMR_TOP_OD_BYASS, handle);
	if (oddmr_data->data->od_version < MTK_OD_V2)
		mtk_oddmr_write(comp, 0x200, DISP_ODDMR_OD_SW_RESET, handle);
}

/*
 * content fps computed by diff of two dirty-frame sof
 * current_timing records vrefresh
 * content_timing records content fps
 * content_timing and current_timing record same bl
 */
static void mtk_oddmr_od_content_timing(struct mtk_disp_oddmr *oddmr_data,
		struct mtk_oddmr_timing *content_timing)
{
	ktime_t sof_diff = 0;
	unsigned int content_fps = 0;
	struct mtk_oddmr_timing *current_timing = &oddmr_data->primary_data->current_timing;

	sof_diff = oddmr_data->primary_data->sof_time - oddmr_data->primary_data->sof_time_last; //ns
	if (sof_diff <= 0) {
		content_fps = current_timing->vrefresh;
		ODDMRAPI_LOG("error: sof_diff<=0, content_fps=vrefresh\n");
	} else {
		content_fps = 1000000000 / sof_diff;
	}
	ODDMRAPI_LOG("sof: last %lld, curr %lld, diff %lld; content_fps %d\n",
			oddmr_data->primary_data->sof_time_last,
			oddmr_data->primary_data->sof_time, sof_diff, content_fps);

	content_timing->vrefresh = content_fps;
	content_timing->bl_level = current_timing->bl_level;
	ODDMRAPI_LOG("content_timing: old_vrefresh %d, vrefresh %d, old_bl_level %d, bl_level %d\n",
			content_timing->old_vrefresh, content_timing->vrefresh,
			content_timing->old_bl_level, content_timing->bl_level);
}

/*
 * od table changes by bl and vrefresh (content fps when od_fps_mode=1)
 * od_force_off = true if vrefresh and/or bl not supported (when od_fps_mode=0)
 * od_force_off also changed by mtk_oddmr_od_timing_chg_dual and mtk_oddmr_od_bl_chg
 * od_force_off2 = true if content fps and/or bl not supported (when od_fps_mode=1)
 * old_vrefresh and old_bl_level will only record last supported fps and bl
 */
static void mtk_oddmr_od_table_chg_by_timing(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle,
		struct mtk_oddmr_timing *current_timing)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_ddp_comp *comp1;
	struct mtk_disp_oddmr *oddmr1_data = NULL;
	uint32_t weight[3] = {0};
	int ret = 0;
	uint32_t od_fps_mode = oddmr_data->primary_data->od_fps_mode;
	int od_update_sram_last = 0;
	bool check_force_flip = false;
	static unsigned int old_vrefresh, old_bl_level;
	int sram_idx, sram_table_idx, table_idx;

	ODDMRAPI_LOG("+\n");
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		od_update_sram_last = oddmr_data->od_update_sram;
		oddmr_data->od_update_sram = 0;
	}
	if (current_timing->old_vrefresh != current_timing->vrefresh ||
		current_timing->old_bl_level != current_timing->bl_level) {
		check_force_flip = (oddmr_data->data->od_version >= MTK_OD_V2) && (od_fps_mode == 1) &&
			(od_update_sram_last == 1); //check if need force flip in mtk_oddmr_od_table_lookup.
		ret = mtk_oddmr_od_table_lookup(oddmr_data, current_timing, &table_idx, check_force_flip);
		ODDMRLOW_LOG("od_table_chg_ret %d, check_force_flip %d\n", ret, check_force_flip);
		if (comp->mtk_crtc->is_dual_pipe) {
			comp1 = oddmr_data->companion;
			oddmr1_data = comp_to_oddmr(comp1);
		}
		if (ret >= 0) {
			if (ret == 1) {
				//flip
				mtk_oddmr_od_flip(comp, handle);
				if (comp->mtk_crtc->is_dual_pipe)
					mtk_oddmr_od_flip(comp1, handle);
				current_timing->old_vrefresh = current_timing->vrefresh;
				current_timing->old_bl_level = current_timing->bl_level;
			} else if (oddmr_data->data->is_od_table_bl_chg && ret == 2) {
				if (oddmr_data->data->od_version >= MTK_OD_V2)
					oddmr_data->od_update_sram = 1;
				oddmr_data->primary_data->update_table_work.data = (void *)comp;
				queue_work(oddmr_data->primary_data->oddmr_wq, &oddmr_data->primary_data->update_table_work.task);
				old_vrefresh = current_timing->vrefresh;
				old_bl_level = current_timing->bl_level;
			} else if (ret == 0) {
				//current table is best choice, or sram is updating
				current_timing->old_vrefresh = current_timing->vrefresh;
				current_timing->old_bl_level = current_timing->bl_level;
			} else if (ret == 3) {
				// force flip sram
				mtk_oddmr_od_flip(comp, handle);
				if (comp->mtk_crtc->is_dual_pipe)
					mtk_oddmr_od_flip(comp1, handle);
				current_timing->old_vrefresh = old_vrefresh;
				current_timing->old_bl_level = old_bl_level;
			}

			mtk_oddmr_od_gain_lookup(comp, current_timing->vrefresh,
					current_timing->bl_level, table_idx, weight);
			mtk_oddmr_set_od_weight_dual(comp, weight, handle);
			if (od_fps_mode == 1) {
				oddmr_data->od_force_off2 = false;
				if (comp->mtk_crtc->is_dual_pipe)
					oddmr1_data->od_force_off2 = false;
			} else {
				oddmr_data->od_force_off = false;
				if (comp->mtk_crtc->is_dual_pipe)
					oddmr1_data->od_force_off = false;
			}
		} else {
			if (od_fps_mode == 1) {
				oddmr_data->od_force_off2 = true;
				if (comp->mtk_crtc->is_dual_pipe)
					oddmr1_data->od_force_off2 = true;
			} else {
				oddmr_data->od_force_off = true;
				if (comp->mtk_crtc->is_dual_pipe)
					oddmr1_data->od_force_off = true;
			}
		}
	} else {
		if (od_fps_mode == 1) {
			oddmr_data->od_force_off2 =false;
			if (comp->mtk_crtc->is_dual_pipe)
				oddmr1_data->od_force_off2 = false;
		}
		if (oddmr_data->od_force_off_last &&
			!oddmr_data->od_force_off && !oddmr_data->od_force_off2) {
			sram_idx = oddmr_data->od_data.od_sram_read_sel;
			sram_table_idx = oddmr_data->od_data.od_sram_table_idx[!!sram_idx];
			table_idx = oddmr_data->od_data.od_dram_sel[sram_table_idx];
			mtk_oddmr_od_gain_lookup(comp, current_timing->vrefresh,
					current_timing->bl_level, table_idx, weight);
			if (oddmr_data->data->od_version >= MTK_OD_V3)
				DDPMSG("OD weight restore from force off: R %u G %u B %u (sram%d %d table%d)\n",
					weight[0], weight[1], weight[2], sram_idx, sram_table_idx, table_idx);
			else
				DDPMSG("OD weight restore from force off: %u (sram%d %d table%d)\n",
					weight[1], sram_idx, sram_table_idx, table_idx);
			mtk_oddmr_set_od_weight_dual(comp, weight, handle);
		}
	}
	ODDMRAPI_LOG("old_vrefresh %d, vrefresh %d, old_bl_level %d, bl_level %d\n",
			current_timing->old_vrefresh, current_timing->vrefresh,
			current_timing->old_bl_level, current_timing->bl_level);
}

/*
 * table changed by vrefresh and bl if od_fps_mode=0
 * table changed by content_fps and bl if od_fps_mode=1
 */
static void mtk_oddmr_od_table_chg(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_timing *current_timing = &oddmr_data->primary_data->current_timing;
	struct mtk_oddmr_timing *od_content_timing = &oddmr_data->primary_data->od_content_timing;

	if (oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE) {
		ODDMRAPI_LOG("+\n");
		if (oddmr_data->primary_data->od_fps_mode == 1){
			mtk_oddmr_od_content_timing(oddmr_data, od_content_timing);
			mtk_oddmr_od_table_chg_by_timing(comp, handle, od_content_timing);
			return;
		}
		mtk_oddmr_od_table_chg_by_timing(comp, handle, current_timing);
	}
}

static void mtk_oddmr_set_od_enable(struct mtk_ddp_comp *comp, uint32_t enable,
		bool force_config, struct cmdq_pkt *handle)
{
	bool sec_on, en, od_force_off;
	uint32_t value = 0, mask = 0;
	uint32_t weight[3] = {0};
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_ddp_comp *output_comp = NULL;
	unsigned int dsi_line_time = 0;
	unsigned int stash_lead_time = 12;
	unsigned int stash_lead_cnt = 0;
	int sram_idx, sram_table_idx, table_idx;

	if (oddmr_data->primary_data->od_state < ODDMR_INIT_DONE)
		return;
	sec_on = comp->mtk_crtc->sec_on;
	en = enable && !sec_on;
	od_force_off = (oddmr_data->od_force_off || oddmr_data->od_force_off2);
	ODDMRAPI_LOG("en %d: enable %d, sec_on %d; force_config %d\n",
		en, enable, sec_on, force_config);
	ODDMRAPI_LOG("force_off %d, force_off2 %d, force_off_last %d\n",
		oddmr_data->od_force_off, oddmr_data->od_force_off2, oddmr_data->od_force_off_last);
	mtk_oddmr_od_srt_cal(comp, en);
	if (force_config || en != oddmr_data->od_enable_last) {
		if (en) {
			if (oddmr_data->data->is_od_support_hw_skip_first_frame) {
				sram_idx = oddmr_data->od_data.od_sram_read_sel;
				sram_table_idx = oddmr_data->od_data.od_sram_table_idx[!!sram_idx];
				table_idx = oddmr_data->od_data.od_dram_sel[sram_table_idx];
				if (oddmr_data->primary_data->od_fps_mode == 1)
					mtk_oddmr_od_gain_lookup(comp,
						oddmr_data->primary_data->od_content_timing.vrefresh,
						oddmr_data->primary_data->od_content_timing.bl_level,
						table_idx, weight);
				else
					mtk_oddmr_od_gain_lookup(comp,
						oddmr_data->primary_data->current_timing.vrefresh,
						oddmr_data->primary_data->current_timing.bl_level,
						table_idx, weight);
				if (oddmr_data->data->od_version >= MTK_OD_V3)
					DDPMSG("OD weight: R %u G %u B %u (sram%d %d table%d)\n",
						weight[0], weight[1], weight[2], sram_idx, sram_table_idx, table_idx);
				else
					DDPMSG("OD weight: %u (sram%d %d table%d)\n",
						weight[1], sram_idx, sram_table_idx, table_idx);
			} else if (!od_force_off) {
				atomic_set(&oddmr_data->primary_data->od_weight_trigger, 1);
			}
			mtk_oddmr_set_od_weight(comp, weight, handle);

			mtk_oddmr_od_init_end(comp, handle);
			if (oddmr_data->data->od_version >= MTK_OD_V2 &&
				!force_config &&
				oddmr_data->od_data.od_set_pu_done == 0)
				mtk_oddmr_od_set_full_height(comp, handle);
			if (oddmr_data->data->od_version >= MTK_OD_V3) {
				if (oddmr_data->data->sodi_config)
					oddmr_data->data->sodi_config(comp->mtk_crtc->base.dev, comp->id, handle, &en);
				SET_VAL_MASK(value, mask, 1, REG_OD_EN);
				SET_VAL_MASK(value, mask, 1, REG_OD_FORCE_EN);
				mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_OD_CTRL_EN, mask, handle);
				value = 0; mask = 0;
				mtk_oddmr_write(comp, 0, DISP_ODDMR_TOP_OD_BYASS, handle);
				//OD DDREN ctrl
				SET_VAL_MASK(value, mask, 0, REG_OD_DDREN_REQ_DISABLE);
				SET_VAL_MASK(value, mask, 1, REG_OD_USE_HRT_DDREN_REQ);
				if (oddmr_data->data->is_od_support_stash) {
					SET_VAL_MASK(value, mask, 0, REG_OD_STASH_DDREN_REQ_DISABLE);
					SET_VAL_MASK(value, mask, 1, REG_OD_STASH_USE_HRT_DDREN_REQ);
				}
				mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DDREN_CTRL_ODW, mask, handle);
				mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DDREN_CTRL_ODR, mask, handle);
				/* stash_lead_cnt = stash_lead_time / dsi_line_time */
				if (oddmr_data->data->is_od_support_stash) {
					stash_lead_time = oddmr_data->data->stash_lead_time;
					output_comp = mtk_ddp_comp_request_output(comp->mtk_crtc);
					if (output_comp && (mtk_ddp_comp_get_type(output_comp->id) == MTK_DSI))
						mtk_ddp_comp_io_cmd(output_comp, NULL,
							DSI_GET_LINE_TIME_NS, &dsi_line_time);
					dsi_line_time /= 1000;
					if (dsi_line_time > 0)
						stash_lead_cnt = (stash_lead_time + dsi_line_time - 1) / dsi_line_time;
					value = (1 << 8) | stash_lead_cnt;
					mtk_oddmr_write(comp, value, MT6993_DISP_ODDMR_UDMA_R_CTRL30, handle);
					mtk_oddmr_write(comp, value, MT6993_DISP_ODDMR_UDMA_W_CTR_1B, handle);
				}
			} else if (oddmr_data->data->od_version == MTK_OD_V2) {
				mtk_oddmr_write_mask(comp, 1, MT6991_DISP_ODDMR_OD_CTRL_EN, 0x01, handle);
				mtk_oddmr_write(comp, 0, DISP_ODDMR_TOP_OD_BYASS, handle);
				mtk_oddmr_write(comp, 4, MT6991_DISP_ODDMR_REG_ODW_DDREN_CTRL, handle);
				mtk_oddmr_write(comp, 4, MT6991_DISP_ODDMR_REG_ODR_DDREN_CTRL, handle);
			} else {
				mtk_oddmr_write_mask(comp, 1, DISP_ODDMR_OD_CTRL_EN, 0x01, handle);
			}
		} else {
			if (oddmr_data->data->od_version >= MTK_OD_V3) {
				SET_VAL_MASK(value, mask, 0, REG_OD_EN);
				SET_VAL_MASK(value, mask, 0, REG_OD_FORCE_EN);
				mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_OD_CTRL_EN, mask, handle);
				value = 0; mask = 0;
				mtk_oddmr_od_bypass(comp, handle);
				//OD DDREN ctrl
				SET_VAL_MASK(value, mask, 1, REG_OD_DDREN_REQ_DISABLE);
				SET_VAL_MASK(value, mask, 0, REG_OD_USE_HRT_DDREN_REQ);
				if (oddmr_data->data->is_od_support_stash) {
					SET_VAL_MASK(value, mask, 1, REG_OD_STASH_DDREN_REQ_DISABLE);
					SET_VAL_MASK(value, mask, 0, REG_OD_STASH_USE_HRT_DDREN_REQ);
				}
				mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DDREN_CTRL_ODW, mask, handle);
				mtk_oddmr_write_mask(comp, value, DISP_ODDMR_DDREN_CTRL_ODR, mask, handle);
				// close stash
				if (oddmr_data->data->is_od_support_stash) {
					mtk_oddmr_write(comp, 0, MT6993_DISP_ODDMR_UDMA_R_CTRL30, handle);
					mtk_oddmr_write(comp, 0, MT6993_DISP_ODDMR_UDMA_W_CTR_1B, handle);
				}
				mtk_oddmr_set_od_clk(comp, 0, handle);
				if (oddmr_data->data->sodi_config)
					oddmr_data->data->sodi_config(comp->mtk_crtc->base.dev, comp->id, handle, &en);
			} else if (oddmr_data->data->od_version == MTK_OD_V2) {
				mtk_oddmr_write_mask(comp, 0, MT6991_DISP_ODDMR_OD_CTRL_EN, 0x01, handle);
				mtk_oddmr_od_bypass(comp, handle);
				mtk_oddmr_write(comp, 9, MT6991_DISP_ODDMR_REG_ODW_DDREN_CTRL, handle);
				mtk_oddmr_write(comp, 9, MT6991_DISP_ODDMR_REG_ODR_DDREN_CTRL, handle);
				mtk_oddmr_set_od_clk(comp, 0, handle);
			} else {
				mtk_oddmr_write_mask(comp, 0, DISP_ODDMR_OD_CTRL_EN, 0x01, handle);
				mtk_oddmr_od_bypass(comp, handle);
			}
		}
		oddmr_data->od_enable_last = en;
		oddmr_data->od_force_off_last = od_force_off;
	} else if (od_force_off != oddmr_data->od_force_off_last) {
		if (od_force_off) {
			DDPMSG("OD weight force off\n");
			mtk_oddmr_set_od_weight(comp, weight, handle);
		}
		oddmr_data->od_force_off_last = od_force_off;
	}
	if (oddmr_data->data->od_version >= MTK_OD_V2)
		oddmr_data->od_data.od_set_pu_done = 0;
}

int mtk_oddmr_get_od_enable(struct mtk_ddp_comp *comp)
{
	int en;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	if (oddmr_data->data->od_version < MTK_OD_V2)
		return 0;
	if (oddmr_data->primary_data->od_state < ODDMR_INIT_DONE)
		return 0;
	en = oddmr_data->od_enable && !comp->mtk_crtc->sec_on;
	ODDMRLOW_LOG("en %d: od_enable %d, sec_on %d\n",
		en, oddmr_data->od_enable, comp->mtk_crtc->sec_on);
	return en;
}

int mtk_oddmr_get_dmr_enable(struct mtk_ddp_comp *comp)
{
	int en = 0;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);

	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE)
		return 0;
	if ((oddmr_data->dmr_enable == 1) && (cur_bin_idx != -1))
		en = 1;
	ODDMRLOW_LOG("en %d: dmr_enable %d, cur_bin_idx %d\n",
		en, oddmr_data->dmr_enable, cur_bin_idx);

	return en;
}

int mtk_oddmr_get_dbi_enable(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRLOW_LOG("dbi_enable %d\n", oddmr_data->dbi_enable);
	return oddmr_data->dbi_enable;
}

static void mtk_oddmr_bypass(struct mtk_ddp_comp *comp, int bypass,
		int caller, struct cmdq_pkt *handle)
{
	ODDMRAPI_LOG("+\n");
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool od_support;

	if (oddmr_data->is_right_pipe)
		return;
	od_support = oddmr_data->primary_data->od_support;
	if (od_support && (oddmr_data->pq_od_bypass != bypass)) {
		oddmr_data->pq_od_bypass = bypass;
		oddmr_data->od_enable =
			oddmr_data->od_enable_req && !oddmr_data->pq_od_bypass;

		if (comp->mtk_crtc->is_dual_pipe) {
			struct mtk_ddp_comp *comp1 = oddmr_data->companion;
			struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

			oddmr1_data->pq_od_bypass = bypass;
			oddmr1_data->od_enable =
				oddmr1_data->od_enable_req && !oddmr1_data->pq_od_bypass;
		}
		ODDMRLOW_LOG("pq_od_bypass %d, caller: 0x%x, od_enable %d\n",
			oddmr_data->pq_od_bypass, caller, oddmr_data->od_enable);
		if (bypass == 0) {
			mtk_oddmr_set_od_enable_dual(comp,
				oddmr_data->od_enable_req, false, handle);
		} else if (bypass == 1) {
			mtk_oddmr_set_od_enable_dual(comp, 0, false, handle);
		}
	}
}

static void mtk_oddmr_set_od_enable_dual(struct mtk_ddp_comp *comp, uint32_t enable,
		bool force_config, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_ddp_comp *comp1;
	struct mtk_disp_oddmr *oddmr1_data;
	bool sec_on, en;
	int od_update_sram_last = 0;

	ODDMRAPI_LOG("+\n");
	sec_on = comp->mtk_crtc->sec_on;
	if (comp->mtk_crtc->is_dual_pipe) {
		comp1 = oddmr_data->companion;
		oddmr1_data = comp_to_oddmr(comp1);
		sec_on = sec_on && comp1->mtk_crtc->sec_on;
	}

	en = enable && !sec_on && !oddmr_data->od_force_off;
	if (comp->mtk_crtc->is_dual_pipe)
		en = en && !oddmr1_data->od_force_off;

	if (oddmr_data->data->od_version >= MTK_OD_V2 &&
		oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE)
		od_update_sram_last = oddmr_data->od_update_sram;

	// od_update_sram = 1 means OD will or still update sram table
	if(en && oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE)
		mtk_oddmr_od_table_chg(comp, handle); //will update od_update_sram
	else if (oddmr_data->primary_data->od_state == ODDMR_INIT_DONE) //!=ODDMR_TABLE_UPDATING
		oddmr_data->od_update_sram = 0;

	// mtk_oddmr_set_od_enable will close top_clk if od_update_sram = 0
	mtk_oddmr_set_od_enable(comp, enable, force_config, handle);
	if (comp->mtk_crtc->is_dual_pipe)
		mtk_oddmr_set_od_enable(comp1, enable, force_config, handle);

	//updating sram done, top_clk can be closed
	if (oddmr_data->data->od_version == MTK_OD_V2  &&
			od_update_sram_last == 1 && oddmr_data->od_update_sram == 0 &&
			!oddmr_data->dmr_enable)
		mtk_oddmr_set_top_clk_force(comp, 0, handle);
}

static void mtk_oddmr_set_dmr_enable(struct mtk_ddp_comp *comp, uint32_t enable,
		struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_ddp_comp *output_comp = NULL;
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	uint32_t reg_val;
	unsigned int dsi_line_time = 0;
	unsigned int stash_lead_time = 12;
	unsigned int stash_lead_cnt = 0;
	uint32_t value = 0, mask = 0;
	bool dmr_support;
	int cur_bin_idx;
	unsigned int cur_dbv, cur_fps, cur_dbv_mode, cur_binset_idx;

	ODDMRAPI_LOG("+\n");

	mtk_oddmr_dmr_srt_cal(comp, enable);
	dmr_support = oddmr_data->primary_data->dmr_support;
	if(!dmr_support) {
		ODDMRAPI_LOG("%s: DeMura is not supported!\n", __func__);
		return;
	}
	if (enable) {
		if (oddmr_data->data->dbi_version == MTK_DBI_V3) {
			//0.reg_dmr_swt_rst 1->0
			value = 0;mask = 0;
			SET_VAL_MASK(value, mask, 1, MT6993_REG_DMR_SW_RST);
			mtk_oddmr_write_mask(comp, value,
				MT6993_DISP_ODDMR_TOP_CTR_4, mask, handle);

			value = 0;mask = 0;
			SET_VAL_MASK(value, mask, 0, MT6993_REG_DMR_SW_RST);
			mtk_oddmr_write_mask(comp, value,
				MT6993_DISP_ODDMR_TOP_CTR_4, mask, handle);

			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, MT6993_REG_DMR_CLK_EN);
			mtk_oddmr_write_mask(comp, value,
				MT6993_DISP_ODDMR_REG_DMR_CLK_EN, mask, handle);
		} else {
			//1.reg_oddmr_top_clk_force_en=1; reg_oddmr_top_clk_gating_db_en=1
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
			SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_TOP_CLK_GATING_DB_EN);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);
			//2.reg_dmr_clk_en=1
			mtk_oddmr_write(comp, 1,
				MT6991_DISP_ODDMR_REG_DMR_CLK_EN, handle);
			//3.reg_dmr_swt_rst=1
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_SW_RST);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_TOP_CTR_4, mask, handle);
			//4.reg_dmr_swt_rst=0
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_SW_RST);
			mtk_oddmr_write_mask(comp, value,
				MT6991_DISP_ODDMR_TOP_CTR_4, mask, handle);
		}
		//4.5 protocal protect off: reg_sw_rst_prtcl_prot
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_PRTCL_PROT_OFF);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_UDMA_DMR_CTRL70, mask, handle);
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_RB_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_UDMA_DMR_CTRL88, mask, handle);
		//5.dmr enable && udma control
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_REG_DMR_EN, mask, handle);
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_UDMA_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_REG_DMR_UDMA_EN, mask, handle);
		//6.reg_dmr_bypass=0
		mtk_oddmr_write(comp, 0,
			MT6991_DISP_ODDMR_TOP_DMR_BYPASS, handle);
		//7.dmr ddren ctrl
		if (oddmr_data->data->dbi_version == MTK_DBI_V3) {
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 0, REG_DMR_DDREN_REQ_DISABLE);
			SET_VAL_MASK(value, mask, 1, REG_DMR_USE_HRT_DDREN_REQ);
			SET_VAL_MASK(value, mask, 0, REG_DMR_STASH_DDREN_REQ_DISABLE);
			SET_VAL_MASK(value, mask, 1, REG_DMR_STASH_USE_HRT_DDREN_REQ);
			mtk_oddmr_write_mask(comp, value,
				DISP_ODDMR_DDREN_CTRL_DMR, mask, handle);
		} else {
			mtk_oddmr_write(comp, 4,
				MT6991_DISP_ODDMR_REG_DMR_DDREN_CTRL, handle);
		}
		//8.stash cmd
		/* stash_lead_cnt = stash_lead_time / dsi_line_time */
		if (oddmr_data->data->is_dmr_support_stash) {
			stash_lead_time = oddmr_data->data->stash_lead_time;
			output_comp = mtk_ddp_comp_request_output(mtk_crtc);
			if (output_comp && (mtk_ddp_comp_get_type(output_comp->id) == MTK_DSI))
				mtk_ddp_comp_io_cmd(output_comp, NULL,
					DSI_GET_LINE_TIME_NS, &dsi_line_time);
			dsi_line_time /= 1000;
			if (dsi_line_time > 0)
				stash_lead_cnt = (stash_lead_time + dsi_line_time - 1) / dsi_line_time;
			reg_val = (1 << 8) | stash_lead_cnt;
			mtk_oddmr_write(comp, reg_val,
				MT6991_DISP_ODDMR_UDMA_DMR_CTRL30, handle);
		}
	} else {
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_REG_DMR_EN, mask, handle);
		value = 0; mask = 0;
		SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_UDMA_EN);
		mtk_oddmr_write_mask(comp, value,
			MT6991_DISP_ODDMR_REG_DMR_UDMA_EN, mask, handle);
		if (oddmr_data->data->dbi_version == MTK_DBI_V3) {
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 1, REG_DMR_DDREN_REQ_DISABLE);
			SET_VAL_MASK(value, mask, 0, REG_DMR_USE_HRT_DDREN_REQ);
			SET_VAL_MASK(value, mask, 1, REG_DMR_STASH_DDREN_REQ_DISABLE);
			SET_VAL_MASK(value, mask, 0, REG_DMR_STASH_USE_HRT_DDREN_REQ);
			mtk_oddmr_write_mask(comp, value,
				DISP_ODDMR_DDREN_CTRL_DMR, mask, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_UDMA_DMR_CTRL30, handle);
			mtk_oddmr_write(comp, 1,
				MT6991_DISP_ODDMR_TOP_DMR_BYPASS, handle);
			value = 0; mask = 0;
			SET_VAL_MASK(value, mask, 0, MT6993_REG_DMR_CLK_EN);
			mtk_oddmr_write(comp, 0,
				MT6993_DISP_ODDMR_REG_DMR_CLK_EN, handle);
		} else {
			mtk_oddmr_write(comp, 9,
				MT6991_DISP_ODDMR_REG_DMR_DDREN_CTRL, handle);
			if (oddmr_data->data->is_dmr_support_stash)
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_UDMA_DMR_CTRL30, handle);
			if (!oddmr_data->dbi_enable) {
				mtk_oddmr_write(comp, 1,
					MT6991_DISP_ODDMR_TOP_DMR_BYPASS, handle);
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_REG_DMR_CLK_EN, handle);
			}
		}
		if (oddmr_data->data->dbi_version == MTK_DBI_V2) {
			if (oddmr_data->od_update_sram == 0) {
				value = 0; mask = 0;
				SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);
			}
		}
		/* DMR info dump when disabled */
		cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
		if (g_dmr_dump_en && cur_bin_idx == -1) {
			cur_binset_idx = atomic_read(&oddmr_data->dmr_data.cur_binset_idx);
			mutex_lock(&oddmr_data->primary_data->timing_lock);
			cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
			cur_fps = oddmr_data->primary_data->current_timing.vrefresh;
			cur_dbv_mode = oddmr_data->primary_data->current_timing.dbv_mode;
			mutex_unlock(&oddmr_data->primary_data->timing_lock);
			DDPMSG("-- DeMura Current info dump --\n");
			DDPMSG("cur_binset_idx: %u\n", cur_binset_idx);
			DDPMSG("cur_bin_idx: %d\n", cur_bin_idx);
			DDPMSG("cur_dbv: %u\n", cur_dbv);
			DDPMSG("cur_fps: %u\n", cur_fps);
			DDPMSG("cur_dbv_mode: %u\n", cur_dbv_mode);
		}
	}
}

static void mtk_oddmr_set_dbi_enable(struct mtk_ddp_comp *comp, uint32_t enable,
		struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_ddp_comp *output_comp = NULL;
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	uint32_t reg_val;
	unsigned int dsi_line_time = 0;
	unsigned int stash_lead_time = 12;
	unsigned int stash_lead_cnt = 0;
	uint32_t value = 0, mask = 0;

	ODDMRAPI_LOG("+\n");

	mtk_oddmr_dbi_srt_cal(comp, enable);

	if(oddmr_data->primary_data->dbi_support) {
		if (oddmr_data->data->dbi_version == MTK_DBI_V3) {
			if (enable) {
				value = 0;mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6993_REG_DBI_SW_RST);
				mtk_oddmr_write_mask(comp, value,
					MT6993_DISP_ODDMR_TOP_CTR_4, mask, handle);

				value = 0;mask = 0;
				SET_VAL_MASK(value, mask, 0, MT6993_REG_DBI_SW_RST);
				mtk_oddmr_write_mask(comp, value,
					MT6993_DISP_ODDMR_TOP_CTR_4, mask, handle);

				value = 0;mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DBI_EN);
				SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DBI_OUT_CUP_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_EN, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_UDMA_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_EN, mask, handle);
				mtk_oddmr_write(comp, 0,
					MT6993_DISP_ODDMR_TOP_DBI_BYPASS, handle);// dbi bypass

				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 0, REG_DBI_DDREN_REQ_DISABLE);
				SET_VAL_MASK(value, mask, 1, REG_DBI_USE_HRT_DDREN_REQ);
				SET_VAL_MASK(value, mask, 0, REG_DBI_STASH_DDREN_REQ_DISABLE);
				SET_VAL_MASK(value, mask, 1, REG_DBI_STASH_USE_HRT_DDREN_REQ);
				mtk_oddmr_write_mask(comp, value,
						MT6993_DISP_ODDMR_DDREN_CTRL_DBI, mask, handle);

				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_PRTCL_PROT_OFF);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_UDMA_DBI_CTRL70, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_RB_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_UDMA_DBI_CTRL88, mask, handle);

				/* stash_lead_cnt = stash_lead_time / dsi_line_time */
				if (oddmr_data->data->is_dbi_support_stash) {
					stash_lead_time = oddmr_data->data->stash_lead_time;
					output_comp = mtk_ddp_comp_request_output(mtk_crtc);
					if (output_comp && (mtk_ddp_comp_get_type(output_comp->id) == MTK_DSI))
						mtk_ddp_comp_io_cmd(output_comp, NULL,
							DSI_GET_LINE_TIME_NS, &dsi_line_time);
					dsi_line_time /= 1000;
					if (dsi_line_time > 0)
						stash_lead_cnt = (stash_lead_time + dsi_line_time - 1) / dsi_line_time;
					reg_val = (1 << 8) | stash_lead_cnt;
					mtk_oddmr_write(comp, reg_val,
						MT6991_DISP_ODDMR_UDMA_DBI_CTRL30, handle);
				}
			} else {
				SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_DBI_EN);
				SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_DBI_OUT_CUP_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_EN, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_UDMA_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_EN, mask, handle);
				mtk_oddmr_write(comp, 1,
					MT6993_DISP_ODDMR_TOP_DBI_BYPASS, handle);

				value = 0; mask = 0;
				SET_VAL_MASK(value, mask, 1, REG_DBI_DDREN_REQ_DISABLE);
				SET_VAL_MASK(value, mask, 0, REG_DBI_USE_HRT_DDREN_REQ);
				SET_VAL_MASK(value, mask, 1, REG_DBI_STASH_DDREN_REQ_DISABLE);
				SET_VAL_MASK(value, mask, 0, REG_DBI_STASH_USE_HRT_DDREN_REQ);
				mtk_oddmr_write_mask(comp, value,
						MT6993_DISP_ODDMR_DDREN_CTRL_DBI, mask, handle);

				if (oddmr_data->data->is_dbi_support_stash)
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_UDMA_DBI_CTRL30, handle);
			}
			return;
		}

		if (oddmr_data->data->dbi_version == MTK_DBI_V2) {
			if (enable) {
				SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
				SET_VAL_MASK(value, mask, 1, MT6991_REG_ODDMR_TOP_CLK_GATING_DB_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);
				mtk_oddmr_write(comp, 1,
						MT6991_DISP_ODDMR_REG_DMR_CLK_EN, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_SW_RST);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_TOP_CTR_4, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_SW_RST);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_TOP_CTR_4, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DBI_EN);
				SET_VAL_MASK(value, mask, 1, MT6991_REG_DMR_DBI_OUT_CUP_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_EN, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_UDMA_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_EN, mask, handle);
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_TOP_DMR_BYPASS, handle);
				mtk_oddmr_write(comp, 4,
					MT6991_DISP_ODDMR_REG_DBI_DDREN_CTRL, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_PRTCL_PROT_OFF);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_UDMA_DBI_CTRL70, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 1, MT6991_REG_RB_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_UDMA_DBI_CTRL88, mask, handle);

				/* stash_lead_cnt = stash_lead_time / dsi_line_time */
				if (oddmr_data->data->is_dbi_support_stash) {
					output_comp = mtk_ddp_comp_request_output(mtk_crtc);
					if (output_comp && (mtk_ddp_comp_get_type(output_comp->id) == MTK_DSI))
						mtk_ddp_comp_io_cmd(output_comp, NULL,
							DSI_GET_LINE_TIME_NS, &dsi_line_time);
					dsi_line_time /= 1000;
					if (dsi_line_time > 0)
						stash_lead_cnt = (24 + dsi_line_time - 1) / dsi_line_time;
					reg_val = (1 << 8) | stash_lead_cnt;
					mtk_oddmr_write(comp, reg_val,
						MT6991_DISP_ODDMR_UDMA_DBI_CTRL30, handle);
				}
				if (!oddmr_data->dmr_enable && oddmr_data->od_update_sram == 0) {
					value = 0;
					mask = 0;
					SET_VAL_MASK(value, mask, 0, MT6991_REG_ODDMR_TOP_CLK_FORCE_EN);
					mtk_oddmr_write_mask(comp, value,
						MT6991_DISP_ODDMR_TOP_CTR_3, mask, handle);
				}
			} else {
				SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_DBI_EN);
				SET_VAL_MASK(value, mask, 0, MT6991_REG_DMR_DBI_OUT_CUP_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_EN, mask, handle);
				value = 0;
				mask = 0;
				SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_UDMA_EN);
				mtk_oddmr_write_mask(comp, value,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_EN, mask, handle);
				mtk_oddmr_write(comp, 1,
					MT6991_DISP_ODDMR_TOP_DMR_BYPASS, handle);
				mtk_oddmr_write(comp, 9,
					MT6991_DISP_ODDMR_REG_DBI_DDREN_CTRL, handle);
				if (oddmr_data->data->is_dbi_support_stash)
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_UDMA_DBI_CTRL30, handle);
				if (!oddmr_data->dmr_enable)
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DMR_CLK_EN, handle);
			}
			return;
		}

		if (enable) {
			//mtk_oddmr_top_prepare(comp, handle);
			mtk_oddmr_write(comp, 1, DISP_ODDMR_REG_DMR_DBI_EN, handle);
			mtk_oddmr_write(comp, 0,
				DISP_ODDMR_TOP_DMR_BYASS, handle);
			mtk_oddmr_write(comp, 1,
				DISP_ODDMR_DMR_UDMA_ENABLE, handle);
			mtk_oddmr_write(comp, 1,
				DISP_ODDMR_REG_DMR_CLK_EN, handle);
		} else {
			mtk_oddmr_write(comp, 1,
				DISP_ODDMR_TOP_DMR_BYASS, handle);
			mtk_oddmr_write(comp, 0,
				DISP_ODDMR_DMR_UDMA_ENABLE, handle);
			mtk_oddmr_write(comp, 0,
				DISP_ODDMR_REG_DMR_CLK_EN, handle);
			mtk_oddmr_write(comp, 0, DISP_ODDMR_REG_DMR_DBI_EN, handle);
		}
	}
}

static void mtk_oddmr_set_dmr_enable_dual(struct mtk_ddp_comp *comp, uint32_t enable,
		struct cmdq_pkt *handle)
{
	ODDMRFLOW_LOG("+\n");
	mtk_oddmr_set_dmr_enable(comp, enable, handle);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_set_dmr_enable(comp1, enable, handle);
	}
}

static void mtk_oddmr_od_init_end_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	ODDMRFLOW_LOG("+\n");
	mtk_oddmr_od_init_end(comp, handle);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_od_init_end(comp1, handle);
	}
}

static void mtk_oddmr_od_tuning_write_sram(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, struct mtk_oddmr_od_tuning_sram *tuning_data)
{
	uint32_t channel, sram, idx, val, ctl;
	uint32_t value = 0, mask = 0, tmp_r_sel = 0, tmp_w_sel = 0;
	uint32_t sram_write_change;
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	if (priv->data->mmsys_id != MMSYS_MT6897)
		sram_write_change = 1;
	else
		sram_write_change = 0;

	channel = tuning_data->channel;
	sram = tuning_data->sram;
	idx = tuning_data->idx;
	val = tuning_data->value;

	if (oddmr_data->data->od_version >= MTK_OD_V2)
		ctl = mtk_oddmr_read(comp, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0);
	else
		ctl = mtk_oddmr_read(comp, DISP_ODDMR_OD_SRAM_CTRL_0);

	tmp_r_sel = (ctl & 0x20) >> 5;
	tmp_w_sel = tmp_r_sel;
	value = 0;
	mask = 0;
	//change begin
	//B:0-bit1, G:1-bit2, R:2-bit3 -->> B:2-bit1, G:1-bit2, R:0-bit3
	if(sram_write_change)
		channel = channel - (channel-1)*2;
	//change end
	SET_VAL_MASK(value, mask, 1 << (channel + 1), REG_WBGR_OD_SRAM_IO_EN);
	SET_VAL_MASK(value, mask, 0, REG_AUTO_SRAM_ADR_INC_EN);
	SET_VAL_MASK(value, mask, tmp_w_sel, REG_OD_SRAM_WRITE_SEL);
	SET_VAL_MASK(value, mask, tmp_r_sel, REG_OD_SRAM_READ_SEL);
	if (oddmr_data->data->od_version >= MTK_OD_V3)
		SET_VAL_MASK(value, mask, 1, REG_OD_SRAM_READ_BACK_SEL);
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		SET_VAL_MASK(value, mask, 1, REG_OD_TABLE_DB_EFF_EN);
		mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, mask, handle);
		mtk_oddmr_write(comp, val,
			(MT6991_DISP_ODDMR_OD_SRAM_CTRL_2 + 12 * (sram - 1)), handle);
		mtk_oddmr_write(comp, 0x8000 | (idx & 0x1FF),
			(MT6991_DISP_ODDMR_OD_SRAM_CTRL_1 + 12 * (sram - 1)), handle);
		mtk_oddmr_write_mask(comp, ctl, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, 0xFFFFFFFF, handle);
	} else {
		mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_SRAM_CTRL_0, mask, handle);
		mtk_oddmr_write(comp, val,
			(DISP_ODDMR_OD_SRAM_CTRL_2 + 12 * (sram - 1)), handle);
		mtk_oddmr_write(comp, 0x8000 | (idx & 0x1FF),
			(DISP_ODDMR_OD_SRAM_CTRL_1 + 12 * (sram - 1)), handle);
		mtk_oddmr_write_mask(comp, ctl, DISP_ODDMR_OD_SRAM_CTRL_0, 0xFFFFFFFF, handle);
	}
}

static void mtk_oddmr_od_tuning_write_sram_dual(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, struct mtk_oddmr_od_tuning_sram *tuning_data)
{
	ODDMRAPI_LOG("+\n");
	mtk_oddmr_od_tuning_write_sram(comp, handle, tuning_data);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_od_tuning_write_sram(comp1, handle, tuning_data);
	}
}

static void mtk_oddmr_od_tuning_read_sram(struct mtk_ddp_comp *comp,
	struct mtk_oddmr_od_tuning_sram *tuning_data)
{
	uint32_t channel, sram, idx;
	int ret, cols, rows, i, raw_idx = 0;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRFLOW_LOG("+\n");
	if (oddmr_data->data->od_version == MTK_OD_V3) {
		channel = tuning_data->channel;
		sram = tuning_data->sram;
		idx = tuning_data->idx;
		if (sram == 1 && idx == 0) {
			ODDMRAPI_LOG("channel %d, sram %d, idx %d: read start\n");
			if (oddmr_data->od_data.buf_read_sram != NULL) {
				kfree(oddmr_data->od_data.buf_read_sram);
				oddmr_data->od_data.buf_read_sram = NULL;
			}
			oddmr_data->od_data.buf_read_sram = kzalloc(33 * 33 * sizeof(uint8_t), GFP_KERNEL);
			if (oddmr_data->od_data.buf_read_sram == NULL) {
				PC_ERR("%s fail kzalloc size 33*33\n", __func__);
				tuning_data->value = 0;
				return;
			}
			oddmr_data->od_data.od_sram_reading = true;
			ret = mtk_oddmr_od_dump_sram(comp, -1, channel, 0);
			oddmr_data->od_data.od_sram_reading = false;
			ODDMRAPI_LOG("od_dump_sram done, %d\n", ret);
			if (ret < 0) {
				kfree(oddmr_data->od_data.buf_read_sram);
				oddmr_data->od_data.buf_read_sram = NULL;
				tuning_data->value = 0;
				return;
			}
		} else {
			if (oddmr_data->od_data.buf_read_sram == NULL) {
				tuning_data->value = 0;
				return;
			}
		}

		for (i = 1; i < sram; i++) {
			rows = (i < 3) ? 17 : 16;
			cols = (i % 2 == 1) ? 17 : 16;
			raw_idx += rows * cols;
		}
		raw_idx += idx;
		tuning_data->value = oddmr_data->od_data.buf_read_sram[raw_idx];
		// ODDMRAPI_LOG("raw_idx %d, value %d\n", raw_idx, tuning_data->value);

		if (raw_idx == 33 * 33 - 1) {
			kfree(oddmr_data->od_data.buf_read_sram);
			oddmr_data->od_data.buf_read_sram = NULL;
			ODDMRAPI_LOG("channel %d, sram %d, idx %d: read done, free buffer\n");
		}
		return;
	}

	uint32_t ctl, value = 0, mask = 0, tmp_r_sel = 0, tmp_w_sel = 0;
	uint32_t sram_write_change;
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;

	if (priv->data->mmsys_id != MMSYS_MT6897)
		sram_write_change = 1;
	else
		sram_write_change = 0;

	channel = tuning_data->channel;
	sram = tuning_data->sram;
	idx = tuning_data->idx;
	if (oddmr_data->data->od_version >= MTK_OD_V2)
		ctl = mtk_oddmr_read(comp, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0);
	else
		ctl = mtk_oddmr_read(comp, DISP_ODDMR_OD_SRAM_CTRL_0);

	tmp_r_sel = (ctl & 0x20) >> 5;
	tmp_w_sel = tmp_r_sel;
	value = 0;
	mask = 0;
	//change begin
	//B:0-bit1, G:1-bit2, R:2-bit3 -->> B:2-bit1, G:1-bit2, R:0-bit3
	if(sram_write_change)
		channel = channel - (channel-1)*2;
	//change end
	SET_VAL_MASK(value, mask, 1 << (channel + 1), REG_WBGR_OD_SRAM_IO_EN);
	SET_VAL_MASK(value, mask, 0, REG_AUTO_SRAM_ADR_INC_EN);
	SET_VAL_MASK(value, mask, tmp_w_sel, REG_OD_SRAM_WRITE_SEL);
	SET_VAL_MASK(value, mask, tmp_r_sel, REG_OD_SRAM_READ_SEL);
	if (oddmr_data->data->od_version >= MTK_OD_V3)
		SET_VAL_MASK(value, mask, 1, REG_OD_SRAM_READ_BACK_SEL);
	if (oddmr_data->data->od_version >= MTK_OD_V2) {
		SET_VAL_MASK(value, mask, 1, REG_OD_TABLE_DB_EFF_EN);
		mtk_oddmr_write_mask_cpu(comp, value, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, mask);
		mtk_oddmr_write_cpu(comp, 0x4000 | (idx & 0x1FF),
			(MT6991_DISP_ODDMR_OD_SRAM_CTRL_1 + 12 * (sram - 1)));
		tuning_data->value = mtk_oddmr_read(comp,
			(MT6991_DISP_ODDMR_OD_SRAM_CTRL_3 + 12 * (sram - 1)));
		mtk_oddmr_write_cpu(comp, ctl, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0);
	} else {
		mtk_oddmr_write_mask_cpu(comp, value, DISP_ODDMR_OD_SRAM_CTRL_0, mask);
		mtk_oddmr_write_cpu(comp, 0x4000 | (idx & 0x1FF),
			(DISP_ODDMR_OD_SRAM_CTRL_1 + 12 * (sram - 1)));
		tuning_data->value = mtk_oddmr_read(comp,
			(DISP_ODDMR_OD_SRAM_CTRL_3 + 12 * (sram - 1)));
		mtk_oddmr_write_cpu(comp, ctl, DISP_ODDMR_OD_SRAM_CTRL_0);
	}
}

#define NUM_OD_SRAM_READ 7
#define NUM_OD_SRAM_READ_RETRY 23

static uint8_t mtk_oddmr_od_find_most_repeated(uint8_t *ptr)
{
	uint32_t freq[NUM_OD_SRAM_READ] = {0};
	uint32_t i, j, max_freq = 0;
	uint8_t most_repeated = ptr[0];

	// Count the occurrences of each value
	for (i = 0; i < NUM_OD_SRAM_READ; i++) {
		for (j = 0; j < NUM_OD_SRAM_READ; j++) {
			if (ptr[i] == ptr[j])
				freq[i]++;
		}
	}
	// Find the most repeated value
	for (i = 0; i < NUM_OD_SRAM_READ; i++) {
		if (freq[i] >= max_freq) {
			max_freq = freq[i];
			most_repeated = ptr[i];
		}
	}
	return most_repeated;
}

static int mtk_oddmr_od_sram_compare_dram(struct mtk_ddp_comp *comp, int sram_idx,
		uint8_t (*read_buf)[NUM_OD_SRAM_READ], int channel)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	int table_idx = oddmr_data->od_data.od_dram_sel[sram_idx];
	struct mtk_oddmr_od_table *table = od_param->od_tables[table_idx];
	uint8_t *raw_table = table->raw_table.value;
	uint8_t read_val, tmp_data;
	int raw_offset = 33 * 33 * channel; //raw_table contains all 3 channels
	uint32_t check_cnt = 0, num_wrong = 0;
	int srams, cols, rows, raw_idx, i;

	ODDMRAPI_LOG("read sram %d, compared to dram %d\n", sram_idx, table_idx);
	for (srams = 1; srams < 5; srams++) {
		rows = (srams < 3) ? 17 : 16;
		cols = (srams % 2 == 1) ? 17 : 16;
		for (i = 0; i < rows * cols; i++) {
			read_val = mtk_oddmr_od_find_most_repeated(read_buf[raw_idx]);
			tmp_data = raw_table[raw_idx + raw_offset];
			if (tmp_data != read_val) {
				num_wrong += 1;
				if (num_wrong <= 10) {
					for (check_cnt = 0; check_cnt < NUM_OD_SRAM_READ; check_cnt++)
						PC_ERR("%s, channel %d, srams %d, i %d: %dth-read %d, target %d\n",
							__func__, channel, srams, i, check_cnt,
							read_buf[raw_idx][check_cnt], tmp_data);
				}
			}
			raw_idx++;
		}
	}
	ODDMRAPI_LOG("num_check %d, num_wrong %d\n", raw_idx, num_wrong);
	if (num_wrong > 0)
		PC_ERR("%s, num_check %d, num_wrong %d\n", __func__, raw_idx, num_wrong);
	return num_wrong;
}

static int mtk_oddmr_od_dump_sram(struct mtk_ddp_comp *comp, int sram_idx,
		int channel, bool od_sram_check)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int srams, cols, rows, raw_idx, i, change_channel;
	uint32_t value, mask, tmp_r_sel, tmp_w_sel, ctl;
	uint32_t check_cnt = 0, num_wrong = 0, num_retry = 0;
	int ret = 0, pm_ret = 0;
	uint8_t read_val;
	uint8_t (*read_buf)[NUM_OD_SRAM_READ] = NULL;
	ktime_t time_diff;

	ODDMRFLOW_LOG("+\n");
	/* 1.create sram readback buffer */
	read_buf = kzalloc(33 * 33 * NUM_OD_SRAM_READ * sizeof(uint8_t), GFP_KERNEL);
	if (read_buf == NULL) {
		PC_ERR("%s fail kzalloc size %d\n", __func__, 33 * 33 * NUM_OD_SRAM_READ);
		goto fail;
	}
	//B:0-bit1, G:1-bit2, R:2-bit3 -->> B:2-bit1, G:1-bit2, R:0-bit3
	change_channel = channel - (channel-1)*2;

	/* 5.read sram NUM_OD_SRAM_READ times */
	do {
		ret = mtk_oddmr_od_trigger_frame(comp);
		if (ret <= 0)
			goto fail;
		ODDMRAPI_LOG("Read%d: od_trigger_frame done %d\n", check_cnt, ret);

		//mtk_drm_idlemgr_kick(__func__, &comp->mtk_crtc->base, 1);
		ret = mtk_oddmr_acquire_clock(comp);
		if (ret != 0)
			goto fail;
		pm_ret = mtk_vidle_pq_power_get(__func__);
		if (pm_ret) {
			PC_ERR("%s pq_power_get failed %d, skip\n", __func__, pm_ret);
			mtk_oddmr_release_clock(comp);
			goto fail;
		}

		time_diff = div_u64(ktime_get() - oddmr_data->primary_data->sof_time, 1000); //us
		if (time_diff > 3000 && num_retry < NUM_OD_SRAM_READ_RETRY) {
			num_retry++;
			ODDMRAPI_LOG("Read%d: start after %d ms, retry %d\n", check_cnt, time_diff, num_retry);
			if (!pm_ret)
				mtk_vidle_pq_power_put(__func__);
			mtk_oddmr_release_clock(comp);
			continue;
		}

		ctl = mtk_oddmr_read(comp, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0);
		value = 0;
		mask = 0;
		if (sram_idx == -1) {
			tmp_r_sel = (ctl & 0x20) >> 5;
			tmp_w_sel = tmp_r_sel;
		} else {
			tmp_w_sel = sram_idx;
			tmp_r_sel = !sram_idx;
		}
		SET_VAL_MASK(value, mask, 1 << (change_channel  + 1), REG_WBGR_OD_SRAM_IO_EN);
		SET_VAL_MASK(value, mask, 0, REG_AUTO_SRAM_ADR_INC_EN);
		SET_VAL_MASK(value, mask, tmp_w_sel, REG_OD_SRAM_WRITE_SEL);
		SET_VAL_MASK(value, mask, tmp_r_sel, REG_OD_SRAM_READ_SEL);
		SET_VAL_MASK(value, mask, 1, REG_OD_SRAM_READ_BACK_SEL);
		SET_VAL_MASK(value, mask, 1, REG_OD_TABLE_DB_EFF_EN);
		mtk_oddmr_write_mask_cpu(comp, value, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, mask);

		raw_idx = 0;
		for (srams = 1; srams < 5; srams++) {
			rows = (srams < 3) ? 17 : 16;
			cols = (srams % 2 == 1) ? 17 : 16;
			for (i = 0; i < rows * cols; i++) {
				mtk_oddmr_write_cpu(comp, 0x4000 | (i & 0x1FF),
					(MT6991_DISP_ODDMR_OD_SRAM_CTRL_1 + 12 * (srams - 1)));
				read_buf[raw_idx][check_cnt] = mtk_oddmr_read(comp,
					(MT6991_DISP_ODDMR_OD_SRAM_CTRL_3 + 12 * (srams - 1)));
				raw_idx++;
			}
		}
		mtk_oddmr_write_cpu(comp, ctl, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0);

		time_diff = div_u64(ktime_get() - oddmr_data->primary_data->sof_time, 1000); //us
		if (time_diff > 7000 && num_retry < NUM_OD_SRAM_READ_RETRY) {
			num_retry++;
			ODDMRAPI_LOG("Read%d: end after %d ms, retry %d\n", check_cnt, time_diff, num_retry);
			if (!pm_ret)
				mtk_vidle_pq_power_put(__func__);
			mtk_oddmr_release_clock(comp);
			continue;
		}

		if (!pm_ret)
			mtk_vidle_pq_power_put(__func__);
		mtk_oddmr_release_clock(comp);

		ODDMRAPI_LOG("Read%d: sram %d channel %d\n", check_cnt, tmp_w_sel, channel);
		check_cnt++;
	} while (check_cnt < NUM_OD_SRAM_READ);

	/* 6.find the most repeated value from NUM_OD_SRAM_READ values */
	raw_idx = 0;
	if (od_sram_check) {
		// compared to dram (table from bin file)
		num_wrong = mtk_oddmr_od_sram_compare_dram(comp, sram_idx, read_buf, channel);
	} else {
		// save to buffer for tuning tool
		for (srams = 1; srams < 5; srams++) {
			rows = (srams < 3) ? 17 : 16;
			cols = (srams % 2 == 1) ? 17 : 16;
			for (i = 0; i < rows * cols; i++) {
				read_val = mtk_oddmr_od_find_most_repeated(read_buf[raw_idx]);
				if (oddmr_data->od_data.buf_read_sram != NULL)
					oddmr_data->od_data.buf_read_sram[raw_idx] = read_val;
				raw_idx++;
			}
		}
	}
	kfree(read_buf);
	return num_wrong;

fail:
	if (read_buf != NULL)
		kfree(read_buf);
	return -EFAULT;
}

/* all oddmr user cmd use handle dualpipe itself because it is not drm atomic */
static int mtk_oddmr_user_cmd(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle,
		uint32_t cmd, void *data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRFLOW_LOG("+ cmd: %d\n", cmd);
	/* only handle comp0 as main oddmr comp */
	if (comp->id == DDP_COMPONENT_ODDMR1)
		return 0;

	switch (cmd) {
	case ODDMR_CMD_OD_SET_WEIGHT:
	{
		uint32_t *value = (uint32_t *)data;

		mtk_oddmr_set_od_weight_dual(comp, value, handle);
		break;
	}
	case ODDMR_CMD_OD_ENABLE:
	{
		uint32_t value = *(uint32_t *)data;

		//sw bypass first frame od pq
		mtk_oddmr_set_od_enable_dual(comp, value, true, handle);
		break;
	}
	case ODDMR_CMD_DMR_ENABLE:
	{
		uint32_t value = *(uint32_t *)data;

		mtk_oddmr_set_dmr_enable_dual(comp, value, handle);
		break;
	}
	case ODDMR_CMD_OD_INIT_END:
	{
		mtk_oddmr_od_init_end_dual(comp, handle);
		break;
	}
	case ODDMR_CMD_OD_TUNING_WRITE_SRAM:
	{
		struct mtk_oddmr_od_tuning_sram *tuning_data = data;

		if (tuning_data == NULL) {
			ODDMRFLOW_LOG("%d tuning data is NULL\n", cmd);
			return -EFAULT;
		}
		mtk_oddmr_od_tuning_write_sram_dual(comp, handle, tuning_data);
		break;
	}
	case ODDMR_CMD_ODDMR_REMAP_EN:
	{
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		mtk_oddmr_dbi_change_remap_gain(comp, handle, oddmr_data->dbi_data.cur_max_time);
		mtk_oddmr_remap_set_enable(comp, handle, true);
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		break;
	}
	case ODDMR_CMD_ODDMR_REMAP_OFF:
	{
		mtk_oddmr_remap_set_enable(comp, handle, false);
		break;
	}
	case ODDMR_CMD_ODDMR_REMAP_CHG:
	{
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		mtk_oddmr_dbi_change_remap_gain(comp, handle, oddmr_data->dbi_data.cur_max_time);
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		break;
	}
	case ODDMR_CMD_SET_SPR2RGB:
	{
		mtk_oddmr_set_spr2rgb_dual(comp, handle);
		break;
	}
	default:
	ODDMRFLOW_LOG("error cmd: %d\n", cmd);
	return -EINVAL;
	}
	return 0;
}

static void disp_oddmr_on_start_of_frame(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool od_support = oddmr_data->primary_data->od_support;

	if (!comp)
		return;

	if (od_support == true &&
			oddmr_data->primary_data->od_state >= ODDMR_INIT_DONE &&
			oddmr_data->primary_data->od_fps_mode == 1) {
		oddmr_data->primary_data->sof_time_last = oddmr_data->primary_data->sof_time;
		oddmr_data->primary_data->sof_time = comp->mtk_crtc->sof_time;
	}

	if (od_support == true && oddmr_data->primary_data->od_state >= ODDMR_LOAD_PARTS) {
		if (!atomic_read(&oddmr_data->primary_data->sof_irq_for_od_sram)) {
			atomic_set(&oddmr_data->primary_data->sof_irq_for_od_sram, 1);
			wake_up_interruptible(&oddmr_data->primary_data->od_sram_wq);
		}
	}

	if (od_support == false ||
			oddmr_data->primary_data->od_state < ODDMR_INIT_DONE ||
			oddmr_data->od_enable == 0)
		return;
	if (!atomic_read(&oddmr_data->primary_data->sof_irq_available)) {
		atomic_set(&oddmr_data->primary_data->sof_irq_available, 1);
		wake_up_interruptible(&oddmr_data->primary_data->sof_irq_wq);
	}
}

static void disp_oddmr_sof_handle(struct mtk_ddp_comp *comp)
{
	uint32_t weight[3] = {0};
	bool frame_req_trig;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	atomic_t *od_weight_trigger = &oddmr_data->primary_data->od_weight_trigger;
	uint32_t od_fps_mode = oddmr_data->primary_data->od_fps_mode;
	int ret = 0;
	int sram_idx, sram_table_idx, table_idx;

	ODDMRAPI_LOG("+\n");
	CRTC_MMP_EVENT_START(0, oddmr_sof_thread, 0, 0);
	CRTC_MMP_MARK(0, oddmr_sof_thread, atomic_read(od_weight_trigger), 0);
	if (oddmr_data->od_enable) {
		struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
		/* 1. restore user weight */
		if (atomic_read(od_weight_trigger) > 0) {
			atomic_dec(od_weight_trigger);
			if (atomic_read(od_weight_trigger) == 0) {
				sram_idx = oddmr_data->od_data.od_sram_read_sel;
				sram_table_idx = oddmr_data->od_data.od_sram_table_idx[!!sram_idx];
				table_idx = oddmr_data->od_data.od_dram_sel[sram_table_idx];
				if (od_fps_mode == 1)
					mtk_oddmr_od_gain_lookup(comp,
						oddmr_data->primary_data->od_content_timing.vrefresh,
						oddmr_data->primary_data->od_content_timing.bl_level,
						table_idx, weight);
				else
					mtk_oddmr_od_gain_lookup(comp,
						oddmr_data->primary_data->current_timing.vrefresh,
						oddmr_data->primary_data->current_timing.bl_level,
						table_idx, weight);
				if (oddmr_data->data->od_version >= MTK_OD_V3)
					DDPMSG("OD weight restore: R %u G %u B %u (sram%d %d table%d)\n",
						 weight[0], weight[1], weight[2], sram_idx, sram_table_idx, table_idx);
				else
					DDPMSG("OD weight restore: %u (sram%d %d table%d)\n",
						weight[1], sram_idx, sram_table_idx, table_idx);
				mtk_crtc_user_cmd(&comp->mtk_crtc->base,
					comp, ODDMR_CMD_OD_SET_WEIGHT, weight);
				CRTC_MMP_MARK(0, oddmr_sof_thread, weight[1], 1);
			}
		}
		/* 2. wait until near next frame te */
		frame_req_trig = (atomic_read(&oddmr_data->primary_data->frame_dirty) == 1);
		if (od_fps_mode == 1)
			oddmr_data->primary_data->frame_dirty_last = frame_req_trig;

		if (priv->data->mmsys_id != MMSYS_MT6989) {
			uint32_t second = 1000000, eof;
			u16 fps = oddmr_data->primary_data->current_timing.vrefresh;

			if (fps <= 0)
				fps = 10;
			eof = 1 * second / fps;
			ODDMRLOW_LOG("fps: %u eof %u\n", fps, eof);

			atomic_set(&oddmr_data->primary_data->frame_dirty, 0);
			if (eof > 2000) {
				ret = wait_event_interruptible_timeout(oddmr_data->primary_data->frame_dirty_wq,
					atomic_read(&oddmr_data->primary_data->frame_dirty) == 1,
					usecs_to_jiffies(eof - 2000));
			}
		} else {
			atomic_set(&oddmr_data->primary_data->frame_dirty, 0);
		}

		CRTC_MMP_MARK(0, oddmr_sof_thread, 0, 2);
		/* 3. check & trigger */
		ODDMRLOW_LOG("frame %d,weight_trigger%d, ret %d\n",
			frame_req_trig,atomic_read(od_weight_trigger), ret);
		if ((frame_req_trig && od_fps_mode == 0) ||
				atomic_read(od_weight_trigger)) {
			ODDMRLOW_LOG("%d,%d,%d\n",
				atomic_read(&oddmr_data->primary_data->frame_dirty),
				mtk_crtc_is_frame_trigger_mode(&comp->mtk_crtc->base),g_od_check_trigger);
			if (atomic_read(&oddmr_data->primary_data->frame_dirty) == 0 &&
				mtk_crtc_is_frame_trigger_mode(&comp->mtk_crtc->base) &&
				g_od_check_trigger != 2) {
				ODDMRLOW_LOG("check trigger\n");
				mtk_crtc_check_trigger(comp->mtk_crtc,
					!!g_od_check_trigger, true);
				CRTC_MMP_MARK(0, oddmr_sof_thread, 0, 3);
			}
		}
	}
	CRTC_MMP_EVENT_END(0, oddmr_sof_thread, 0, 0);
}

static int disp_oddmr_sof_kthread(void *data)
{
	struct mtk_ddp_comp *comp = (struct mtk_ddp_comp *)data;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int ret;
	uint32_t timeout, od_wait_time;
	ktime_t time_diff;

	while (!kthread_should_stop()) {
		if (atomic_read(&oddmr_data->primary_data->sof_irq_available) == 0) {
			//clear frame_dirty_last when od disabled
			if (oddmr_data->primary_data->od_fps_mode == 1 && !oddmr_data->od_enable)
				oddmr_data->primary_data->frame_dirty_last = false;
			//when od enabled and last frame is dirty, instant trigger when waiting sof timeout
			if (oddmr_data->primary_data->od_fps_mode == 1 &&
					oddmr_data->od_enable &&
					oddmr_data->primary_data->frame_dirty_last) {
				oddmr_data->primary_data->frame_dirty_last = false;
				//subtracts the usleep time in disp_oddmr_sof_handle
				od_wait_time = oddmr_data->primary_data->od_wait_time;
				time_diff = div_u64(ktime_get() - oddmr_data->primary_data->sof_time, 1000000); //ms
				ret = 0;
				//if od_wait_time <= time_diff, no waiting
				if (od_wait_time > time_diff) {
					timeout = od_wait_time - time_diff;
					ODDMRLOW_LOG("wait_event_interruptible_timeout: sof_time %lld, wait_time %d, timeout %d\n",
							oddmr_data->primary_data->sof_time, od_wait_time, timeout);
					ret = wait_event_interruptible_timeout(oddmr_data->primary_data->sof_irq_wq,
							atomic_read(&oddmr_data->primary_data->sof_irq_available) == 1,
							msecs_to_jiffies(timeout));
					ODDMRLOW_LOG("sof_irq_available = %d, ret = %d, waken up; od_enable %d\n",
							atomic_read(&oddmr_data->primary_data->sof_irq_available),
							ret, oddmr_data->od_enable);
				}
				if (ret == 0 && oddmr_data->od_enable) {
					//may change to disable when timeout
					mtk_crtc_check_trigger(comp->mtk_crtc, false, true);
					ODDMRLOW_LOG("instant trigger\n");
				}
				if (ret > 0)
					disp_oddmr_sof_handle(comp);
			} else {
				ODDMRLOW_LOG("wait_event_interruptible\n");
				ret = wait_event_interruptible(oddmr_data->primary_data->sof_irq_wq,
						atomic_read(&oddmr_data->primary_data->sof_irq_available) == 1);
				ODDMRLOW_LOG("sof_irq_available = 1, waken up, ret = %d\n", ret);
				if (ret == 0)
					disp_oddmr_sof_handle(comp);
			}
		} else
			ODDMRLOW_LOG("sof_irq_available already 1,ret = %d, skip\n", ret);
		atomic_set(&oddmr_data->primary_data->sof_irq_available, 0);
	}
	return 0;
}

/* top,dither,common pq, udma */
static void mtk_oddmr_od_common_init_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	ODDMRAPI_LOG("+\n");
	mtk_oddmr_od_common_init(comp, pkg);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_od_common_init(comp1, pkg);
	}
}

static void mtk_oddmr_od_hsk_force_clk(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	ODDMRAPI_LOG("+\n");
	mtk_oddmr_write(comp, 1, DISP_ODDMR_OD_HSK_0, pkg);
	mtk_oddmr_write(comp, 1, DISP_ODDMR_OD_HSK_1, pkg);
	mtk_oddmr_write(comp, 0xFFF, DISP_ODDMR_OD_HSK_2, pkg);
	mtk_oddmr_write(comp, 0xFFF, DISP_ODDMR_OD_HSK_3, pkg);
	mtk_oddmr_write(comp, 0xFFF, DISP_ODDMR_OD_HSK_4, pkg);
}

static void mtk_oddmr_od_hsk_force_clk_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{
	ODDMRAPI_LOG("+\n");
	mtk_oddmr_od_hsk_force_clk(comp, pkg);
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		mtk_oddmr_od_hsk_force_clk(comp1, pkg);
	}
}

static void mtk_oddmr_od_gce_pkt_init(struct mtk_drm_crtc *mtk_crtc,
	struct mtk_ddp_comp *comp,
	struct mtk_disp_oddmr *oddmr_data, uint32_t dram_id)
{
	ODDMRAPI_LOG("+\n");
	//create table  gce for sram 0
	mtk_oddmr_create_gce_pkt(&mtk_crtc->base,
		&oddmr_data->od_data.od_sram_pkgs[dram_id][0]);
	//table write in sram 0
	mtk_oddmr_od_init_sram(comp,
		oddmr_data->od_data.od_sram_pkgs[dram_id][0], dram_id, 0);
	//create table  gce for sram 1
	mtk_oddmr_create_gce_pkt(&mtk_crtc->base,
		&oddmr_data->od_data.od_sram_pkgs[dram_id][1]);
	//table write in sram 1
	mtk_oddmr_od_init_sram(comp,
		oddmr_data->od_data.od_sram_pkgs[dram_id][1], dram_id, 1);
}

static int mtk_oddmr_od_trigger_frame(struct mtk_ddp_comp *comp)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int ret = 0;

	atomic_set(&oddmr_data->primary_data->sof_irq_for_od_sram, 0);
	drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
	ret = wait_event_interruptible_timeout(oddmr_data->primary_data->od_sram_wq,
			atomic_read(&oddmr_data->primary_data->sof_irq_for_od_sram) == 1,
			msecs_to_jiffies(200));
	if (ret <= 0)
		PC_ERR("od_trigger_frame timeout %d\n", ret);
	else if (oddmr_data->primary_data->od_fps_mode != 1)
		oddmr_data->primary_data->sof_time = comp->mtk_crtc->sof_time;
	return ret;
}

static int mtk_oddmr_od_init(struct mtk_ddp_comp *comp, void *data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	struct mtk_drm_crtc *mtk_crtc;
	int ret, idx, table_idx, pm_ret = 0;
	struct cmdq_client *client = NULL;
	bool od_support = oddmr_data->primary_data->od_support;
	uint32_t value = 0, mask = 0, i = 0;
	uint32_t cnts = od_param->od_basic_info.basic_param.table_cnt;
	struct mtk_oddmr_pq_param *basic_pq = &od_param->od_basic_info.basic_pq;

	ODDMRAPI_LOG("+\n");
	DDPMSG("%s+\n",__func__);
	if (!od_support) {
		ODDMRFLOW_LOG("od is not support\n");
		return -1;
	}
	if (oddmr_data->primary_data->od_state != ODDMR_LOAD_PARTS) {
		ODDMRFLOW_LOG("od can not init, state %d\n", oddmr_data->primary_data->od_state);
		return -1;
	}
	if (oddmr_data->od_enable > 0) {
		ODDMRFLOW_LOG("od can not init when running\n");
		return -1;
	}
	if (od_param->od_basic_info.basic_param.table_cnt != od_param->valid_table_cnt) {
		oddmr_data->primary_data->od_state = ODDMR_INVALID;
		ODDMRFLOW_LOG("tables are not fully loaded,cnts %d, valid %d\n",
			od_param->od_basic_info.basic_param.table_cnt, od_param->valid_table_cnt);
		return -1;
	}
	if (!mtk_oddmr_match_panelid(&oddmr_data->primary_data->panelid, &od_param->od_basic_info.basic_param.panelid)) {
		ODDMRFLOW_LOG("panelid does not match\n");
		return -1;
	}

	mtk_oddmr_od_table_fps_minmax(oddmr_data);
	if (oddmr_data->primary_data->od_fps_mode == 1 &&
			oddmr_data->primary_data->od_wait_time == 0) {
		//use defuault 1000/od_min_fps if given 0
		oddmr_data->primary_data->od_wait_time = 1000 / oddmr_data->primary_data->od_min_fps;
	}
	// init pu last roi record to full frame
	oddmr_data->roi_y_last = 0;
	oddmr_data->roi_height_last = mtk_crtc_get_height_by_comp(__func__,
		&comp->mtk_crtc->base, comp, true);
	if (oddmr_data->data->od_version >= MTK_OD_V3) {
		for (i = 0; i < basic_pq->counts; i++) {
			if (basic_pq->param[i].addr == MT6991_DISP_ODDMR_OD_SCALING_6) {
				oddmr_data->od_data.spr_rgbg_mode = (basic_pq->param[i].value & 0x8) >> 3;
				break;
			}
		}
		ODDMRAPI_LOG("spr_rgbg_mode %d (0x%x = 0x%x)\n", oddmr_data->od_data.spr_rgbg_mode,
			basic_pq->param[i].addr, basic_pq->param[i].value);
	}

	if (oddmr_data->data->od_version == MTK_OD_V3) {
		mtk_drm_idlemgr_kick(__func__, &comp->mtk_crtc->base, 1);
		ret = mtk_oddmr_acquire_clock(comp);
		ODDMRAPI_LOG("od_init_ret-1, %d\n", ret);
		if (ret == 0) {
			pm_ret = mtk_vidle_pq_power_get(__func__);
			if (pm_ret) {
				PC_ERR("%s pq_power_get failed %d, skip\n", __func__, pm_ret);
				mtk_oddmr_release_clock(comp);
				return -1;
			}
			mtk_oddmr_set_top_clk_force(comp, 1, NULL); //needed by writing sram and udma init
			if (!pm_ret)
				mtk_vidle_pq_power_put(__func__);
			mtk_oddmr_release_clock(comp);

			ret = mtk_oddmr_od_trigger_frame(comp);
		}
	}

	mtk_crtc = comp->mtk_crtc;
	mtk_drm_idlemgr_kick(__func__, &comp->mtk_crtc->base, 1);
	ret = mtk_oddmr_acquire_clock(comp);
	ODDMRAPI_LOG("od_init_ret-2, %d\n", ret);
	if (ret == 0) {
		pm_ret = mtk_vidle_pq_power_get(__func__);
		if (pm_ret) {
			PC_ERR("%s pq_power_get failed %d, skip\n", __func__, pm_ret);
			mtk_oddmr_release_clock(comp);
			return -1;
		}
		oddmr_data->primary_data->od_state = ODDMR_LOAD_DONE;

		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			SET_VAL_MASK(value, mask, 1, REG_OD_RD_REG_EN); //for sram read
			mtk_oddmr_write_mask(comp, value, DISP_ODDMR_OD_UDMA_CTR_0, mask, NULL);
			value = 0; mask = 0;
			if (oddmr_data->data->od_version != MTK_OD_V3)
				mtk_oddmr_set_top_clk_force(comp, 1, NULL); //needed by writing sram and udma init
		}
		mtk_oddmr_od_common_init_dual(comp, NULL);
		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			SET_VAL_MASK(value, mask, 0, MT6991_REG_OD_SPR2RGB_BYPASS); // =1 will cause OD bypass
			mtk_oddmr_write_mask(comp, value, MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS, mask, NULL);
		}
		mtk_oddmr_od_smi_dual(comp, NULL);
		mtk_oddmr_od_alloc_dram_dual(comp);
		mtk_oddmr_od_set_dram_dual(comp, NULL);
		table_idx = _mtk_oddmr_od_table_lookup(oddmr_data, &oddmr_data->primary_data->current_timing);
		if (table_idx == -1)
			table_idx = 0;
		ODDMRFLOW_LOG("init table_idx %d\n", table_idx);
		//for 6985 force en clk, need to restore od_hsk later
		if (oddmr_data->data->is_od_need_force_clk)
			mtk_oddmr_od_hsk_force_clk_dual(comp, NULL);
		//init srams
		if (mtk_crtc->gce_obj.client[CLIENT_PQ])
			client = mtk_crtc->gce_obj.client[CLIENT_PQ];
		else
			client = mtk_crtc->gce_obj.client[CLIENT_CFG];
		cmdq_mbox_enable(client->chan);
		//sram [0] --> dram [0]
		//sram [1] --> dram [table_idx]
		if (IS_TABLE_VALID(0, od_param->valid_table)) {
			CRTC_MMP_MARK(0, oddmr_ctl, 0, 0);
			mtk_oddmr_od_gce_pkt_init(mtk_crtc, comp, oddmr_data, 0);
			oddmr_data->od_data.od_sram_table_idx[0] = 0;
			oddmr_data->od_data.od_dram_sel[0] = 0;
			CRTC_MMP_MARK(0, oddmr_ctl, 0, 1);
			//use gce for sram 0
			cmdq_pkt_flush(oddmr_data->od_data.od_sram_pkgs[0][0]);
			CRTC_MMP_MARK(0, oddmr_ctl, 0, 2);
		} else {
			ODDMRFLOW_LOG("table0 must be valid\n");
			oddmr_data->primary_data->od_state = ODDMR_LOAD_PARTS;
			if (!pm_ret)
				mtk_vidle_pq_power_put(__func__);
			mtk_oddmr_release_clock(comp);
			return -1;
		}
		if (IS_TABLE_VALID(1, od_param->valid_table)) {
			CRTC_MMP_MARK(0, oddmr_ctl, 0, 10);
			mtk_oddmr_od_gce_pkt_init(mtk_crtc, comp, oddmr_data, 1);
			if(table_idx == 0 || table_idx == 1) {
				oddmr_data->od_data.od_sram_table_idx[1] = 1;
				oddmr_data->od_data.od_dram_sel[1] = 1;
				CRTC_MMP_MARK(0, oddmr_ctl, 0, 11);
				//use gce for sram 1
				cmdq_pkt_flush(oddmr_data->od_data.od_sram_pkgs[1][1]);
			}
			CRTC_MMP_MARK(0, oddmr_ctl, 0, 12);
		}
		for (idx = 2; idx < cnts; idx++) {
			if (IS_TABLE_VALID(idx, od_param->valid_table)) {
				CRTC_MMP_MARK(0, oddmr_ctl, 0, idx * 10);
				mtk_oddmr_od_gce_pkt_init(mtk_crtc, comp, oddmr_data, idx);
				if(table_idx == idx) {
					oddmr_data->od_data.od_sram_table_idx[1] = 1;
					oddmr_data->od_data.od_dram_sel[1] = idx;
					CRTC_MMP_MARK(0, oddmr_ctl, 0, idx * 10 + 1);
					cmdq_pkt_flush(oddmr_data->od_data.od_sram_pkgs[idx][1]);
				}
				CRTC_MMP_MARK(0, oddmr_ctl, 0, idx * 10 + 2);
			}
		}

		if (table_idx == 0) {
			if (oddmr_data->data->od_version >= MTK_OD_V3)
				mtk_oddmr_write(comp,
					0xD0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			else if (oddmr_data->data->od_version == MTK_OD_V2)
				mtk_oddmr_write(comp,
					0x90, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			else
				mtk_oddmr_write(comp,
					0x10, DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			oddmr_data->od_data.od_sram_read_sel = 0;
		} else {
			if (oddmr_data->data->od_version >= MTK_OD_V3)
				mtk_oddmr_write(comp,
					0xE0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			else if (oddmr_data->data->od_version == MTK_OD_V2)
				mtk_oddmr_write(comp,
					0xA0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			else
				mtk_oddmr_write(comp,
					0x20, DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
			oddmr_data->od_data.od_sram_read_sel = 1;
		}
		//sram [0] --> dram [0]
		//sram [1] --> dram [table_idx]
		if (comp->mtk_crtc->is_dual_pipe) {
			struct mtk_ddp_comp *comp1 = oddmr_data->companion;
			struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

			if (IS_TABLE_VALID(0, od_param->valid_table)) {
				CRTC_MMP_MARK(0, oddmr_ctl, 1, 0);
				mtk_oddmr_od_gce_pkt_init(mtk_crtc, comp1, oddmr1_data, 0);
				oddmr1_data->od_data.od_sram_table_idx[0] = 0;
				oddmr1_data->od_data.od_dram_sel[0] = 0;
				CRTC_MMP_MARK(0, oddmr_ctl, 1, 1);
				cmdq_pkt_flush(oddmr1_data->od_data.od_sram_pkgs[0][0]);
				CRTC_MMP_MARK(0, oddmr_ctl, 1, 2);
			}
			if (IS_TABLE_VALID(1, od_param->valid_table)) {
				CRTC_MMP_MARK(0, oddmr_ctl, 1, 10);
				mtk_oddmr_od_gce_pkt_init(mtk_crtc, comp1, oddmr1_data, 1);
				if (table_idx == 0 || table_idx == 1) {
					oddmr1_data->od_data.od_sram_table_idx[1] = 1;
					oddmr1_data->od_data.od_dram_sel[1] = 1;
					CRTC_MMP_MARK(0, oddmr_ctl, 1, 11);
					cmdq_pkt_flush(oddmr1_data->od_data.od_sram_pkgs[1][1]);
				}
				CRTC_MMP_MARK(0, oddmr_ctl, 1, 12);
			}
			for (idx = 2; idx < cnts; idx++) {
				if (IS_TABLE_VALID(idx, od_param->valid_table)) {
					CRTC_MMP_MARK(0, oddmr_ctl, 1, idx * 10);
					mtk_oddmr_od_gce_pkt_init(mtk_crtc, comp1, oddmr1_data, idx);
					if(table_idx == idx) {
						oddmr1_data->od_data.od_sram_table_idx[1] = 1;
						oddmr1_data->od_data.od_dram_sel[1] = idx;
						CRTC_MMP_MARK(0, oddmr_ctl, 1, idx * 10 +1);
						cmdq_pkt_flush(oddmr1_data->od_data.od_sram_pkgs[idx][1]);
					}
					CRTC_MMP_MARK(0, oddmr_ctl, 1, idx * 10 + 2);
				}
			}

			if (table_idx == 0) {
				if (oddmr_data->data->od_version >= MTK_OD_V3)
					mtk_oddmr_write(comp1,
						0xD0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
				else if (oddmr_data->data->od_version == MTK_OD_V2)
					mtk_oddmr_write(comp1,
						0x90, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
				else
					mtk_oddmr_write(comp1,
						0x10, DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
				oddmr1_data->od_data.od_sram_read_sel = 0;
			} else {
				if (oddmr_data->data->od_version >= MTK_OD_V3)
					mtk_oddmr_write(comp1,
						0xE0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
				else if (oddmr_data->data->od_version == MTK_OD_V2)
					mtk_oddmr_write(comp1,
						0xA0, MT6991_DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
				else
					mtk_oddmr_write(comp1,
						0x20, DISP_ODDMR_OD_SRAM_CTRL_0, NULL);
				oddmr1_data->od_data.od_sram_read_sel = 1;
			}
		}
		cmdq_mbox_disable(client->chan);

		mtk_oddmr_od_set_res_udma_dual(comp, NULL);
		if (oddmr_data->data->od_version < MTK_OD_V2)
			mtk_oddmr_set_crop_dual(comp, NULL);
		oddmr_data->primary_data->od_state = ODDMR_INIT_DONE;
		if (!pm_ret)
			mtk_vidle_pq_power_put(__func__);
		mtk_oddmr_release_clock(comp);

		ret = mtk_crtc_user_cmd(&comp->mtk_crtc->base,
				comp, ODDMR_CMD_SET_SPR2RGB, NULL);
		if (oddmr_data->data->od_version < MTK_OD_V2)
			ret = mtk_crtc_user_cmd(&comp->mtk_crtc->base,
					comp, ODDMR_CMD_OD_INIT_END, NULL);
		if (oddmr_data->data->od_version == MTK_OD_V2 && !oddmr_data->dmr_enable)
			mtk_oddmr_set_top_clk_force(comp, 0, NULL);
		mtk_crtc_check_trigger(comp->mtk_crtc, false, true);
	}
	return ret;
}


static int mtk_oddmr_od_enable(struct mtk_ddp_comp *comp, int en)
{
	int ret = 0, enable = en;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("+\n");
	DDPMSG("%s:%d+\n",__func__,enable);

	if (oddmr_data->primary_data->od_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("od can not enable/disable, state %d\n", oddmr_data->primary_data->od_state);
		return -EFAULT;
	}

	if (atomic_read(&oddmr_data->primary_data->od_deinit) == 1) {
		ODDMRFLOW_LOG("od can not enable/disable when deinit\n");
		return -EFAULT;
	}

	oddmr_data->od_enable_req = enable;
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;
		struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

		oddmr1_data->od_enable_req = enable;
	}
	atomic_set(&oddmr_data->primary_data->od_hrt_done, 2);
	drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
	ret = wait_event_interruptible_timeout(g_oddmr_hrt_wq,
			atomic_read(&oddmr_data->primary_data->od_hrt_done) == 1, msecs_to_jiffies(200));
	if (ret <= 0) {
		ODDMRFLOW_LOG("enable %d repaint timeout %d\n", enable, ret);
		ret = 0;
	}
	return ret;
}

static int mtk_oddmr_od_user_gain(struct mtk_ddp_comp *comp, void *data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint8_t od_user_gain = 0;

	ODDMRAPI_LOG("+\n");
	if (!comp || !data) {
		ODDMRFLOW_LOG("param is invalid\n");
		return -EFAULT;
	}
	od_user_gain = *(uint8_t *)data;
	oddmr_data->od_user_gain = od_user_gain;
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

		oddmr_data = comp_to_oddmr(comp1);
		oddmr_data->od_user_gain = od_user_gain;
	}

	atomic_set(&oddmr_data->primary_data->od_weight_trigger, 1);
	mtk_drm_idlemgr_kick(__func__,
			&comp->mtk_crtc->base, 1);
	mtk_crtc_check_trigger(comp->mtk_crtc, true, true);
	ODDMRFLOW_LOG("weight set user gain %u\n", od_user_gain);
	return 0;
}


static int mtk_oddmr_od_deinit(struct mtk_ddp_comp *comp, void *data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	int ret = 0, idx;
	bool od_support = oddmr_data->primary_data->od_support;
	uint32_t value = 0, mask = 0;
	uint32_t cnts = od_param->od_basic_info.basic_param.table_cnt;
	struct mtk_oddmr_pq_param *basic_pq = &od_param->od_basic_info.basic_pq;
	struct mtk_ddp_comp *comp1 = NULL;
	struct mtk_disp_oddmr *oddmr1_data = NULL;

	DDPMSG("%s+\n",__func__);
	if (!od_support) {
		ODDMRFLOW_LOG("od is not support\n");
		goto fail;
	}
	if (oddmr_data->primary_data->od_state != ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("cannot deinit, state %d\n", oddmr_data->primary_data->od_state);
		goto fail;
	}
	if (comp->mtk_crtc->is_dual_pipe) {
		comp1 = oddmr_data->companion;
		oddmr1_data = comp_to_oddmr(comp1);
	}

	if (oddmr_data->od_enable_req > 0) {//dual will change at the same time
		ODDMRFLOW_LOG("cannot deinit, enable_req %d\n", oddmr_data->od_enable_req);
		goto fail;
	}
	atomic_set(&oddmr_data->primary_data->od_deinit, 1); //od_enable_req cannot change

	/* 1.1. wait od_enable = 0 after od_enable_req = 0 (dual will change at the same time) */
	if (oddmr_data->od_enable > 0) {
		if (atomic_read(&oddmr_data->primary_data->od_hrt_done) != 1) {
			ODDMRFLOW_LOG("cannot deinit, enable_req %d enable %d\n",
					oddmr_data->od_enable_req, oddmr_data->od_enable);
			goto fail;
		} else {
			ret = wait_event_interruptible_timeout(oddmr_data->primary_data->od_deinit_wq,
					atomic_read(&oddmr_data->primary_data->od_hrt_done) == 0,
					msecs_to_jiffies(1000));
			if (ret <= 0 || oddmr_data->od_enable > 0) {
				ODDMRFLOW_LOG("ret %d, cannot deinit, enable_req %d enable %d\n",
					ret, oddmr_data->od_enable_req, oddmr_data->od_enable);
				goto fail;
			}
		}
	}
	/* 1.2. wait FRAME_DIRTY (mtk_oddmr_set_od_enable already done) */
	if (oddmr_data->od_enable_last > 0) {
		atomic_set(&oddmr_data->primary_data->frame_dirty, 0);
		ret = wait_event_interruptible_timeout(oddmr_data->primary_data->frame_dirty_wq,
			atomic_read(&oddmr_data->primary_data->frame_dirty) == 1,
			msecs_to_jiffies(1000));
		if (ret <= 0 || oddmr_data->od_enable_last > 0) {
			ODDMRFLOW_LOG("ret %d, cannot deinit, enable_req %d enable %d enable_last %d\n",
				ret, oddmr_data->od_enable_req, oddmr_data->od_enable, oddmr_data->od_enable_last);
			goto fail;
		}
	}
	/* 1.3. wait to next sof for od disable HW config done */
	ret = mtk_oddmr_od_trigger_frame(comp);
	if (ret <= 0)
		goto fail;
	ODDMRFLOW_LOG("done trigger_frame, ret %d\n", ret);

	/* 1.4. final check */
	if (oddmr_data->od_enable_req > 0 || oddmr_data->od_enable > 0 ||
			oddmr_data->od_enable_last > 0) {
		PC_ERR("%s failed, enable_req %d enable %d enable_last %d\n", __func__,
			oddmr_data->od_enable_req, oddmr_data->od_enable, oddmr_data->od_enable_last);
		goto fail;
	}

	/* 2. flush workque */
	flush_workqueue(oddmr_data->primary_data->oddmr_wq);
	ODDMRFLOW_LOG("done flush_workqueue\n");

	oddmr_data->primary_data->od_state = ODDMR_LOAD_DONE; //cannot init or enable/disable
	/* 3. destroy sram pkgs */
	for (idx = 0; idx < cnts; idx++) {
		cmdq_pkt_destroy(oddmr_data->od_data.od_sram_pkgs[idx][0]);
		cmdq_pkt_destroy(oddmr_data->od_data.od_sram_pkgs[idx][1]);
	}
	if (comp->mtk_crtc->is_dual_pipe) {
		for (idx = 0; idx < cnts; idx++) {
			cmdq_pkt_destroy(oddmr1_data->od_data.od_sram_pkgs[idx][0]);
			cmdq_pkt_destroy(oddmr1_data->od_data.od_sram_pkgs[idx][1]);
		}
	}
	ODDMRFLOW_LOG("done destroy sram pkgs\n");

	/* 4. free frame buffer */
	mtk_oddmr_od_free_buffer(comp);
	if (comp->mtk_crtc->is_dual_pipe)
		mtk_oddmr_od_free_buffer(comp1);
	ODDMRFLOW_LOG("done free frame buffer\n");

	/* 5. reset variables */
	atomic_set(&oddmr_data->primary_data->od_weight_trigger, 0);
	// atomic_set(&oddmr_data->primary_data->frame_dirty, 0);
	atomic_set(&oddmr_data->primary_data->sof_irq_available, 0);
	// atomic_set(&oddmr_data->primary_data->sof_irq_for_od_sram, 0);
	atomic_set(&oddmr_data->primary_data->od_hrt_done, 0);
	memset(&oddmr_data->primary_data->od_content_timing, 0,
		sizeof(oddmr_data->primary_data->od_content_timing));
	oddmr_data->primary_data->frame_dirty_last = 0;
	oddmr_data->primary_data->od_fps_mode = 0;
	oddmr_data->primary_data->od_wait_time = 0;
	oddmr_data->primary_data->od_min_fps = 0;
	oddmr_data->primary_data->od_max_fps = 0;
	oddmr_data->primary_data->sof_time = ktime_set(0, 0);
	oddmr_data->primary_data->sof_time_last = ktime_set(0, 0);

	memset(&oddmr_data->od_data, 0, sizeof(oddmr_data->od_data));
	oddmr_data->od_data.od_sram_read_sel = -1;
	oddmr_data->od_data.od_sram_table_idx[0] = -1;
	oddmr_data->od_data.od_sram_table_idx[1] = -1;

	oddmr_data->od_enable_req = 0;
	oddmr_data->od_enable = 0;
	oddmr_data->od_enable_last = 0;
	oddmr_data->od_update_sram = 0;
	oddmr_data->od_force_off = 0;
	oddmr_data->od_force_off2 = 0;
	oddmr_data->od_force_off_last = 0;
	oddmr_data->qos_srt_odr = 0;
	oddmr_data->last_qos_srt_odr = 0;
	oddmr_data->qos_srt_odw = 0;
	oddmr_data->last_qos_srt_odw = 0;
	oddmr_data->last_hrt_odrw = 0;
	oddmr_data->last_hrt_odrw_stash = 0;

	if (comp->mtk_crtc->is_dual_pipe) {
		memset(&oddmr1_data->od_data, 0, sizeof(oddmr1_data->od_data));
		oddmr1_data->od_data.od_sram_read_sel = -1;
		oddmr1_data->od_data.od_sram_table_idx[0] = -1;
		oddmr1_data->od_data.od_sram_table_idx[1] = -1;

		oddmr1_data->od_enable_req = 0;
		oddmr1_data->od_enable = 0;
		oddmr1_data->od_enable_last = 0;
		oddmr1_data->od_update_sram = 0;
		oddmr1_data->od_force_off = 0;
		oddmr1_data->od_force_off2 = 0;
		oddmr1_data->od_force_off_last = 0;
		oddmr1_data->qos_srt_odr = 0;
		oddmr1_data->last_qos_srt_odr = 0;
		oddmr1_data->qos_srt_odw = 0;
		oddmr1_data->last_qos_srt_odw = 0;
		oddmr1_data->last_hrt_odrw = 0;
		oddmr1_data->last_hrt_odrw_stash = 0;
	}
	ODDMRFLOW_LOG("done reset variables\n");

	/* 6. free od_param buffers*/
	if (od_param->od_basic_info.basic_pq.param != NULL) {
#ifndef APP_DEBUG
		kfree(od_param->od_basic_info.basic_pq.param);
#else
		free(od_param->od_basic_info.basic_pq.param);
#endif
		od_param->od_basic_info.basic_pq.param = NULL;
		ODDMRFLOW_LOG("done free od_basic_info.basic_pq.param\n");
	}
	for (idx = 0; idx < cnts; idx++) {
		if (od_param->od_tables[idx] != NULL &&
			od_param->od_tables[idx]->pq_od.param != NULL) {
#ifndef APP_DEBUG
			kfree(od_param->od_tables[idx]->pq_od.param);
#else
			free(od_param->od_tables[idx]->pq_od.param);
#endif
			od_param->od_tables[idx]->pq_od.param = NULL;
			ODDMRFLOW_LOG("done free od_tables[%d]->pq_od.param\n", idx);
		}
	}
	for (idx = 0; idx < cnts; idx++) {
		if (od_param->od_tables[idx] != NULL &&
			od_param->od_tables[idx]->raw_table.value != NULL) {
#ifndef APP_DEBUG
			kfree(od_param->od_tables[idx]->raw_table.value);
#else
			free(od_param->od_tables[idx]->raw_table.value);
#endif
			od_param->od_tables[idx]->raw_table.value = NULL;
			ODDMRFLOW_LOG("done free od_tables[%d]->raw_table.value\n", idx);
		}
	}
	for (idx = 0; idx < cnts; idx++) {
		if (od_param->od_tables[idx] != NULL &&
			od_param->od_tables[idx]->gain_table_raw != NULL) {
#ifndef APP_DEBUG
			kfree(od_param->od_tables[idx]->gain_table_raw);
#else
			free(od_param->od_tables[idx]->gain_table_raw);
#endif
			od_param->od_tables[idx]->gain_table_raw = NULL;
			ODDMRFLOW_LOG("done free od_tables[%d]->gain_table_raw\n", idx);
		}
	}
	for (idx = 0; idx < cnts; idx++) {
		if (od_param->od_tables[idx] != NULL) {
#ifndef APP_DEBUG
			kfree(od_param->od_tables[idx]);
#else
			free(od_param->od_tables[idx]);
#endif
			od_param->od_tables[idx] = NULL;
			ODDMRFLOW_LOG("done free od_tables[%d]\n", idx);
		}
	}

	/* 7. reset od_param*/
	memset(&oddmr_data->primary_data->od_param, 0, sizeof(oddmr_data->primary_data->od_param));
	oddmr_data->primary_data->od_state = ODDMR_INVALID;
	oddmr_data->primary_data->od_basic_info_loaded = 0; //can do mtk_oddmr_load_param again

	atomic_set(&oddmr_data->primary_data->od_deinit, 0);
	return 0;

fail:
	atomic_set(&oddmr_data->primary_data->od_deinit, 0);
	return -EFAULT;
}

static void mtk_oddmr_dmr_common_init(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{

	ODDMRAPI_LOG("+\n");
	/* top */
	mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_TOP_CLK_GATING, pkg);
}

static void mtk_oddmr_dbi_common_init(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
{

	ODDMRAPI_LOG("+\n");
	/* top */
	mtk_oddmr_write(comp, 1, MT6991_DISP_ODDMR_TOP_CLK_GATING, pkg);
}


//static void mtk_oddmr_dmr_common_init_dual(struct mtk_ddp_comp *comp, struct cmdq_pkt *pkg)
//{
//	ODDMRAPI_LOG("+\n");
//	mtk_oddmr_dmr_common_init(comp, pkg);
//	if (comp->mtk_crtc->is_dual_pipe) {
//		struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
//		struct mtk_ddp_comp *comp1 = oddmr_data->companion;

//		mtk_oddmr_dmr_common_init(comp1, pkg);
//	}
//}

static void mtk_oddmr_dmr_static_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, struct mtk_drm_dmr_static_cfg *static_cfg_data)
{
	uint32_t cnt;
	int i;

	ODDMRAPI_LOG("+\n");
	if (static_cfg_data && static_cfg_data->reg_num &&
		static_cfg_data->reg_offset &&
		static_cfg_data->reg_value &&
		static_cfg_data->reg_mask) {
		cnt = static_cfg_data->reg_num;
		for (i = 0; i < cnt; i++)
			if(static_cfg_data->reg_mask[i])
				mtk_oddmr_write_mask(comp,static_cfg_data->reg_value[i],
					static_cfg_data->reg_offset[i], static_cfg_data->reg_mask[i], pkg);
	} else
		ODDMRFLOW_LOG("dmr static config data error\n");
}

int mtk_oddmr_linear_interpolation(int x, int x1, int y1, int x2, int y2)
{
	int y;

	if(x1 == x2)
		return y1;
	y = (100 * (long long) y1 +
		100 * ((long long) y2 - (long long) y1) *
		((long long) x - (long long) x1) /
		((long long) x2 - (long long) x1)) / 100;
	return y;
}

static int mtk_oddmr_linear_interpolation_round(int x, int x1, int y1, int x2, int y2)
{
	int y;

	if (x1 == x2)
		return y1;
	if (x <= x1)
		return y1;
	if (x >= x2)
		return y2;

	y = 100 * (long long) y1 +
		100 * ((long long) y2 - (long long) y1) *
		((long long) x - (long long) x1) /
		((long long) x2 - (long long) x1);
	y = (y >= 0) ? (y + 50) : (y - 50);
	y = y / 100;
	return y;
}

static void mtk_oddmr_dmr_gain_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, unsigned int dbv_node, unsigned int fps_node,
		struct mtk_drm_dmr_cfg_info *cfg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_cus_setting_info *cus_setting_info;
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node;
	struct mtk_drm_dmr_fps_dbv_change_cfg *fps_dbv_change_cfg;
	unsigned int setting_state;
	unsigned int cur_binset_idx = atomic_read(&oddmr_data->dmr_data.cur_binset_idx);
	int cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
	unsigned int cnt;
	int i;
	unsigned int base_idx;
	unsigned int base_idx_fps_add1;
	unsigned int base_idx_dbv_add1;
	unsigned int base_idx_dbv_fps_add1;

	unsigned int dbv_node_add1;
	unsigned int fps_node_add1;
	unsigned int value_interpolate_by_dbv;
	unsigned int value_interpolate_by_dbv1;
	unsigned int value_interpolate_by_fps;
	unsigned int cur_dbv;
	unsigned int cur_fps;
	unsigned int cur_dbv_mode;
	unsigned int result_offset = 0;
	char result[512];
	unsigned int shift;

	if (!cfg_info) {
		ODDMRFLOW_LOG("cfg_info is NULL\n");
		return;
	}

	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
	cur_fps = oddmr_data->primary_data->current_timing.vrefresh;
	cur_dbv_mode = oddmr_data->primary_data->current_timing.dbv_mode;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	ODDMRAPI_LOG("+\n");
	setting_state = atomic_read(&oddmr_data->dmr_data.cus_setting_state);
	cus_setting_info = &oddmr_data->primary_data->dmr_cus_setting_info;
	if (setting_state == 1) {
		if(cur_dbv_mode >= cus_setting_info->dbv_mode_num) {
			ODDMRFLOW_LOG("dbv_mode out of range\n");
			return;
		}
		fps_dbv_node = &cus_setting_info->fps_dbv_node[cur_dbv_mode];
		fps_dbv_change_cfg = &cus_setting_info->fps_dbv_change_cfg[cur_dbv_mode];
	} else {
		fps_dbv_node = &cfg_info->fps_dbv_node;
		fps_dbv_change_cfg = &cfg_info->fps_dbv_change_cfg;
	}
	if ((fps_dbv_node == NULL) || (fps_dbv_change_cfg == NULL)) {
		ODDMRFLOW_LOG("fps_dbv setting node is NULL\n");
		return;
	}
	if (dbv_node >= fps_dbv_node->DBV_num) {
		ODDMRFLOW_LOG("dbv_node out of range\n");
		return;
	}
	if (fps_node >= fps_dbv_node->FPS_num) {
		ODDMRFLOW_LOG("fps_node out of range\n");
		return;
	}
	if (fps_dbv_change_cfg->reg_offset && fps_dbv_change_cfg->reg_value) {
		cnt = fps_dbv_change_cfg->reg_num;
		if(dbv_node < (fps_dbv_node->DBV_num - 1))
			dbv_node_add1 = dbv_node + 1;
		else
			dbv_node_add1 = dbv_node;
		if(fps_node < (fps_dbv_node->FPS_num- 1))
			fps_node_add1 = fps_node + 1;
		else
			fps_node_add1 = fps_node;
		if(g_dmr_dump_en) {
			DDPMSG("-- DeMura Current gain info dump --\n");
			DDPMSG("cur_binset_idx: %u\n", cur_binset_idx);
			DDPMSG("cur_bin_idx: %d\n", cur_bin_idx);
			DDPMSG("cur_dbv: %u\n", cur_dbv);
			DDPMSG("cur_fps: %u\n", cur_fps);
			DDPMSG("cur_dbv_mode: %u\n", cur_dbv_mode);
			DDPMSG("cur_dbv_node[%u]:%u\n", dbv_node, fps_dbv_node->DBV_node[dbv_node]);
			DDPMSG("cur_fps_node[%u]:%u\n", fps_node, fps_dbv_node->FPS_node[fps_node]);
			DDPMSG("reg_cfg count: %u\n", cnt);
			DDPMSG("value_interpolate_by_fps_dbv_mode:\n");
		}
		base_idx = dbv_node * fps_dbv_node->FPS_num * cnt + fps_node * cnt;
		base_idx_fps_add1 = dbv_node * fps_dbv_node->FPS_num * cnt + fps_node_add1 * cnt;
		base_idx_dbv_add1 = dbv_node_add1 * fps_dbv_node->FPS_num * cnt + fps_node * cnt;
		base_idx_dbv_fps_add1 = dbv_node_add1 * fps_dbv_node->FPS_num * cnt + fps_node_add1 * cnt;
		for(i = 0; i < cnt; i++) {
			value_interpolate_by_dbv = mtk_oddmr_linear_interpolation_round(cur_dbv,
				fps_dbv_node->DBV_node[dbv_node],
				fps_dbv_change_cfg->reg_value[base_idx + i],
				fps_dbv_node->DBV_node[dbv_node_add1],
				fps_dbv_change_cfg->reg_value[base_idx_dbv_add1 + i]);
			value_interpolate_by_dbv1 = mtk_oddmr_linear_interpolation_round(cur_dbv,
				fps_dbv_node->DBV_node[dbv_node],
				fps_dbv_change_cfg->reg_value[base_idx_fps_add1 + i],
				fps_dbv_node->DBV_node[dbv_node_add1],
				fps_dbv_change_cfg->reg_value[base_idx_dbv_fps_add1 + i]);
			value_interpolate_by_fps = mtk_oddmr_linear_interpolation_round(cur_fps,
				fps_dbv_node->FPS_node[fps_node],
				value_interpolate_by_dbv,
				fps_dbv_node->FPS_node[fps_node_add1],
				value_interpolate_by_dbv1);
			/* shift value_interpolate_by_fps */
			shift = ((fps_dbv_change_cfg->reg_mask[i]^(fps_dbv_change_cfg->reg_mask[i] -1 )) + 1) >> 1;
			mtk_oddmr_write_mask(comp,
				(value_interpolate_by_fps * shift),
				fps_dbv_change_cfg->reg_offset[i],
				fps_dbv_change_cfg->reg_mask[i], pkg);
			if(g_dmr_dump_en) {
				result_offset += sprintf(result + result_offset, "%d ", value_interpolate_by_fps);
				if(((i + 1) % 7) == 0) {
					DDPMSG("%s\n", result);
					result_offset = 0;
				}
			}
		}
		if(g_dmr_dump_en && (i % 7 != 0))
			DDPMSG("%s\n", result);
	} else
		ODDMRFLOW_LOG("dmr static config data error\n");
}

static void mtk_oddmr_tuning_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, struct mtk_drm_oddmr_reg_tuning *tuning_info)
{
	uint32_t cnt;
	int i;

	ODDMRAPI_LOG("+\n");
	if (tuning_info && tuning_info->reg_num && tuning_info->reg_addr
		&& tuning_info->reg_value && tuning_info->reg_mask) {
		cnt = tuning_info->reg_num;
		for (i = 0; i < cnt; i++) {
			if(tuning_info->reg_mask[i])
				mtk_oddmr_register_write_mask(comp, tuning_info->reg_addr[i],
					tuning_info->reg_value[i], tuning_info->reg_mask[i], pkg);
		}
	} else
		PC_ERR("oddmr tuning config error\n");
}

static void mtk_oddmr_dbi_gain_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, unsigned int dbv_node, unsigned int fps_node,
		struct mtk_drm_dbi_cfg_info *cfg_info, unsigned int gain_ratio)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int cnt;
	int i;
	unsigned int base_idx;
	unsigned int base_idx_fps_add1;
	unsigned int base_idx_dbv_add1;
	unsigned int base_idx_dbv_fps_add1;

	unsigned int dbv_node_add1;
	unsigned int fps_node_add1;
	unsigned int value_interpolate_by_dbv;
	unsigned int value_interpolate_by_dbv1;
	unsigned int value_interpolate_by_fps;
	unsigned int cur_dbv;
	unsigned int cur_fps;

	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
	cur_fps = oddmr_data->primary_data->current_timing.vrefresh;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	ODDMRAPI_LOG("+\n");

	if (cfg_info && cfg_info->fps_dbv_change_cfg.reg_offset && cfg_info->fps_dbv_change_cfg.reg_value) {
		cnt = cfg_info->fps_dbv_change_cfg.reg_num;
		if(dbv_node < (cfg_info->fps_dbv_node.DBV_num - 1))
			dbv_node_add1 = dbv_node + 1;
		else
			dbv_node_add1 = dbv_node;

		if(fps_node < (cfg_info->fps_dbv_node.FPS_num- 1))
			fps_node_add1 = fps_node + 1;
		else
			fps_node_add1 = fps_node;


		base_idx = dbv_node * (cfg_info->fps_dbv_node.FPS_num) * cnt + fps_node * cnt;
		base_idx_fps_add1 = dbv_node * (cfg_info->fps_dbv_node.FPS_num) * cnt + fps_node_add1 * cnt;
		base_idx_dbv_add1 = dbv_node_add1 * (cfg_info->fps_dbv_node.FPS_num) * cnt + fps_node * cnt;
		base_idx_dbv_fps_add1 = dbv_node_add1 * (cfg_info->fps_dbv_node.FPS_num) * cnt + fps_node_add1 * cnt;

		for(i = 0; i < cnt; i++) {
			value_interpolate_by_dbv = mtk_oddmr_linear_interpolation(cur_dbv,
				cfg_info->fps_dbv_node.DBV_node[dbv_node],
				cfg_info->fps_dbv_change_cfg.reg_value[base_idx + i],
				cfg_info->fps_dbv_node.DBV_node[dbv_node_add1],
				cfg_info->fps_dbv_change_cfg.reg_value[base_idx_dbv_add1 + i]);
			value_interpolate_by_dbv1 = mtk_oddmr_linear_interpolation(cur_dbv,
				cfg_info->fps_dbv_node.DBV_node[dbv_node],
				cfg_info->fps_dbv_change_cfg.reg_value[base_idx_fps_add1 + i],
				cfg_info->fps_dbv_node.DBV_node[dbv_node_add1],
				cfg_info->fps_dbv_change_cfg.reg_value[base_idx_dbv_fps_add1 + i]);
			value_interpolate_by_fps = mtk_oddmr_linear_interpolation(cur_fps,
				cfg_info->fps_dbv_node.FPS_node[fps_node],
				value_interpolate_by_dbv,
				cfg_info->fps_dbv_node.FPS_node[fps_node_add1],
				value_interpolate_by_dbv1);

			ODDMRAPI_LOG("gain_ratio : %d\n", gain_ratio);
			value_interpolate_by_fps *= gain_ratio;
			value_interpolate_by_fps /= 100;

			mtk_oddmr_write_mask(comp,
				value_interpolate_by_fps,
				cfg_info->fps_dbv_change_cfg.reg_offset[i],
				cfg_info->fps_dbv_change_cfg.reg_mask[i], pkg);
		}
	} else
		ODDMRFLOW_LOG("dbi gain config data error\n");
}


static void mtk_oddmr_dbi_dbv_table_cfg(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, unsigned int dbv_node,
		struct mtk_drm_dbi_cfg_info *cfg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int cnt;
	int i,j;
	unsigned int base_idx;
	unsigned int base_idx_dbv_add1;

	unsigned int dbv_node_add1;
	unsigned int value_interpolate_by_dbv;

	unsigned int cur_dbv;
	unsigned int cur_fps;
	int index[7] = {3, 4, 6, 8, 12, 18, 20};
	int value[7] = {4, 8, 32, 64, 128, 224, 255};

	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
	cur_fps = oddmr_data->primary_data->current_timing.vrefresh;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	ODDMRAPI_LOG("+\n");

	if (cfg_info && cfg_info->dbv_change_cfg.reg_offset && cfg_info->dbv_change_cfg.reg_value) {
		cnt = cfg_info->dbv_change_cfg.reg_num;
		if(dbv_node < (cfg_info->dbv_node.DBV_num - 1))
			dbv_node_add1 = dbv_node + 1;
		else
			dbv_node_add1 = dbv_node;

		base_idx = dbv_node * cfg_info->dbv_change_cfg.reg_num;
		base_idx_dbv_add1 = dbv_node_add1 * cfg_info->dbv_change_cfg.reg_num;

		ODDMRAPI_LOG("dbv num  %d\n", cfg_info->dbv_node.DBV_num);
		ODDMRAPI_LOG("curdbv : %d\n", cur_dbv);
		for(i = 0; i < cnt; i++) {

			value_interpolate_by_dbv = mtk_oddmr_linear_interpolation(cur_dbv,
				cfg_info->dbv_node.DBV_node[dbv_node],
				cfg_info->dbv_change_cfg.reg_value[base_idx + i],
				cfg_info->dbv_node.DBV_node[dbv_node_add1],
				cfg_info->dbv_change_cfg.reg_value[base_idx_dbv_add1 + i]);

			for(j = 0; j < 7; j++) {
				if(i%21 == index[j]) {
					ODDMRAPI_LOG("dbv_node : %d, value:%d\n",
						cfg_info->dbv_node.DBV_node[dbv_node],
						cfg_info->dbv_change_cfg.reg_value[base_idx + i]/4);
					ODDMRAPI_LOG("dbv_node+1 : %d, value:%d\n",
						cfg_info->dbv_node.DBV_node[dbv_node_add1],
						cfg_info->dbv_change_cfg.reg_value[base_idx_dbv_add1 + i]/4);
					if(i/21 == 0)
						ODDMRAPI_LOG("R gray %d : %d\n", value[j],
							value_interpolate_by_dbv/4);
					if(i/21 == 1)
						ODDMRAPI_LOG("G gray %d : %d\n", value[j],
							value_interpolate_by_dbv/4);
					if(i/21 == 2)
						ODDMRAPI_LOG("B gray %d : %d\n", value[j],
							value_interpolate_by_dbv/4);
				}
			}
			mtk_oddmr_write_mask(comp,
				value_interpolate_by_dbv,
				cfg_info->dbv_change_cfg.reg_offset[i],
				cfg_info->dbv_change_cfg.reg_mask[i], pkg);
		}
	} else
		ODDMRFLOW_LOG("dbi dbv table config data error\n");
}

static int mtk_oddmr_get_dmr_cfg_data(struct mtk_ddp_comp *comp,
	struct mtk_drm_dmr_cfg_info *cfg_info, unsigned int bin_index)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	void *data = NULL;
	uint64_t size;
	int i;
	int static_log=10;
	int change_log=10;
	int table_log = 10;
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data;

	ODDMRAPI_LOG("+\n");

	dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[bin_index - 1];

	dmr_cfg_data->basic_info = cfg_info->basic_info;
	mtk_drm_dmr_static_cfg_cpy(&dmr_cfg_data->static_cfg, &cfg_info->static_cfg, true);
	mtk_drm_dmr_fps_dbv_node_cpy(&dmr_cfg_data->fps_dbv_node, &cfg_info->fps_dbv_node, true);
	mtk_drm_dmr_fps_dbv_change_cfg_cpy(&dmr_cfg_data->fps_dbv_change_cfg, &cfg_info->fps_dbv_change_cfg, true);
	mtk_drm_dmr_table_index_cpy(&dmr_cfg_data->table_index, &cfg_info->table_index, true);
	mtk_drm_dmr_table_content_cpy(&dmr_cfg_data->table_content, &cfg_info->table_content, true);
	mtk_drm_oddmr_partial_update_params_cpy(&dmr_cfg_data->dmr_pu_info, &cfg_info->dmr_pu_info, true);
	dmr_cfg_data->panel_id = cfg_info->panel_id;

	if (oddmr_data->dmr_data.max_table_size < dmr_cfg_data->table_index.table_byte_num)
		oddmr_data->dmr_data.max_table_size = dmr_cfg_data->table_index.table_byte_num;

	ODDMRLOW_LOG("basic_info.panel_id_len %d\n", dmr_cfg_data->basic_info.panel_id_len);
	ODDMRLOW_LOG("basic_info.panel_width %d\n", dmr_cfg_data->basic_info.panel_width);
	ODDMRLOW_LOG("basic_info.panel_height %d\n", dmr_cfg_data->basic_info.panel_height);
	ODDMRLOW_LOG("basic_info.catch_bit %d\n", dmr_cfg_data->basic_info.catch_bit);
	ODDMRLOW_LOG("basic_info.blank_bit %d\n", dmr_cfg_data->basic_info.blank_bit);
	ODDMRLOW_LOG("basic_info.zero_bit %d\n", dmr_cfg_data->basic_info.zero_bit);
	ODDMRLOW_LOG("basic_info.h_num %d\n", dmr_cfg_data->basic_info.h_num);
	ODDMRLOW_LOG("basic_info.v_num %d\n", dmr_cfg_data->basic_info.v_num);
	ODDMRLOW_LOG("dmr_pu_info.is_compression_mode %d\n",
		dmr_cfg_data->dmr_pu_info.is_compression_mode);
	ODDMRLOW_LOG("dmr_pu_info.compression_mode_ln_offset %d\n",
		dmr_cfg_data->dmr_pu_info.compression_mode_ln_offset);
	ODDMRLOW_LOG("table_byte_num %d\n", dmr_cfg_data->table_index.table_byte_num);
	ODDMRLOW_LOG("dmr_pu_info.slice_num %d\n", dmr_cfg_data->dmr_pu_info.slice_num);
	ODDMRLOW_LOG("table_byte_num %d\n", dmr_cfg_data->table_index.table_byte_num);
	ODDMRLOW_LOG("max table byte num %d\n", oddmr_data->dmr_data.max_table_size);

	if (dmr_cfg_data->static_cfg.reg_num > PQ_MAX_REG_NUM ||
		dmr_cfg_data->fps_dbv_change_cfg.reg_num > PQ_MAX_REG_NUM ||
		dmr_cfg_data->fps_dbv_node.DBV_num > CUS_MAX_DBV_NUM ||
		dmr_cfg_data->fps_dbv_node.FPS_num > CUS_MAX_FPS_NUM ||
		dmr_cfg_data->table_index.DBV_table_num > 1 ||
		dmr_cfg_data->table_index.FPS_table_num > 1) {
		PC_ERR("%s:%d, dmr_cfg_data data invalid\n", __func__, __LINE__);
			goto fail;
	}


	if(dmr_cfg_data->static_cfg.reg_num) {
		size = sizeof(uint32_t) * dmr_cfg_data->static_cfg.reg_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->static_cfg.reg_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->static_cfg.reg_value = (uint32_t *)data;

		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->static_cfg.reg_offset, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->static_cfg.reg_offset = (uint32_t *)data;

		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->static_cfg.reg_mask, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->static_cfg.reg_mask = (uint32_t *)data;
	}

	if(static_log > dmr_cfg_data->static_cfg.reg_num)
		static_log = dmr_cfg_data->static_cfg.reg_num;

	if(dmr_cfg_data->fps_dbv_node.DBV_num){
		ODDMRLOW_LOG("dmr copy dbv node: %d", dmr_cfg_data->fps_dbv_node.DBV_num);
		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_node.DBV_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_node.DBV_node, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_node.DBV_node = (uint32_t *)data;
	}

	if(dmr_cfg_data->fps_dbv_node.FPS_num) {
		ODDMRLOW_LOG("dmr copy fps node: %d", dmr_cfg_data->fps_dbv_node.FPS_num);
		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_node.FPS_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_node.FPS_node, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_node.FPS_node = (uint32_t *)data;
	}

	if(dmr_cfg_data->fps_dbv_node.remap_reduce_offset_num) {
		ODDMRLOW_LOG("dmr copy remap node: %d", dmr_cfg_data->fps_dbv_node.remap_reduce_offset_num);
		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_node.remap_reduce_offset_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_node.remap_reduce_offset_node, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_node.remap_reduce_offset_node = (uint32_t *)data;
	}

	if(dmr_cfg_data->fps_dbv_node.remap_reduce_offset_num) {
		ODDMRLOW_LOG("dmr copy remap node: %d", dmr_cfg_data->fps_dbv_node.remap_reduce_offset_num);
		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_node.remap_reduce_offset_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_node.remap_reduce_offset_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_node.remap_reduce_offset_value = (uint32_t *)data;
	}

	if(dmr_cfg_data->fps_dbv_node.remap_dbv_gain_num) {
		ODDMRLOW_LOG("dmr copy remap dbv node: %d", dmr_cfg_data->fps_dbv_node.remap_dbv_gain_num);
		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_node.remap_dbv_gain_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_node.remap_dbv_gain_node, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_node.remap_dbv_gain_node = (uint32_t *)data;
	}

	if(dmr_cfg_data->fps_dbv_node.remap_dbv_gain_num) {
		ODDMRLOW_LOG("dmr copy remap dbv node: %d", dmr_cfg_data->fps_dbv_node.remap_dbv_gain_num);
		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_node.remap_dbv_gain_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_node.remap_dbv_gain_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_node.remap_dbv_gain_value = (uint32_t *)data;
	}

	if(dmr_cfg_data->fps_dbv_change_cfg.reg_num){
		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_change_cfg.reg_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_change_cfg.reg_offset, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_change_cfg.reg_offset = (uint32_t *)data;

		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->fps_dbv_change_cfg.reg_mask, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->fps_dbv_change_cfg.reg_mask = (uint32_t *)data;

		size = sizeof(uint32_t) * dmr_cfg_data->fps_dbv_node.FPS_num
			* dmr_cfg_data->fps_dbv_node.DBV_num * dmr_cfg_data->fps_dbv_change_cfg.reg_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}

		if (dmr_cfg_data->fps_dbv_node.DC_flag) {
			if (copy_from_user(data, cfg_info->fps_dbv_change_cfg.reg_DC_value, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			dmr_cfg_data->fps_dbv_change_cfg.reg_DC_value= (uint32_t *)data;
		}else{
			if (copy_from_user(data, cfg_info->fps_dbv_change_cfg.reg_value, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			dmr_cfg_data->fps_dbv_change_cfg.reg_value= (uint32_t *)data;
		}
	}

	if(change_log > dmr_cfg_data->fps_dbv_change_cfg.reg_num)
		change_log = dmr_cfg_data->fps_dbv_change_cfg.reg_num;

	if(dmr_cfg_data->table_index.DBV_table_num){
		ODDMRLOW_LOG("dmr copy DBV table index: %d", dmr_cfg_data->table_index.DBV_table_num);
		size = sizeof(uint32_t) * dmr_cfg_data->table_index.DBV_table_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->table_index.DBV_table_idx, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->table_index.DBV_table_idx = (uint32_t *)data;
	}

	if (dmr_cfg_data->table_index.FPS_table_num) {
		ODDMRLOW_LOG("dmr copy FPS table index: %d", dmr_cfg_data->table_index.FPS_table_num);
		size = sizeof(uint32_t) * dmr_cfg_data->table_index.FPS_table_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->table_index.FPS_table_idx, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->table_index.FPS_table_idx = (uint32_t *)data;
	}
	if (dmr_cfg_data->table_index.table_byte_num) {
		unsigned int DBV_table_num = dmr_cfg_data->table_index.DBV_table_num;
		unsigned int FPS_table_num = dmr_cfg_data->table_index.FPS_table_num;
		unsigned int table_byte_num = dmr_cfg_data->table_index.table_byte_num;

		if (table_byte_num == 0 || DBV_table_num == 0 || FPS_table_num == 0 ||
			DBV_table_num > 1 || FPS_table_num > 1) {
			PC_ERR("%s:%d, table size invalid DBV_table_num=%d FPS_table_num=%d table_byte_num=%d\n",
				__func__, __LINE__, DBV_table_num, FPS_table_num, table_byte_num);
			goto fail;
		}
		size = table_byte_num * DBV_table_num * FPS_table_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (dmr_cfg_data->table_index.DC_table_flag) {
			if (copy_from_user(data, cfg_info->table_content.table_single_DC, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			dmr_cfg_data->table_content.table_single_DC = (unsigned char *)data;
		}else{
			if (copy_from_user(data, cfg_info->table_content.table_single, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			dmr_cfg_data->table_content.table_single = (unsigned char *)data;
		}
		ODDMRLOW_LOG("%s bin_index=%d\n", __func__, bin_index);
		ODDMRLOW_LOG("%s DBV_table_num=%d FPS_table_num=%d table_byte_num=%d\n", __func__,
			DBV_table_num, FPS_table_num, table_byte_num);
		if (mtk_oddmr_dmr_alloc_table(comp, (bin_index - 1), dmr_cfg_data)) {
			PC_ERR("dmr alloc table fail\n");
			goto fail;
		}
		if (dmr_cfg_data->table_index.DC_table_flag) {
			if (dmr_cfg_data->table_content.table_single_DC)
				vfree(dmr_cfg_data->table_content.table_single_DC);
			dmr_cfg_data->table_content.table_single_DC = NULL;
		} else {
			if (dmr_cfg_data->table_content.table_single)
				vfree(dmr_cfg_data->table_content.table_single);
			dmr_cfg_data->table_content.table_single = NULL;
		}
	}

	if(table_log > dmr_cfg_data->table_index.table_byte_num)
		table_log = dmr_cfg_data->table_index.table_byte_num;

	if(dmr_cfg_data->dmr_pu_info.slice_num) {
		size = sizeof(uint32_t) * dmr_cfg_data->dmr_pu_info.slice_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->dmr_pu_info.slice_size, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->dmr_pu_info.slice_size = (uint32_t *)data;

		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cfg_info->dmr_pu_info.slice_height, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_cfg_data->dmr_pu_info.slice_height = (uint32_t *)data;
	}
	if (bin_index == oddmr_data->primary_data->dmr_binset_cfg_info.binfile_num)
		oddmr_data->primary_data->dmr_state = ODDMR_LOAD_DONE;
	return 0;

fail:
	mtk_drm_dmr_cfg_info_rst(dmr_cfg_data);
	return -EFAULT;
}

void *oddmr_realloc_buffer(void *a, int old_size, int new_size)
{
	void *b;

	b = vmalloc(new_size);
	if (b) {
		memcpy(b,a,old_size);
		vfree(a);
	}
	return b;
}

void insert_buffer(struct bitstream_buffer *a, uint8_t element)
{
	uint8_t *extended_array = NULL;

	if (a->used_entry == a->size) {
		a->size += 10; // extend size for 10 entries each time
		extended_array = (uint8_t *)oddmr_realloc_buffer(a->_buffer, a->size-10, a->size);

		if (extended_array != NULL)
			a->_buffer = extended_array;
		else {
			// Fail to extend array size
			a->_buffer = NULL;
		}
	}
	if(a->_buffer)
		a->_buffer[a->used_entry++] = element;
}

void init_buffer(struct bitstream_buffer *a, uint32_t initialSize)
{
	a->_buffer = vmalloc(initialSize * sizeof(uint8_t));
	a->used_entry = 0;
	a->used_bit = 0;
	a->size = initialSize;
}

void free_buffer(struct bitstream_buffer *a)
{
	vfree(a->_buffer);
	a->_buffer = NULL;
	a->used_entry = a->size = 0;
}


void init_read(struct bitstream_buffer *a)
{
	a->read_bit = 0;
}

int get_buffer(struct bitstream_buffer *a, int bits)
{
	int data = 0;
	unsigned int res_bits = a->read_bit & 0x7;
	int rem_bytes;
	unsigned int read_bits;

	if (res_bits > 0) {
		read_bits = MIN(8 - res_bits, (unsigned int)bits);
		data = (a->_buffer[a->read_bit >> 3] >> (8 - res_bits - read_bits)) & ((1 << read_bits) - 1);

		bits -= read_bits;
		a->read_bit += read_bits;
	}

	rem_bytes = bits >> 3;
	for (int i = 0; i < rem_bytes; ++i) {
		data = (data << 8) | a->_buffer[a->read_bit >> 3];
		bits -= 8;
		a->read_bit += 8;
	}

	if (bits > 0) {
		data = (data << bits) | (a->_buffer[a->read_bit >> 3] >> (8 - bits));
		a->read_bit += bits;
	}

	return data;
}

void put_buffer(struct bitstream_buffer *a, uint32_t data, uint32_t data_bits)
{
	uint32_t bytes = a->used_bit >> 3;
	uint32_t res_bits = a->used_bit & 0x7;
	int rem_bytes;
	uint32_t push_bits;

	a->used_bit += data_bits;
	if (res_bits > 0) {
		push_bits = MIN(8 - res_bits, data_bits);
		a->_buffer[bytes] = a->_buffer[bytes] | (
			(((1 << push_bits) - 1) & (data >> (data_bits - push_bits))
				) << (8 - res_bits - push_bits)
			);
		data_bits -= push_bits;
		data = data & ((1 << data_bits) - 1);
	}
	rem_bytes = data_bits >> 3;
	for (int i = 0; i < rem_bytes; ++i) {
		insert_buffer(a, (data >> (data_bits - 8)));
		data_bits -= 8;
	}

	if (data_bits > 0)
		insert_buffer(a, (data & ((1 << data_bits) - 1)) << (8 - data_bits));
}

unsigned char _reverse(unsigned char n)
{
	unsigned char tmp = n & 0xf;
	unsigned char tmp1 = n >> 4;

	// Reverse the top and bottom nibble then swap them.
	return (lookup[tmp] << 4) | lookup[tmp1];
}

int mtk_oddmr_dbi_copy_static_cfg(struct mtk_drm_dmr_static_cfg *static_cfg,
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct)
{
	int size = sizeof(uint32_t) * static_cfg->reg_num;

	if (copy_from_user(dbi_bin_struct->static_cfg.reg_value,
		static_cfg->reg_value, size)) {
		PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
		return -1;
	}
	if (copy_from_user(dbi_bin_struct->static_cfg.reg_offset,
		static_cfg->reg_offset, size)) {
		PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
		return -1;
	}
	if (copy_from_user(dbi_bin_struct->static_cfg.reg_mask,
		static_cfg->reg_mask, size)) {
		PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
		return -1;
	}
	return 0;
}

int mtk_oddmr_dbi_copy_chg_cfg(struct mtk_drm_dmr_fps_dbv_change_cfg *change_cfg,
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct)
{
	int size = sizeof(uint32_t) * change_cfg->reg_num;

	if (copy_from_user(dbi_bin_struct->fps_dbv_change_cfg.reg_value,
		change_cfg->reg_value, size)) {
		PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
		return -1;
	}
	if (copy_from_user(dbi_bin_struct->fps_dbv_change_cfg.reg_offset,
		change_cfg->reg_offset, size)) {
		PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
		return -1;
	}
	if (copy_from_user(dbi_bin_struct->fps_dbv_change_cfg.reg_mask,
		change_cfg->reg_mask, size)) {
		PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
		return -1;
	}

	size = sizeof(uint32_t) * dbi_bin_struct->fps_dbv_node.FPS_num
		* dbi_bin_struct->fps_dbv_node.DBV_num * dbi_bin_struct->fps_dbv_change_cfg.reg_num;

	if (dbi_bin_struct->fps_dbv_node.DC_flag) {
		if (copy_from_user(dbi_bin_struct->fps_dbv_change_cfg.reg_DC_value,
			change_cfg->reg_DC_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			return -1;
		}
	} else {
		if (copy_from_user(dbi_bin_struct->fps_dbv_change_cfg.reg_value,
			change_cfg->reg_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			return -1;
		}
	}
	return 0;
}

static unsigned int mtk_oddmr_dbi_block_h(struct mtk_drm_dbi_cfg_info *dbi_bin_struct)
{
	unsigned int ret = 0;
	int i;

	for (i = 0; i < dbi_bin_struct->static_cfg.reg_num; i++) {
		if((dbi_bin_struct->static_cfg.reg_offset[i] == 0x10710)
			&& (dbi_bin_struct->static_cfg.reg_mask[i] == 0xf))
			ret = dbi_bin_struct->static_cfg.reg_value[i];
	}
	return ret;
}

static unsigned int mtk_oddmr_dbi_block_v(struct mtk_drm_dbi_cfg_info *dbi_bin_struct)
{
	unsigned int ret = 0;
	int i;

	for (i = 0; i < dbi_bin_struct->static_cfg.reg_num; i++) {
		if((dbi_bin_struct->static_cfg.reg_offset[i] == 0x10714)
			&& (dbi_bin_struct->static_cfg.reg_mask[i] == 0xf))
			ret = dbi_bin_struct->static_cfg.reg_value[i];
	}
	return ret;
}


void kernel_dbi_table_update_V3(struct mtk_ddp_comp *comp, struct mtk_dbi_alg_comp_hw_param *data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct = &oddmr_data->primary_data->dbi_cfg_info;
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct_tb1 = &oddmr_data->primary_data->dbi_cfg_info_tb1;
	static int first_update;
	unsigned int block_v, block_h;
	struct mtk_dbi_alg_comp_hw_param *hw_param = data;
	unsigned int size;
	void *ptr = NULL;
	void *ptr_t = NULL;
	unsigned int panel_height = dbi_bin_struct->basic_info.panel_height;

	size = hw_param->dram_table.used_entry;
	ptr = vmalloc(size);
	if (!ptr) {
		PC_ERR("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
		return;
	}

	if (copy_from_user(ptr,
		hw_param->dram_table._buffer, size)) {
		PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
		goto exit;
	}
	hw_param->dram_table._buffer = ptr;

	if(!first_update) {
		first_update++;
		if(hw_param->table_format == DBI_COMP_TABLE_COMPRESSION) {
			oddmr_data->dbi_data.used_entry[0] = hw_param->dram_table.used_entry;
			oddmr_data->dbi_data.used_entry[1] = hw_param->dram_table.used_entry;
			oddmr_data->dbi_data.curr_used_entry = hw_param->dram_table.used_entry;
			oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_dbi_load_buffer(
				&comp->mtk_crtc->base, hw_param->dram_table.used_entry+4096,
				hw_param->dram_table.used_entry,
				hw_param->dram_table._buffer, false);
			oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_dbi_load_buffer(
				&comp->mtk_crtc->base, hw_param->dram_table.used_entry+4096,
				hw_param->dram_table.used_entry,
				hw_param->dram_table._buffer, false);
		} else {
			oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_load_buffer(
				&comp->mtk_crtc->base,
				hw_param->dram_table.used_entry,
				hw_param->dram_table._buffer, false);
			oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_load_buffer(
				&comp->mtk_crtc->base,
				hw_param->dram_table.used_entry,
				hw_param->dram_table._buffer, false);
		}

		if(mtk_oddmr_dbi_copy_static_cfg(&hw_param->static_cfg, dbi_bin_struct)) {
			PC_ERR("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto exit;
		}
		if(mtk_oddmr_dbi_copy_static_cfg(&hw_param->static_cfg, dbi_bin_struct_tb1)) {
			PC_ERR("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto exit;
		}
		if(mtk_oddmr_dbi_copy_chg_cfg(&hw_param->fps_dbv_change_cfg, dbi_bin_struct)) {
			PC_ERR("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto exit;
		}
		if(mtk_oddmr_dbi_copy_chg_cfg(&hw_param->fps_dbv_change_cfg, dbi_bin_struct_tb1)) {
			PC_ERR("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto exit;
		}
		if(hw_param->table_format == DBI_COMP_TABLE_COMPRESSION) {
			block_h = 1;
			block_v = 4;

			size = hw_param->slice_num * sizeof(uint32_t);
			ptr_t = vmalloc(size);
			if (!ptr_t) {
				PC_ERR("%s:%d, param buffer alloc fail\n",
					__func__, __LINE__);
				goto exit;
			}

			if (copy_from_user(ptr_t, hw_param->slice_offset, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				vfree(ptr_t);
				goto exit;
			}
			oddmr_data->dbi_data.slice_offset[0] = ptr_t;

			ptr_t = vmalloc(size);
			if (!ptr_t) {
				PC_ERR("%s:%d, param buffer alloc fail\n",
					__func__, __LINE__);
				goto exit;
			}
			memcpy(ptr_t, oddmr_data->dbi_data.slice_offset[0], size);
			oddmr_data->dbi_data.slice_offset[1] = ptr_t;

			ptr_t = vmalloc(size);
			if (!ptr_t) {
				PC_ERR("%s:%d, param buffer alloc fail\n",
					__func__, __LINE__);
				goto exit;
			}
			memcpy(ptr_t, oddmr_data->dbi_data.slice_offset[0], size);
			oddmr_data->dbi_data.curr_slice_offset = ptr_t;

			oddmr_data->dbi_data.curr_slice_num = hw_param->slice_num;
			oddmr_data->dbi_data.slice_num[0] = hw_param->slice_num;
			oddmr_data->dbi_data.slice_num[1] = hw_param->slice_num;
			oddmr_data->dbi_data.table_size =  hw_param->max_line_size * panel_height;
			oddmr_data->dbi_data.slice_height[0] = hw_param->slice_height;
			oddmr_data->dbi_data.slice_height[1] = hw_param->slice_height;
			oddmr_data->dbi_data.curr_slice_height = hw_param->slice_height;
		} else  {
			block_h = mtk_oddmr_dbi_block_h(dbi_bin_struct);
			block_v = mtk_oddmr_dbi_block_v(dbi_bin_struct);
			oddmr_data->dbi_data.table_size =  hw_param->dram_table.used_entry;
		}
		atomic_set(&oddmr_data->dbi_data.cur_table_idx, 0);
		atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
		oddmr_data->dbi_data.dbi_table_size[0] = oddmr_data->dbi_data.table_size;
		oddmr_data->dbi_data.dbi_table_size[1] = oddmr_data->dbi_data.table_size;
		oddmr_data->dbi_data.dbi_table_block_h[0] = block_h;
		oddmr_data->dbi_data.dbi_table_block_h[1] = block_h;
		oddmr_data->dbi_data.dbi_table_block_v[0] = block_v;
		oddmr_data->dbi_data.dbi_table_block_v[1] = block_v;
		oddmr_data->dbi_data.table_format[0] = hw_param->table_format;
		oddmr_data->dbi_data.table_format[1] = hw_param->table_format;
		oddmr_data->dbi_data.curr_table_format = hw_param->table_format;
		oddmr_data->primary_data->dbi_cfg_info.basic_info.partial_update_scale_factor_h = block_h;
		oddmr_data->primary_data->dbi_cfg_info.basic_info.partial_update_scale_factor_v = block_v;
		atomic_set(&oddmr_data->dbi_data.update_table_done, 1);
	} else {
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		if(atomic_read(&oddmr_data->dbi_data.cur_table_idx)) {
			if(mtk_oddmr_dbi_copy_static_cfg(&hw_param->static_cfg, dbi_bin_struct)) {
				PC_ERR("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				goto exit;
			}
			if(mtk_oddmr_dbi_copy_chg_cfg(&hw_param->fps_dbv_change_cfg, dbi_bin_struct)) {
				PC_ERR("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				goto exit;
			}

			if(hw_param->table_format == DBI_COMP_TABLE_COMPRESSION) {
				if(hw_param->dram_table.used_entry != oddmr_data->dbi_data.used_entry[0]) {
					mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[0]->base);
					oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_dbi_load_buffer(
						&comp->mtk_crtc->base, hw_param->dram_table.used_entry + 4096,
						hw_param->dram_table.used_entry,
						hw_param->dram_table._buffer, false);
				} else
					memcpy(oddmr_data->dbi_data.dbi_table[0]->kvaddr,
						hw_param->dram_table._buffer, hw_param->dram_table.used_entry);
				oddmr_data->dbi_data.used_entry[0] = hw_param->dram_table.used_entry;
			} else{
				if (hw_param->dram_table.used_entry != oddmr_data->dbi_data.dbi_table_size[0]) {
					mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[0]->base);
					oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_load_buffer(
						&comp->mtk_crtc->base, hw_param->dram_table.used_entry,
						hw_param->dram_table._buffer, false);
				} else
					memcpy(oddmr_data->dbi_data.dbi_table[0]->kvaddr,
						hw_param->dram_table._buffer, hw_param->dram_table.used_entry);
			}
			if(hw_param->table_format == DBI_COMP_TABLE_COMPRESSION){
				block_h =1;
				block_v = 4;
				size = hw_param->slice_num * sizeof(uint32_t);
				if (hw_param->slice_num != oddmr_data->dbi_data.slice_num[0]) {
					oddmr_data->dbi_data.slice_num[0] = hw_param->slice_num;
					vfree(oddmr_data->dbi_data.slice_offset[0]);
					ptr_t = vmalloc(size);
					if (!ptr_t) {
						PC_ERR("%s:%d, param buffer alloc fail\n",
						__func__, __LINE__);
						goto exit;
					}
					if (copy_from_user(ptr_t, hw_param->slice_offset, size)) {
						PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
						goto exit;
					}
					oddmr_data->dbi_data.slice_offset[0] = ptr_t;
				} else {
					if (copy_from_user(oddmr_data->dbi_data.slice_offset[0],
						hw_param->slice_offset, size)) {
						PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
						goto exit;
					}
				}
				oddmr_data->dbi_data.slice_num[0] = hw_param->slice_num;
				oddmr_data->dbi_data.dbi_table_size[0] = hw_param->max_line_size * panel_height;
				oddmr_data->dbi_data.table_format[0] = hw_param->table_format;
				oddmr_data->dbi_data.slice_height[0] = hw_param->slice_height;
				oddmr_data->dbi_data.dbi_table_block_h[0] = block_h;
				oddmr_data->dbi_data.dbi_table_block_v[0] = block_v;
				atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
			}else {
				block_h = mtk_oddmr_dbi_block_h(dbi_bin_struct);
				block_v = mtk_oddmr_dbi_block_v(dbi_bin_struct);
				if (hw_param->dram_table.used_entry != oddmr_data->dbi_data.dbi_table_size[0]) {
					mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[0]->base);
					oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_load_buffer(
						&comp->mtk_crtc->base, hw_param->dram_table.used_entry,
						hw_param->dram_table._buffer, false);
					oddmr_data->dbi_data.dbi_table_block_h[0] = block_h;
					oddmr_data->dbi_data.dbi_table_block_v[0] = block_v;
					oddmr_data->dbi_data.dbi_table_size[0] = hw_param->dram_table.used_entry;
				} else
					memcpy(oddmr_data->dbi_data.dbi_table[0]->kvaddr,
						hw_param->dram_table._buffer, hw_param->dram_table.used_entry);
				atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
			}
		} else {
			if(mtk_oddmr_dbi_copy_static_cfg(&hw_param->static_cfg, dbi_bin_struct_tb1)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				return;
			}
			if(mtk_oddmr_dbi_copy_chg_cfg(&hw_param->fps_dbv_change_cfg, dbi_bin_struct_tb1)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				return;
			}

			if(hw_param->table_format == DBI_COMP_TABLE_COMPRESSION) {
				if(hw_param->dram_table.used_entry != oddmr_data->dbi_data.used_entry[1]) {
					mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[1]->base);
					oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_dbi_load_buffer(
						&comp->mtk_crtc->base, hw_param->dram_table.used_entry + 4096,
						hw_param->dram_table.used_entry,
						hw_param->dram_table._buffer, false);
				} else
					memcpy(oddmr_data->dbi_data.dbi_table[1]->kvaddr,
						hw_param->dram_table._buffer, hw_param->dram_table.used_entry);
				oddmr_data->dbi_data.used_entry[1] = hw_param->dram_table.used_entry;
			} else{
				if (hw_param->dram_table.used_entry != oddmr_data->dbi_data.dbi_table_size[1]) {
					mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[1]->base);
					oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_load_buffer(
						&comp->mtk_crtc->base, hw_param->dram_table.used_entry,
						hw_param->dram_table._buffer, false);
				} else
					memcpy(oddmr_data->dbi_data.dbi_table[1]->kvaddr,
						hw_param->dram_table._buffer, hw_param->dram_table.used_entry);
			}
			if(hw_param->table_format == DBI_COMP_TABLE_COMPRESSION){
				block_h =1;
				block_v = 4;
				size = hw_param->slice_num * sizeof(uint32_t);
				if (hw_param->slice_num != oddmr_data->dbi_data.slice_num[1]) {
					oddmr_data->dbi_data.slice_num[1] = hw_param->slice_num;
					vfree(oddmr_data->dbi_data.slice_offset[1]);
					ptr_t = vmalloc(size);
					if (!ptr_t) {
						PC_ERR("%s:%d, param buffer alloc fail\n",
						__func__, __LINE__);
						goto exit;
					}
					if (copy_from_user(ptr_t, hw_param->slice_offset, size)) {
						PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
						goto exit;
					}
					oddmr_data->dbi_data.slice_offset[1] = ptr_t;
				} else {
					if (copy_from_user(oddmr_data->dbi_data.slice_offset[1],
						hw_param->slice_offset, size)) {
						PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
						goto exit;
					}
				}

				oddmr_data->dbi_data.slice_num[1] = hw_param->slice_num;
				oddmr_data->dbi_data.dbi_table_size[1] = hw_param->max_line_size * panel_height;
				oddmr_data->dbi_data.table_format[1] = hw_param->table_format;
				oddmr_data->dbi_data.slice_height[1] = hw_param->slice_height;
				oddmr_data->dbi_data.dbi_table_block_h[1] = block_h;
				oddmr_data->dbi_data.dbi_table_block_v[1] = block_v;

				atomic_set(&oddmr_data->dbi_data.update_table_idx, 1);
			} else  {
				block_h = mtk_oddmr_dbi_block_h(dbi_bin_struct_tb1);
				block_v = mtk_oddmr_dbi_block_v(dbi_bin_struct_tb1);

				if (hw_param->dram_table.used_entry != oddmr_data->dbi_data.dbi_table_size[1]) {
					mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[1]->base);
					oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_load_buffer(
						&comp->mtk_crtc->base, hw_param->dram_table.used_entry,
						hw_param->dram_table._buffer, false);
					oddmr_data->dbi_data.dbi_table_block_h[1] = block_h;
					oddmr_data->dbi_data.dbi_table_block_v[1] = block_v;
					oddmr_data->dbi_data.dbi_table_size[1] =hw_param->dram_table.used_entry;
				} else
					memcpy(oddmr_data->dbi_data.dbi_table[1]->kvaddr,
						hw_param->dram_table._buffer, hw_param->dram_table.used_entry);
				atomic_set(&oddmr_data->dbi_data.update_table_idx, 1);
			}
		}
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
	}
exit:
	if (ptr)
		vfree(ptr);
}


void kernel_dbi_table_update_V2(struct mtk_ddp_comp *comp, struct bitstream_buffer *ret_drm_data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct = &oddmr_data->primary_data->dbi_cfg_info;
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct_tb1 = &oddmr_data->primary_data->dbi_cfg_info_tb1;
	static int first_update;
	unsigned int block_v, block_h;

	if(!first_update) {
		first_update++;
		oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_load_buffer(
			&comp->mtk_crtc->base, ret_drm_data->used_entry, ret_drm_data->_buffer, false);
		oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_load_buffer(
			&comp->mtk_crtc->base, ret_drm_data->used_entry, ret_drm_data->_buffer, false);

		if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			return;
		}
		if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct_tb1)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			return;
		}
		if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			return;
		}
		if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct_tb1)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			return;
		}

		block_h = mtk_oddmr_dbi_block_h(dbi_bin_struct);
		block_v = mtk_oddmr_dbi_block_v(dbi_bin_struct);

		atomic_set(&oddmr_data->dbi_data.update_table_done, 1);
		atomic_set(&oddmr_data->dbi_data.cur_table_idx, 0);
		atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
		oddmr_data->dbi_data.table_size =  ret_drm_data->used_entry;
		oddmr_data->dbi_data.dbi_table_size[0] = ret_drm_data->used_entry;
		oddmr_data->dbi_data.dbi_table_size[1] = ret_drm_data->used_entry;
		oddmr_data->dbi_data.dbi_table_block_h[0] = block_h;
		oddmr_data->dbi_data.dbi_table_block_h[1] = block_h;
		oddmr_data->dbi_data.dbi_table_block_v[0] = block_v;
		oddmr_data->dbi_data.dbi_table_block_v[1] = block_v;
		oddmr_data->primary_data->dbi_cfg_info.basic_info.partial_update_scale_factor_h = block_h;
		oddmr_data->primary_data->dbi_cfg_info.basic_info.partial_update_scale_factor_v = block_v;
	} else {
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		if(atomic_read(&oddmr_data->dbi_data.cur_table_idx)) {
			if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				return;
			}
			if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				return;
			}
			block_h = mtk_oddmr_dbi_block_h(dbi_bin_struct);
			block_v = mtk_oddmr_dbi_block_v(dbi_bin_struct);
			if (ret_drm_data->used_entry != oddmr_data->dbi_data.dbi_table_size[0]) {
				mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[0]->base);
				oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_load_buffer(
					&comp->mtk_crtc->base, ret_drm_data->used_entry,
					ret_drm_data->_buffer, false);
				oddmr_data->dbi_data.dbi_table_block_h[0] = block_h;
				oddmr_data->dbi_data.dbi_table_block_v[0] = block_v;
				oddmr_data->dbi_data.dbi_table_size[0] = ret_drm_data->used_entry;
			} else
				memcpy(oddmr_data->dbi_data.dbi_table[0]->kvaddr,
					ret_drm_data->_buffer, ret_drm_data->used_entry);
			atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
		} else {
			if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct_tb1)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				return;
			}
			if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct_tb1)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				return;
			}
			block_h = mtk_oddmr_dbi_block_h(dbi_bin_struct_tb1);
			block_v = mtk_oddmr_dbi_block_v(dbi_bin_struct_tb1);

			if (ret_drm_data->used_entry != oddmr_data->dbi_data.dbi_table_size[1]) {
				mtk_drm_gem_free_object(&oddmr_data->dbi_data.dbi_table[1]->base);
				oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_load_buffer(
					&comp->mtk_crtc->base, ret_drm_data->used_entry,
					ret_drm_data->_buffer, false);
				oddmr_data->dbi_data.dbi_table_block_h[1] = block_h;
				oddmr_data->dbi_data.dbi_table_block_v[1] = block_v;
				oddmr_data->dbi_data.dbi_table_size[1] = ret_drm_data->used_entry;
			} else
				memcpy(oddmr_data->dbi_data.dbi_table[1]->kvaddr,
					ret_drm_data->_buffer, ret_drm_data->used_entry);
			atomic_set(&oddmr_data->dbi_data.update_table_idx, 1);
		}
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
	}
}

void kernel_dbi_table_update(struct mtk_ddp_comp *comp, struct bitstream_buffer *ret_drm_data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct = &oddmr_data->primary_data->dbi_cfg_info;
	struct mtk_drm_dbi_cfg_info *dbi_bin_struct_tb1 = &oddmr_data->primary_data->dbi_cfg_info_tb1;
	int h_bit_cnt = ((dbi_bin_struct->basic_info.catch_bit + dbi_bin_struct->basic_info.blank_bit)
		* dbi_bin_struct->basic_info.h_num);
	int stuff_bit = 128 - (h_bit_cnt % 128);
	int use_byte = (h_bit_cnt + stuff_bit)*dbi_bin_struct->basic_info.v_num / 8;
	struct bitstream_buffer dbi_table_real;
	struct bitstream_buffer *dbi_table = &dbi_table_real;
	static int first_update;
	int line_stuff_bit;
	const int catch_once = 32;
	int catch_bit;

	init_buffer(dbi_table, use_byte);
	init_read(ret_drm_data);

	for (int y = 0; y < dbi_bin_struct->basic_info.v_num; y++) {
		for (int x = 0; x < dbi_bin_struct->basic_info.h_num; x++) {
			catch_bit = dbi_bin_struct->basic_info.catch_bit;
			while(catch_bit > 0) {
				if(catch_bit > catch_once)
					put_buffer(dbi_table, get_buffer(ret_drm_data, catch_once), catch_once);
				else
					put_buffer(dbi_table, get_buffer(ret_drm_data, catch_bit), catch_bit);
				catch_bit -= catch_once;
			}
			put_buffer(dbi_table, 0, dbi_bin_struct->basic_info.blank_bit);
		}
		line_stuff_bit = dbi_table->used_bit % 128;
		if (line_stuff_bit != 0)
			put_buffer(dbi_table, 0, (128-line_stuff_bit));
	}

	for (int i = 0; i < dbi_table->used_entry; i++)
		dbi_table->_buffer[i] = _reverse(dbi_table->_buffer[i]);

	if(!first_update) {
		first_update++;
		oddmr_data->dbi_data.dbi_table[0]=mtk_oddmr_load_buffer(
				&comp->mtk_crtc->base, dbi_table->used_entry, dbi_table->_buffer, false);
		oddmr_data->dbi_data.dbi_table[1]=mtk_oddmr_load_buffer(
				&comp->mtk_crtc->base, dbi_table->used_entry, dbi_table->_buffer, false);

		if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto final;
		}
		if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct_tb1)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto final;
		}
		if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto final;
		}
		if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct_tb1)) {
			DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
			goto final;
		}

		atomic_set(&oddmr_data->dbi_data.update_table_done, 1);
		atomic_set(&oddmr_data->dbi_data.cur_table_idx, 0);
		atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
		oddmr_data->dbi_data.table_size =  dbi_table->used_entry;

	} else {
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		if(atomic_read(&oddmr_data->dbi_data.cur_table_idx)) {
			if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				goto final;
			}
			if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				goto final;
			}
			memcpy(oddmr_data->dbi_data.dbi_table[0]->kvaddr, dbi_table->_buffer, dbi_table->used_entry);
			atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
		} else {
			if(mtk_oddmr_dbi_copy_static_cfg(&ret_drm_data->static_cfg, dbi_bin_struct_tb1)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				goto final;
			}
			if(mtk_oddmr_dbi_copy_chg_cfg(&ret_drm_data->fps_dbv_change_cfg, dbi_bin_struct_tb1)) {
				DDPMSG("%s:%d,copy_from_user fail\n", __func__, __LINE__);
				goto final;
			}
			memcpy(oddmr_data->dbi_data.dbi_table[1]->kvaddr, dbi_table->_buffer, dbi_table->used_entry);
			atomic_set(&oddmr_data->dbi_data.update_table_idx, 1);
		}
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
	}
final:
	free_buffer(dbi_table);
	return;
}


static int mtk_oddmr_dbi_init(struct mtk_ddp_comp *comp, struct mtk_drm_dbi_cfg_info *cfg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_panelid expect_panel_id = {0};
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data;
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data_tb1;
	void *data[30] = {0};
	unsigned int size;
	unsigned int index = 0;
	int i;

	ODDMRAPI_LOG("+\n");
	if (!oddmr_data->primary_data->dbi_support) {
		ODDMRFLOW_LOG("dbi is not support\n");
		return -1;
	}

	if (oddmr_data->primary_data->dbi_state != ODDMR_INVALID) {
		if(oddmr_data->primary_data->dbi_state >= ODDMR_INIT_DONE){
			DDPMSG("%s dbi already inited, state %d\n",__func__, oddmr_data->primary_data->dmr_state);
			return 0;
		}

		ODDMRFLOW_LOG("dbi can not init, state %d\n", oddmr_data->primary_data->dmr_state);
		return -1;
	}
	if (oddmr_data->dbi_enable > 0) {
		ODDMRFLOW_LOG("dbi can not init when running\n");
		return -1;
	}

	if(!cfg_info){
		ODDMRFLOW_LOG("dbi config info is NULL\n");
		return -1;
	}

	mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
	dbi_cfg_data =	&oddmr_data->primary_data->dbi_cfg_info;
	dbi_cfg_data_tb1 = &oddmr_data->primary_data->dbi_cfg_info_tb1;
	memcpy(dbi_cfg_data, cfg_info, sizeof(struct mtk_drm_dbi_cfg_info));

	if (dbi_cfg_data->basic_info.panel_id_len < 0 || dbi_cfg_data->basic_info.panel_id_len > 16) {
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		PC_ERR("panelid len %d invalid!\n", dbi_cfg_data->basic_info.panel_id_len);
		return -1;
	}
	/*match panel id */
	expect_panel_id.len = dbi_cfg_data->basic_info.panel_id_len;
	if(expect_panel_id.len)
		memcpy(expect_panel_id.data, dbi_cfg_data->basic_info.panel_id, expect_panel_id.len);
	if (!mtk_oddmr_match_panelid(&oddmr_data->primary_data->panelid, &expect_panel_id)) {
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		ODDMRFLOW_LOG("panelid does not match\n");
		return -1;
	}

	dbi_cfg_data_tb1->static_cfg.reg_num = dbi_cfg_data->static_cfg.reg_num;
	dbi_cfg_data_tb1->fps_dbv_node.FPS_num = dbi_cfg_data->fps_dbv_node.FPS_num;
	dbi_cfg_data_tb1->fps_dbv_node.DBV_num = dbi_cfg_data->fps_dbv_node.DBV_num;
	dbi_cfg_data_tb1->fps_dbv_node.DC_flag = dbi_cfg_data->fps_dbv_node.DC_flag;
	dbi_cfg_data_tb1->fps_dbv_change_cfg.reg_num = dbi_cfg_data->fps_dbv_change_cfg.reg_num;

	if(dbi_cfg_data->static_cfg.reg_num) {
		size = sizeof(uint32_t) * dbi_cfg_data->static_cfg.reg_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->static_cfg.reg_value, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->static_cfg.reg_value = (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->static_cfg.reg_offset, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->static_cfg.reg_offset = (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->static_cfg.reg_mask, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->static_cfg.reg_mask = (uint32_t *)data[index];
		index++;

		//for other table
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data_tb1->static_cfg.reg_offset= (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data_tb1->static_cfg.reg_value= (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data_tb1->static_cfg.reg_mask= (uint32_t *)data[index];
		index++;

	}



	if(dbi_cfg_data->fps_dbv_node.DBV_num){
		ODDMRLOW_LOG("dbi copy dbv node: %d", dbi_cfg_data->fps_dbv_node.DBV_num);
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.DBV_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_node.DBV_node, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_node.DBV_node = (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data_tb1->fps_dbv_node.DBV_node = (uint32_t *)data[index];
		index++;
		memcpy(dbi_cfg_data_tb1->fps_dbv_node.DBV_node,
			dbi_cfg_data->fps_dbv_node.DBV_node, size);
	}



	if(dbi_cfg_data->fps_dbv_node.FPS_num) {
		ODDMRLOW_LOG("dbi copy fps node: %d", dbi_cfg_data->fps_dbv_node.FPS_num);
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.FPS_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_node.FPS_node, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_node.FPS_node = (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data_tb1->fps_dbv_node.FPS_node = (uint32_t *)data[index];
		index++;
		memcpy(dbi_cfg_data_tb1->fps_dbv_node.FPS_node,
			dbi_cfg_data->fps_dbv_node.FPS_node, size);
	}

	if(dbi_cfg_data->fps_dbv_node.remap_reduce_offset_num) {
		ODDMRLOW_LOG("dmr copy remap node: %d", dbi_cfg_data->fps_dbv_node.remap_reduce_offset_num);
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.remap_reduce_offset_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_node.remap_reduce_offset_node, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_node.remap_reduce_offset_node = (uint32_t *)data[index];
		index++;
	}

	if(dbi_cfg_data->fps_dbv_node.remap_reduce_offset_num) {
		ODDMRLOW_LOG("dmr copy remap node: %d", dbi_cfg_data->fps_dbv_node.remap_reduce_offset_num);
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.remap_reduce_offset_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_node.remap_reduce_offset_value, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_node.remap_reduce_offset_value = (uint32_t *)data[index];
		index++;
	}

	if(dbi_cfg_data->fps_dbv_node.remap_dbv_gain_num) {
		ODDMRLOW_LOG("dmr copy remap dbv node: %d", dbi_cfg_data->fps_dbv_node.remap_dbv_gain_num);
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.remap_dbv_gain_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_node.remap_dbv_gain_node, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_node.remap_dbv_gain_node = (uint32_t *)data[index];
		index++;
	}

	if(dbi_cfg_data->fps_dbv_node.remap_dbv_gain_num) {
		ODDMRLOW_LOG("dmr copy remap dbv node: %d", dbi_cfg_data->fps_dbv_node.remap_dbv_gain_num);
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.remap_dbv_gain_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_node.remap_dbv_gain_value, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_node.remap_dbv_gain_value = (uint32_t *)data[index];
		index++;
	}



	if(dbi_cfg_data->fps_dbv_change_cfg.reg_num){
		ODDMRLOW_LOG("dmr copy fps_dbv_change_cfg: %d", dbi_cfg_data->fps_dbv_change_cfg.reg_num);
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_change_cfg.reg_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_change_cfg.reg_offset, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_change_cfg.reg_offset = (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->fps_dbv_change_cfg.reg_mask, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->fps_dbv_change_cfg.reg_mask = (uint32_t *)data[index];
		index++;

		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.FPS_num
			* dbi_cfg_data->fps_dbv_node.DBV_num * dbi_cfg_data->fps_dbv_change_cfg.reg_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}

		if (dbi_cfg_data->fps_dbv_node.DC_flag) {
			if (copy_from_user(data[index], dbi_cfg_data->fps_dbv_change_cfg.reg_DC_value, size)) {
				DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			dbi_cfg_data->fps_dbv_change_cfg.reg_DC_value= (uint32_t *)data[index];
		}else{
			if (copy_from_user(data[index], dbi_cfg_data->fps_dbv_change_cfg.reg_value, size)) {
				DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			dbi_cfg_data->fps_dbv_change_cfg.reg_value= (uint32_t *)data[index];
		}
		index++;

		//for other table
		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_change_cfg.reg_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data_tb1->fps_dbv_change_cfg.reg_offset = (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data_tb1->fps_dbv_change_cfg.reg_mask= (uint32_t *)data[index];
		index++;

		size = sizeof(uint32_t) * dbi_cfg_data->fps_dbv_node.FPS_num
			* dbi_cfg_data->fps_dbv_node.DBV_num * dbi_cfg_data->fps_dbv_change_cfg.reg_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (dbi_cfg_data->fps_dbv_node.DC_flag)
			dbi_cfg_data_tb1->fps_dbv_change_cfg.reg_DC_value= (uint32_t *)data[index];
		else
			dbi_cfg_data_tb1->fps_dbv_change_cfg.reg_value= (uint32_t *)data[index];
		index++;
	}

	if(dbi_cfg_data->dbv_node.DBV_num) {
		ODDMRLOW_LOG("dbi copy dbv node: %d", dbi_cfg_data->dbv_node.DBV_num);
		size = sizeof(uint32_t) * dbi_cfg_data->dbv_node.DBV_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->dbv_node.DBV_node, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->dbv_node.DBV_node= (uint32_t *)data[index];
		index++;
	}

	if(dbi_cfg_data->dbv_change_cfg.reg_num) {
		ODDMRLOW_LOG("dbi copy dbv chg cfg num: %d", dbi_cfg_data->dbv_change_cfg.reg_num);
		size = sizeof(uint32_t) * dbi_cfg_data->dbv_change_cfg.reg_num;
		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->dbv_change_cfg.reg_offset, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->dbv_change_cfg.reg_offset= (uint32_t *)data[index];
		index++;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->dbv_change_cfg.reg_mask, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->dbv_change_cfg.reg_mask= (uint32_t *)data[index];
		index++;

		size = sizeof(uint32_t) * dbi_cfg_data->dbv_change_cfg.reg_num * dbi_cfg_data->dbv_node.DBV_num;

		data[index] = vmalloc(size);
		if (!data[index]) {
			DDPINFO("%s:%d, param buffer alloc fail\n",
			__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data[index],
			dbi_cfg_data->dbv_change_cfg.reg_value, size)) {
			DDPINFO("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dbi_cfg_data->dbv_change_cfg.reg_value= (uint32_t *)data[index];
		index++;
	}

	oddmr_data->dbi_data.min_block_v = dbi_cfg_data->basic_info.partial_update_scale_factor_v;
	oddmr_data->dbi_data.min_block_h = dbi_cfg_data->basic_info.partial_update_scale_factor_h;
	oddmr_data->primary_data->dbi_state = ODDMR_INIT_DONE;
	mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
	return 0;

fail:
	for (i = 0; i<ARRAY_SIZE(data); i++) {
		if (data[i])
			vfree(data[i]);

	}
	mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
	return -EFAULT;


}

static int mtk_oddmr_dmr_binset_init (struct mtk_ddp_comp *comp,
	struct mtk_drm_oddmr_binset_cfg_info *binset_cfg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	void *data = NULL;
	uint64_t size;
	int i = 0, j = 0;
	struct mtk_drm_oddmr_binset_cfg_info *dmr_binset_cfg_info;

	ODDMRAPI_LOG("+\n");
	if (!oddmr_data->primary_data->dmr_support) {
		PC_ERR("dmr is not support\n");
		return -1;
	}
	if (oddmr_data->dmr_enable > 0) {
		PC_ERR("dmr can not init when running\n");
		return -1;
	}
	if(!binset_cfg_info){
		PC_ERR("dmr binset config info is NULL\n");
		return -1;
	}
	if(binset_cfg_info->binset_num > MAX_BINSET_NUM){
		PC_ERR("dmr binset num exceed %d\n", MAX_BINSET_NUM);
		return -1;
	}
	if(binset_cfg_info->binfile_num > MAX_BIN_NUM){
		PC_ERR("dmr bin file num exceed %d\n", MAX_BIN_NUM);
		return -1;
	}

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	dmr_binset_cfg_info = &oddmr_data->primary_data->dmr_binset_cfg_info;
	mtk_drm_oddmr_binset_cfg_info_rst(dmr_binset_cfg_info);
	dmr_binset_cfg_info->binfile_num = binset_cfg_info->binfile_num;
	dmr_binset_cfg_info->binset_num = binset_cfg_info->binset_num;
	dmr_binset_cfg_info->basic_info = binset_cfg_info->basic_info;
	dmr_binset_cfg_info->panel_id = binset_cfg_info->panel_id;
	mtk_drm_dmr_fps_dbv_node_cpy(&dmr_binset_cfg_info->remap_params, &binset_cfg_info->remap_params, true);

	ODDMRLOW_LOG("binfile_num %d\n", dmr_binset_cfg_info->binfile_num);
	ODDMRLOW_LOG("binset_num %d\n", dmr_binset_cfg_info->binset_num);

	for (i = 0; i < dmr_binset_cfg_info->binset_num; i++) {
		mtk_drm_oddmr_binset_info_cpy(&dmr_binset_cfg_info->binset_list[i],
			&binset_cfg_info->binset_list[i], false);

		// DBV internal copy
		size = sizeof(uint32_t) * dmr_binset_cfg_info->binset_list[i].dbv_interval_num;

		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			binset_cfg_info->binset_list[i].dbv_interval_node, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_binset_cfg_info->binset_list[i].dbv_interval_node = (uint32_t *)data;

		// DBV internal bin mapping copy
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			binset_cfg_info->binset_list[i].dbv_interval_bin_idx, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_binset_cfg_info->binset_list[i].dbv_interval_bin_idx = (uint32_t *)data;
		for (j = 0; j < dmr_binset_cfg_info->binset_list[i].dbv_interval_num; j++) {
			int idx = dmr_binset_cfg_info->binset_list[i].dbv_interval_bin_idx[j];

			if (idx < -1 || idx >=  MAX_BIN_NUM) {
				PC_ERR("%s:%d, found invalid idx [%d][%d] = %d\n", __func__, __LINE__, i, j, idx);
				goto fail;
			}
		}
	}

	if (dmr_binset_cfg_info->remap_params.remap_reduce_offset_num) {
		size = sizeof(uint32_t) * dmr_binset_cfg_info->remap_params.remap_reduce_offset_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			binset_cfg_info->remap_params.remap_reduce_offset_node, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_binset_cfg_info->remap_params.remap_reduce_offset_node = (uint32_t *)data;
	}

	if (dmr_binset_cfg_info->remap_params.remap_reduce_offset_num) {
		size = sizeof(uint32_t) * dmr_binset_cfg_info->remap_params.remap_reduce_offset_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			binset_cfg_info->remap_params.remap_reduce_offset_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_binset_cfg_info->remap_params.remap_reduce_offset_value = (uint32_t *)data;
	}

	if (dmr_binset_cfg_info->remap_params.remap_dbv_gain_num) {
		size = sizeof(uint32_t) * dmr_binset_cfg_info->remap_params.remap_dbv_gain_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			binset_cfg_info->remap_params.remap_dbv_gain_node, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_binset_cfg_info->remap_params.remap_dbv_gain_node = (uint32_t *)data;
	}

	if (dmr_binset_cfg_info->remap_params.remap_dbv_gain_num) {
		size = sizeof(uint32_t) * dmr_binset_cfg_info->remap_params.remap_dbv_gain_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			binset_cfg_info->remap_params.remap_dbv_gain_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dmr_binset_cfg_info->remap_params.remap_dbv_gain_value = (uint32_t *)data;
	}

	if (oddmr_data->primary_data->dmr_state == ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("re-init dmr, state %d\n", oddmr_data->primary_data->dmr_state);
		oddmr_data->primary_data->dmr_state = ODDMR_RELOAD;
	}
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
	return 0;

fail:
	mtk_drm_oddmr_binset_cfg_info_rst(dmr_binset_cfg_info);
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
	return -1;
}

static int mtk_oddmr_dmr_init(struct mtk_ddp_comp *comp, struct mtk_drm_dmr_cfg_info *cfg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data = NULL;
	int ret = 0;
	struct mtk_oddmr_panelid expect_panel_id = {0};
	struct mtk_drm_oddmr_binset_info *dmr_binset = NULL;
	unsigned int cur_dbv;
	int i = 0;
	static unsigned int load_bin_num;

	ODDMRAPI_LOG("+\n");
	oddmr_data = comp_to_oddmr(comp);
	if (!oddmr_data->primary_data->dmr_support) {
		PC_ERR("dmr is not support\n");
		return -1;
	}
	if (oddmr_data->dmr_enable > 0) {
		PC_ERR("dmr can not init when running\n");
		return -1;
	}
	if(!cfg_info){
		PC_ERR("dmr config info is NULL\n");
		return -1;
	}
	if (oddmr_data->primary_data->dmr_state == ODDMR_INIT_DONE) {
		PC_ERR("dmr bin can not load when dmr_state is ODDMR_INIT_DONE\n");
		return -1;
	}

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	if (oddmr_data->primary_data->dmr_state == ODDMR_RELOAD) {
		//need release previous bin info
		for (i = 0; i < MAX_BIN_NUM; i++) {
			dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[i];
			mtk_oddmr_dmr_free_table(i, comp, dmr_cfg_data);
			mtk_drm_dmr_cfg_info_rst(dmr_cfg_data);
		}
		load_bin_num = 0;
		oddmr_data->dmr_data.max_table_size = 0;
		oddmr_data->primary_data->dmr_state = ODDMR_INVALID;
		ODDMRFLOW_LOG("re-load dmr bin info, dmr_state:%d\n", oddmr_data->primary_data->dmr_state);
	}

	if (load_bin_num < oddmr_data->primary_data->dmr_binset_cfg_info.binfile_num) {
		load_bin_num ++;
		if (mtk_oddmr_get_dmr_cfg_data(comp, cfg_info, load_bin_num)) {
			load_bin_num --;
			mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
			PC_ERR("get dmr config data fail\n");
			return -1;
		}
		ODDMRFLOW_LOG("load_bin_num=%d\n", load_bin_num);
		if (load_bin_num < oddmr_data->primary_data->dmr_binset_cfg_info.binfile_num) {
			mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
			return 0;
		} else { // load_bin_num == oddmr_data->primary_data->dmr_binset_cfg_info.binfile_num
			mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
			goto __load_done;
		}
	} else {
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		PC_ERR("load too many dmr bin files\n");
		return -1;
	}

__load_done:
	/* keep track of chg anytime */
	mutex_lock(&oddmr_data->primary_data->timing_lock);
	cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	dmr_binset = &oddmr_data->primary_data->dmr_binset_cfg_info.binset_list[0];
	atomic_set(&oddmr_data->dmr_data.cur_binset_idx, 0);
	//dbv mode lookup
	for(i = 1; i < dmr_binset->dbv_interval_num; i++)
		if(cur_dbv <= dmr_binset->dbv_interval_node[i])
			break;
	i--;
	atomic_set(&oddmr_data->dmr_data.cur_bin_idx, dmr_binset->dbv_interval_bin_idx[i]);
	//DBV_internal_bin_mapping == -1: in current DBV, DMR should disable
	if (dmr_binset->dbv_interval_bin_idx[i] == -1) {
		oddmr_data->primary_data->dmr_state = ODDMR_INIT_DONE;
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		ODDMRFLOW_LOG("In current DBV range, DMR should off");
		return 0;
	}
	if (dmr_binset->dbv_interval_bin_idx[i] < 0 || dmr_binset->dbv_interval_bin_idx[i] >= MAX_BIN_NUM) {
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		PC_ERR("dbv_interval_bin_idx overflow!\n");
		return -1;
	}
	dmr_cfg_data =
		&oddmr_data->primary_data->dmr_multi_bin[dmr_binset->dbv_interval_bin_idx[i]];
	if (!dmr_cfg_data) {
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		PC_ERR("dmr_cfg_data null!\n");
		return -1;
	}

	if (dmr_cfg_data->basic_info.panel_id_len < 0 || dmr_cfg_data->basic_info.panel_id_len > 16) {
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		PC_ERR("panelid len %d invalid!\n", dmr_cfg_data->basic_info.panel_id_len);
		return -1;
	}
	expect_panel_id.len = dmr_cfg_data->basic_info.panel_id_len;
	memcpy(expect_panel_id.data, dmr_cfg_data->basic_info.panel_id, expect_panel_id.len);

	if (!mtk_oddmr_match_panelid(&oddmr_data->primary_data->panelid, &expect_panel_id)) {
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		PC_ERR("panelid does not match\n");
		return -1;
	}

	oddmr_data->primary_data->dmr_state = ODDMR_INIT_DONE;
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

	return ret;
}

static int mtk_oddmr_dmr_cus_own_data_init(struct mtk_ddp_comp *comp,
	struct cus_own_data *dmr_cus_own_data)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct cus_own_data *cus_data = &oddmr_data->primary_data->dmr_cus_own_data;
	unsigned int cus_data_state = atomic_read(&oddmr_data->dmr_data.cus_own_data_state);
	void *data;
	int ret = 0;

	ODDMRAPI_LOG("+\n");
	if (!oddmr_data->primary_data->dmr_support) {
		PC_ERR("dmr is not support\n");
		goto fail;
	}
	if(!dmr_cus_own_data) {
		PC_ERR("dmr customer own data is NULL\n");
		goto fail;
	}

	mutex_lock(&oddmr_data->primary_data->dmr_cus_own_data_lock);
	/* reload customer setting info */
	if(cus_data_state) {
		/* 1.set customer own data to invalid */
		atomic_set(&oddmr_data->dmr_data.cus_own_data_state, 0);
		/* 2.free old customer own data */
		cus_data->size = 0;
		if(cus_data->data) {
			vfree(cus_data->data);
			cus_data->data = NULL;
		}
	}

	/* customer own data internal copy */
	cus_data->size = dmr_cus_own_data->size;

	if(cus_data->size){
		data = vmalloc(cus_data->size);
		if (!data) {
			PC_ERR("%s %d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		ret = copy_from_user(data, dmr_cus_own_data->data, cus_data->size);
		if (ret) {
			PC_ERR("%s %d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		cus_data->data = data;
	}
	atomic_set(&oddmr_data->dmr_data.cus_own_data_state, 1);
	mutex_unlock(&oddmr_data->primary_data->dmr_cus_own_data_lock);
	return 0;

fail:
	if (cus_data->data) {
		vfree(cus_data->data);
		cus_data->data = NULL;
	}
	mutex_unlock(&oddmr_data->primary_data->dmr_cus_own_data_lock);

	return -1;
}

static int mtk_oddmr_dmr_cus_binset_init(struct mtk_ddp_comp *comp,
	struct mtk_drm_oddmr_binset_cfg_info *cus_binset_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_oddmr_binset_cfg_info *dmr_cus_binset_info =
		&oddmr_data->primary_data->dmr_cus_binset_info;
	struct mtk_drm_oddmr_binset_info *dst_binset, *src_binset;
	struct mtk_drm_dmr_fps_dbv_node *remap_params = NULL;
	void *data;
	unsigned int i, j;
	unsigned int binset_state;
	int ret = 0;
	uint64_t size;

	ODDMRAPI_LOG("+\n");
	if (!oddmr_data->primary_data->dmr_support) {
		PC_ERR("dmr is not support\n");
		return -1;
	}
	if(!cus_binset_info) {
		PC_ERR("dmr customer binset info is NULL\n");
		return -1;
	}
	if(cus_binset_info->binset_num > MAX_BINSET_NUM){
		PC_ERR("dmr cus binset num exceed %d\n", MAX_BINSET_NUM);
		return -1;
	}
	if(cus_binset_info->binfile_num > MAX_BIN_NUM){
		PC_ERR("dmr cus bin file num exceed %d\n", MAX_BIN_NUM);
		return -1;
	}

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	/* reload customer setting info */
	binset_state = atomic_read(&oddmr_data->dmr_data.cus_binset_state);
	if(binset_state) {
		/* 1.set customer bisnet config info to invalid */
		atomic_set(&oddmr_data->dmr_data.cus_binset_state, 0);
		/* 2.free old customer bisnet cofig info */
		mtk_drm_oddmr_binset_cfg_info_rst(dmr_cus_binset_info);
	}
	/* customer binset config internal copy */
	dmr_cus_binset_info->binfile_num = cus_binset_info->binfile_num;
	dmr_cus_binset_info->binset_num = cus_binset_info->binset_num;
	dmr_cus_binset_info->basic_info = cus_binset_info->basic_info;
	dmr_cus_binset_info->panel_id = cus_binset_info->panel_id;
	mtk_drm_dmr_fps_dbv_node_cpy(&dmr_cus_binset_info->remap_params, &cus_binset_info->remap_params, true);

	for (i = 0; i < dmr_cus_binset_info->binset_num; i++) {
		dst_binset = &dmr_cus_binset_info->binset_list[i];
		mtk_drm_oddmr_binset_info_cpy(dst_binset, &cus_binset_info->binset_list[i], false);
		// DBV internal copy
		size = sizeof(uint32_t) * dst_binset->dbv_interval_num;
		data =  vmalloc(size);
		if (!data) {
			PC_ERR("%s %d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data, cus_binset_info->binset_list[i].dbv_interval_node, size)) {
			PC_ERR("%s %d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dst_binset->dbv_interval_node = (uint32_t *)data;

		data =  vmalloc(size);
		if (!data) {
			PC_ERR("%s %d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data, cus_binset_info->binset_list[i].dbv_interval_bin_idx, size)) {
			PC_ERR("%s %d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		dst_binset->dbv_interval_bin_idx = (uint32_t *)data;
		for (j = 0; j < dst_binset->dbv_interval_num; j++) {
			int idx = dst_binset->dbv_interval_bin_idx[j];

			if (idx < -1 || idx >=  MAX_BINSET_NUM) {
				PC_ERR("%s:%d, found invalid idx [%d][%d] = %d\n", __func__, __LINE__, i, j, idx);
				goto fail;
			}
		}
	}
	/* customer binset remap internal copy */
	remap_params = &dmr_cus_binset_info->remap_params;
	if (remap_params->remap_dbv_gain_num > 0) {
		size = sizeof(uint32_t) * remap_params->remap_dbv_gain_num;
		data =  vmalloc(size);
		if (!data) {
			PC_ERR("%s %d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cus_binset_info->remap_params.remap_dbv_gain_node, size)) {
			PC_ERR("%s %d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		remap_params->remap_dbv_gain_node = (uint32_t *)data;

		data =  vmalloc(size);
		if (!data) {
			PC_ERR("%s %d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cus_binset_info->remap_params.remap_dbv_gain_value, size)) {
			PC_ERR("%s %d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		remap_params->remap_dbv_gain_value = (uint32_t *)data;
	}
	if (remap_params->remap_reduce_offset_num > 0) {
		size = sizeof(uint32_t) * remap_params->remap_reduce_offset_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s %d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cus_binset_info->remap_params.remap_reduce_offset_node, size)) {
			PC_ERR("%s %d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		remap_params->remap_reduce_offset_node = (uint32_t *)data;

		data =  vmalloc(size);
		if (!data) {
			PC_ERR("%s %d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data,
			cus_binset_info->remap_params.remap_reduce_offset_value, size)) {
			PC_ERR("%s %d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		remap_params->remap_reduce_offset_value = (uint32_t *)data;
	}
	atomic_set(&oddmr_data->dmr_data.cus_binset_state, 1);
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

	atomic_set(&oddmr_data->dmr_data.dmr_timing_state, 1);
	return 0;

fail:
	mtk_drm_oddmr_binset_cfg_info_rst(dmr_cus_binset_info);
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
	return -1;
}

static int mtk_oddmr_dmr_cus_setting_init(struct mtk_ddp_comp *comp,
	struct mtk_drm_cus_setting_info *cus_setting_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_cus_setting_info *dmr_cus_setting_info = NULL;
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node = NULL;
	struct mtk_drm_dmr_fps_dbv_change_cfg *fps_dbv_chg = NULL;
	void *data;
	unsigned int i;
	unsigned int setting_state;
	int ret = 0;
	uint64_t size;

	ODDMRAPI_LOG("+\n");
	oddmr_data = comp_to_oddmr(comp);
	if (!oddmr_data->primary_data->dmr_support) {
		PC_ERR("dmr is not support\n");
		return -1;
	}
	if(!cus_setting_info){
		PC_ERR("dmr customer setting info is NULL\n");
		return -1;
	}
	if (cus_setting_info->dbv_mode_num < 0 || cus_setting_info->dbv_mode_num > MAX_DBV_MODE_NUM) {
		PC_ERR("dmr customer dbv_mode_num %d invalid\n", cus_setting_info->dbv_mode_num);
		return -1;
	}
	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	dmr_cus_setting_info = &oddmr_data->primary_data->dmr_cus_setting_info;
	/* reload customer setting info */
	setting_state = atomic_read(&oddmr_data->dmr_data.cus_setting_state);
	if(setting_state) {
		/* 1.set customer bisnet config info to invalid */
		atomic_set(&oddmr_data->dmr_data.cus_setting_state, 0);
		/* 2.free old customer bisnet cofig info */
		mtk_drm_cus_setting_info_rst(dmr_cus_setting_info);
	}
	/* customer fps_dbv setting internal copy */
	dmr_cus_setting_info->dbv_mode_num = cus_setting_info->dbv_mode_num;
	dmr_cus_setting_info->default_dbv_mode = cus_setting_info->default_dbv_mode;
	for (i = 0; i < MAX_DBV_MODE_NUM; i++) {
		mtk_drm_dmr_fps_dbv_node_cpy(dmr_cus_setting_info->fps_dbv_node,
			cus_setting_info->fps_dbv_node, true);
		mtk_drm_dmr_fps_dbv_change_cfg_cpy(dmr_cus_setting_info->fps_dbv_change_cfg,
			cus_setting_info->fps_dbv_change_cfg, true);
	}

	for (i = 0; i < dmr_cus_setting_info->dbv_mode_num; i++) {
		/* customer fps_dbv node copy */
		fps_dbv_node = &dmr_cus_setting_info->fps_dbv_node[i];
		/* DBV node copy */
		if(fps_dbv_node->DBV_num) {
			size = sizeof(uint32_t) * fps_dbv_node->DBV_num;
			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data, cus_setting_info->fps_dbv_node[i].DBV_node, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_node->DBV_node = (uint32_t *)data;
		}
		/* FPS node copy */
		if (fps_dbv_node->FPS_num) {
			size = sizeof(uint32_t) * fps_dbv_node->FPS_num;
			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data, cus_setting_info->fps_dbv_node[i].FPS_node, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_node->FPS_node = (uint32_t *)data;
		}
		/* remap reduce offset copy */
		if (fps_dbv_node->remap_reduce_offset_num) {
			size = sizeof(uint32_t) * fps_dbv_node->remap_reduce_offset_num;
			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data,
				cus_setting_info->fps_dbv_node[i].remap_reduce_offset_node, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_node->remap_reduce_offset_node = (uint32_t *)data;

			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data,
				cus_setting_info->fps_dbv_node[i].remap_reduce_offset_value, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_node->remap_reduce_offset_value = (uint32_t *)data;
		}
		/* remap dbv gain copy */
		if (fps_dbv_node->remap_dbv_gain_num) {
			size = sizeof(uint32_t) * fps_dbv_node->remap_dbv_gain_num;
			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data, cus_setting_info->fps_dbv_node[i].remap_dbv_gain_node, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_node->remap_dbv_gain_node = (uint32_t *)data;

			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data, cus_setting_info->fps_dbv_node[i].remap_dbv_gain_value, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_node->remap_dbv_gain_value = (uint32_t *)data;
		}
		/* dbv_fps change config copy */
		fps_dbv_chg = &dmr_cus_setting_info->fps_dbv_change_cfg[i];
		if(fps_dbv_chg->reg_num) {
			size = sizeof(uint32_t) * fps_dbv_chg->reg_num;
			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data, cus_setting_info->fps_dbv_change_cfg[i].reg_offset, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_chg->reg_offset = (uint32_t *)data;

			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data, cus_setting_info->fps_dbv_change_cfg[i].reg_mask, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_chg->reg_mask = (uint32_t *)data;

			size = sizeof(uint32_t) * fps_dbv_chg->reg_num *
				fps_dbv_node->DBV_num * fps_dbv_node->FPS_num;
			data = vmalloc(size);
			if (!data) {
				PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				goto fail;
			}
			if (copy_from_user(data, cus_setting_info->fps_dbv_change_cfg[i].reg_value, size)) {
				PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
				goto fail;
			}
			fps_dbv_chg->reg_value = (uint32_t *)data;
		}
	}
	atomic_set(&oddmr_data->dmr_data.cus_setting_state, 1);
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

	atomic_set(&oddmr_data->dmr_data.dmr_timing_state, 1);

	mutex_lock(&oddmr_data->primary_data->timing_lock);
	oddmr_data->primary_data->current_timing.dbv_mode = dmr_cus_setting_info->default_dbv_mode;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);

	return 0;

fail:
	mtk_drm_cus_setting_info_rst(dmr_cus_setting_info);
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

	return -1;
}

static int mtk_oddmr_reg_tuning_init(struct mtk_ddp_comp *comp, struct mtk_drm_oddmr_reg_tuning *tuning_reg_info)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	void *data = NULL;
	int size;
	struct mtk_drm_oddmr_reg_tuning *reg_tuning_info = &oddmr_data->primary_data->oddmr_reg_tuning_info;
	unsigned int i = 0;
	int reg_num;

	ODDMRAPI_LOG("+\n");
	if (!oddmr_data->primary_data->dmr_support) {
		PC_ERR("dmr is not support\n");
		return -1;
	}
	if(!tuning_reg_info){
		PC_ERR("dmr gain config info is NULL\n");
		return -1;
	}

	mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
	mtk_drm_oddmr_reg_tuning_cpy(reg_tuning_info, tuning_reg_info, true);
	reg_num = MIN(reg_tuning_info->reg_num, PQ_MAX_REG_NUM);
	ODDMRLOW_LOG("tuning register num %d\n", reg_tuning_info->reg_num);

	if(reg_num) {
		size = sizeof(uint32_t) * tuning_reg_info->reg_num;
		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data, tuning_reg_info->reg_value, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		reg_tuning_info->reg_value = (uint32_t *)data;

		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data, tuning_reg_info->reg_addr, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		reg_tuning_info->reg_addr = (uint32_t *)data;

		data = vmalloc(size);
		if (!data) {
			PC_ERR("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
			goto fail;
		}
		if (copy_from_user(data, tuning_reg_info->reg_mask, size)) {
			PC_ERR("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			goto fail;
		}
		reg_tuning_info->reg_mask = (uint32_t *)data;
	}
	atomic_set(&oddmr_data->dmr_data.reg_tuning_chg, 1);
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);

	return 0;

fail:
	mtk_drm_oddmr_reg_tuning_free(reg_tuning_info);
	memset(reg_tuning_info, 0, sizeof(struct mtk_drm_oddmr_reg_tuning));
	mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
	return -1;
}

uint32_t mtk_oddmr_dbi_alpha_blend_int(uint32_t list_num, uint32_t *list_node,
	uint32_t *list_value, uint32_t target, uint32_t frac_bit)
{
	unsigned long num;
	int reduce_ind;
	unsigned long alpha;

	if (list_node == NULL || list_value == NULL || list_num == 0)
		return 0;

	if (target <= list_node[0])
		return (list_value[0] << frac_bit);

	if (target >= list_node[list_num - 1])
		return (list_value[list_num - 1] << frac_bit);

	for (reduce_ind = 1; reduce_ind < list_num; reduce_ind++) {
		if (target == list_node[reduce_ind])
			return (list_value[reduce_ind] << frac_bit);
		if (target < list_node[reduce_ind]) {
			num = list_node[reduce_ind] - list_node[reduce_ind - 1];
			alpha = target - list_node[reduce_ind - 1];
			if (num == 0)
				return (list_value[reduce_ind - 1] << frac_bit);
			else
				return (((unsigned long)(list_value[reduce_ind - 1] * (num - alpha))
					+ (unsigned long)(list_value[reduce_ind] * (alpha))) << frac_bit) / num;
		}
	}

	return 0;
}

void mtk_oddmr_scp_status(bool enable)
{
	if(enable)
		atomic_set(&g_oddmr_priv->dbi_data.enter_scp, 1);
}
EXPORT_SYMBOL(mtk_oddmr_scp_status);

#define OFST_M0_AP 0x69C
#define OFST_M1_SCP  0x6A0
#define KEY_HOLE    BIT(7)

static int mtk_dbi_scp_set_semaphore_noirq(struct mtk_ddp_comp *comp, bool lock)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int i = 0;
	bool key = false;
	void __iomem *SPM_SEMA_AP = NULL, *SPM_SEMA_SCP = NULL;

	if (!oddmr_data->dbi_data.spm_base) {
		PC_ERR("%s, invalid spm base\n", __func__);
		goto fail;
	}

	SPM_SEMA_AP = oddmr_data->dbi_data.spm_base + OFST_M0_AP;
	SPM_SEMA_SCP = oddmr_data->dbi_data.spm_base + OFST_M1_SCP;

	key = ((readl(SPM_SEMA_AP) & KEY_HOLE) == KEY_HOLE);
	if (key == lock) {
		DDPINFO("%s, skip %s sema\n", __func__, lock ? "get" : "put");
		//mutex_unlock(&spm_sema_lock);
		return 1;
	}

	if (lock) {
		do {
			/* 40ms timeout */
			if (unlikely(++i > 4000))
				goto fail;
			writel(KEY_HOLE, SPM_SEMA_AP);
			udelay(10);
		} while ((readl(SPM_SEMA_AP) & KEY_HOLE) != KEY_HOLE);
	} else {
		writel(KEY_HOLE, SPM_SEMA_AP);
		do {
			/* 10ms timeout */
			if (unlikely(++i > 1000))
				goto fail;
			udelay(10);
		} while (readl(SPM_SEMA_AP) & KEY_HOLE);
	}

	return 1;
fail:
	PC_ERR("%s: %s sema:0x%lx/0x%lx fail(0x%x), retry:%d\n",
		__func__, lock ? "get" : "put", (unsigned long)SPM_SEMA_AP,
		(unsigned long)SPM_SEMA_SCP, readl(SPM_SEMA_AP), i);
	return 0;
}

unsigned int mtk_oddmr_get_dbi_hw_enable(struct mtk_drm_crtc *mtk_crtc)
{
	struct mtk_ddp_comp *comp = mtk_ddp_comp_sel_in_cur_crtc_path(mtk_crtc, MTK_DISP_ODDMR, 0);
	struct mtk_disp_oddmr *oddmr_data;

	if (!comp)
		return 0;
	oddmr_data = comp_to_oddmr(comp);
	return oddmr_data->dbi_enable;
}

unsigned int mtk_oddmr_get_dbi_init_done(struct mtk_drm_crtc *mtk_crtc)
{
	struct mtk_ddp_comp *comp = mtk_ddp_comp_sel_in_cur_crtc_path(mtk_crtc, MTK_DISP_ODDMR, 0);
	struct mtk_disp_oddmr *oddmr_data;

	if (!comp)
		return 0;
	oddmr_data = comp_to_oddmr(comp);
	return oddmr_data->primary_data->dbi_state >= ODDMR_INIT_DONE;
}

#define share_lifecycle_offset (0x10000)
bool mtk_drm_dbi_backup(struct drm_crtc *crtc, void *get_phys, void *get_virt,
	void *get_size, unsigned int curr_bl, unsigned int curr_fps, int curr_temp)
{
#if !IS_ENABLED(CONFIG_MTK_TINYSYS_SCP_CM4_SUPPORT)
	struct iommu_domain *domain;
	int ret = 0;
	get_mem_phys = get_phys;
	get_mem_virt = get_virt;
	get_mem_size = get_size;
	struct mtk_drm_dbi_share_info *share_mem;
	unsigned int width, height, scale_factor_h, scale_factor_v;
	unsigned int *tmp_addr;
	unsigned int *tmp_addr1;
	unsigned int i;
	static bool mem_maped;
	static bool mem_init;
	unsigned int map_size;
	struct mtk_drm_crtc *mtk_crtc = NULL;
	struct mtk_ddp_comp *comp = NULL;
	struct mtk_disp_oddmr *oddmr_data;
	struct dbi_count_block_info block;
	unsigned int size;

	if (!crtc)
		return false;
	mtk_crtc = to_mtk_crtc(crtc);
	comp = mtk_ddp_comp_sel_in_cur_crtc_path(mtk_crtc, MTK_DISP_ODDMR, 0);
	if (!comp)
		return false;
	oddmr_data = comp_to_oddmr(comp);
	if(!oddmr_data->dbi_data.support_scp)
		return false;

	DDPMSG("%s: dbi-scp :%d scp rsv mem 0x%llx(0x%llx), size 0x%llx\n", __func__, SCP_DBI_MEM_ID,
	get_mem_virt(SCP_DBI_MEM_ID), get_mem_phys(SCP_DBI_MEM_ID),
	get_mem_size(SCP_DBI_MEM_ID));

	if(!mem_init) {
		memset((void *)get_mem_virt(SCP_DBI_MEM_ID), 0, get_mem_size(SCP_DBI_MEM_ID));
		mem_init = true;
	}

	share_mem = (struct mtk_drm_dbi_share_info *)get_mem_virt(SCP_DBI_MEM_ID);
	share_mem->unused_offset = sizeof(struct mtk_drm_dbi_share_info);

	if (oddmr_data->primary_data->dbi_state >= ODDMR_INIT_DONE)
		share_mem->dbi_init_done = 1;
	else
		share_mem->dbi_init_done = 0;
	share_mem->dbi_hw_enable = oddmr_data->dbi_enable;

	share_mem->counting_info.size = 0;

	share_mem->curr_fps = curr_fps;
	share_mem->curr_bl = curr_bl;
	share_mem->curr_temp = curr_temp;
	share_mem->spr_format = mtk_spr_get_format(mtk_crtc);

	DDPMSG("dbi-scp %d/%d\n", share_mem->dbi_init_done, share_mem->dbi_hw_enable);

	if (share_mem->dbi_init_done) {
		width = oddmr_data->primary_data->dbi_cfg_info.basic_info.panel_width;
		height = oddmr_data->primary_data->dbi_cfg_info.basic_info.panel_height;
		scale_factor_h = oddmr_data->dbi_data.min_block_h;
		scale_factor_v = oddmr_data->dbi_data.min_block_v;
		DDPMSG("dbi-scp min block %d/%d\n", scale_factor_h, scale_factor_v);

		share_mem->panel_width = width;
		share_mem->panel_height = height;

		share_mem->lifecycle_addr_pa= share_lifecycle_offset + get_mem_phys(SCP_DBI_MEM_ID);
		share_mem->lifecycle_addr_va= share_lifecycle_offset + get_mem_virt(SCP_DBI_MEM_ID);

		if(oddmr_data->data->dbi_version == MTK_DBI_V3) {
			block = mtk_dbi_count_get_block_info(scale_factor_h, scale_factor_v);
			size = width * height * block.channel* sizeof(unsigned int) / block.block_h / block.block_v;
			oddmr_data->dbi_data.scp_lifecycle_size = size;
			share_mem->pic_addr_pa[0] = share_mem->lifecycle_addr_pa + (size + 4095)/4096*4096;
			share_mem->pic_addr_va[0] = share_mem->lifecycle_addr_va + (size + 4095)/4096*4096;
		} else {
			oddmr_data->dbi_data.scp_lifecycle_size
				= width*height*4*3/scale_factor_h/scale_factor_v;

			share_mem->pic_addr_pa[0] = share_mem->lifecycle_addr_pa +
				(width*height*4*3/scale_factor_h/scale_factor_v + 4095)/4096*4096;
			share_mem->pic_addr_va[0] = share_mem->lifecycle_addr_va +
				(width*height*4*3/scale_factor_h/scale_factor_v + 4095)/4096*4096;
		}

		share_mem->pic_addr_pa[1] = share_mem->pic_addr_pa[0] + (width*height*3 + 4095)/4096*4096;
		share_mem->pic_addr_va[1] = share_mem->pic_addr_va[0] + (width*height*3 + 4095)/4096*4096;

		share_mem->table_addr_pa = share_mem->pic_addr_pa[1] + (width*height*3 + 4095)/4096*4096;
		share_mem->table_addr_va = share_mem->pic_addr_va[1] + (width*height*3 + 4095)/4096*4096;

		map_size = get_mem_size(SCP_DBI_MEM_ID) - (share_mem->pic_addr_pa[0] - get_mem_phys(SCP_DBI_MEM_ID));
		if (!mem_maped) {
			domain = iommu_get_domain_for_dev(mtk_smmu_get_shared_device(comp->dev));
			if (domain == NULL) {
				PC_ERR("%s, iommu_get_domain fail\n", __func__);
				return false;
			}
			ret = iommu_map(domain, share_mem->pic_addr_pa[0], share_mem->pic_addr_pa[0],
				ROUNDUP(map_size, PAGE_SIZE),
				IOMMU_READ | IOMMU_WRITE, GFP_KERNEL);
			if (ret < 0) {
				PC_ERR("%s, iommu_map fail\n", __func__);
				return false;
			}
			mem_maped = true;
		}
	}

	share_mem->backup.backup_offset_pa = get_mem_phys(SCP_DBI_MEM_ID) + share_mem->unused_offset;
	tmp_addr = (unsigned int *)(get_mem_virt(SCP_DBI_MEM_ID) + share_mem->unused_offset);

	if (share_mem->dbi_hw_enable) {
		//top
		i = 0;
		*(tmp_addr+(i++)) = DISP_ODDMR_TOP_CTR_1;
		*(tmp_addr+(i++)) = DISP_ODDMR_TOP_CTR_2;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_TOP_CTR_3;

		*(tmp_addr+(i++)) = DISP_ODDMR_TOP_SHADOW_CTRL;
		*(tmp_addr+(i++)) = DISP_ODDMR_DMR_SHADOW_CTRL;
		*(tmp_addr+(i++)) = DISP_ODDMR_MURA_SHADOW_CTRL;
		*(tmp_addr+(i++)) = DISP_ODDMR_DBI_SHADOW_CTRL;
		*(tmp_addr+(i++)) = DISP_ODDMR_REG_DMR_REAL_FRAME_WIDTH;
		*(tmp_addr+(i++)) = DISP_ODDMR_REG_DMR_FRAME_WIDTH;
		*(tmp_addr+(i++)) = MT6993_DISP_ODDMR_DDREN_CTRL_DBI;
		*(tmp_addr+(i++)) = DISP_ODDMR_TOP_DBI_BYPASS;
		// *(tmp_addr+(i++)) = MT6993_DISP_ODDMR_REG_DMR_Y_INI;
		// *(tmp_addr+(i++)) = MT6991_DISP_ODDMR_UDMA_DBI_CTRL70;
		// *(tmp_addr+(i++)) = MT6991_DISP_ODDMR_UDMA_DBI_CTRL88;
		// *(tmp_addr+(i++)) = MT6991_DISP_ODDMR_UDMA_DBI_CTRL30;

		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_OUTP_EN;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_FRAME_WIDTH;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_HSIZE;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE;
		*(tmp_addr+(i++)) = DISP_ODDMR_TOP_CLK_GATING;
		//smi
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_SMI_SB_FLG_DBI;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_UDMA_DBI_CTRL21;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_UDMA_DBI_CTRL22;

		//static change config
		if (atomic_read(&oddmr_data->dbi_data.cur_table_idx)){
			memcpy(tmp_addr+i,
				oddmr_data->primary_data->dbi_cfg_info_tb1.static_cfg.reg_offset,
				oddmr_data->primary_data->dbi_cfg_info_tb1.static_cfg.reg_num * sizeof(unsigned int));
				i += oddmr_data->primary_data->dbi_cfg_info_tb1.static_cfg.reg_num;

			memcpy(tmp_addr+i,
				oddmr_data->primary_data->dbi_cfg_info_tb1.fps_dbv_change_cfg.reg_offset,
				oddmr_data->primary_data->dbi_cfg_info_tb1.fps_dbv_change_cfg.reg_num * sizeof(unsigned int));
				i += oddmr_data->primary_data->dbi_cfg_info_tb1.fps_dbv_change_cfg.reg_num;
		} else {
			memcpy(tmp_addr+i,
				oddmr_data->primary_data->dbi_cfg_info.static_cfg.reg_offset,
				oddmr_data->primary_data->dbi_cfg_info.static_cfg.reg_num * sizeof(unsigned int));
				i += oddmr_data->primary_data->dbi_cfg_info.static_cfg.reg_num;
			memcpy(tmp_addr+i,
				oddmr_data->primary_data->dbi_cfg_info.fps_dbv_change_cfg.reg_offset,
				oddmr_data->primary_data->dbi_cfg_info.fps_dbv_change_cfg.reg_num * sizeof(unsigned int));
				i += oddmr_data->primary_data->dbi_cfg_info.fps_dbv_change_cfg.reg_num;
		}

		//partiful update

		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DMR_REAL_FRAME_WIDTH;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DMR_FRAME_WIDTH;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DBI_SCL_HSIZE;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_HSIZE;

		//dbv table
		memcpy(tmp_addr+i,
			oddmr_data->primary_data->dbi_cfg_info.dbv_change_cfg.reg_offset,
			oddmr_data->primary_data->dbi_cfg_info.dbv_change_cfg.reg_num * sizeof(unsigned int));
		i += oddmr_data->primary_data->dbi_cfg_info.dbv_change_cfg.reg_num;

		//dbi enable
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DMR_EN;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DMR_UDMA_EN;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_TOP_DMR_BYPASS;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DBI_DDREN_CTRL;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_UDMA_DBI_CTRL30;

		//oddmr spr
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_COMP_EN;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_0;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_1;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_2;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_3;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_4;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_5;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_2X2;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_PANEL_WIDTH;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_X_INIT;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_REMAP_EN;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_SPR_REMAP_GAIN;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_SPR_SHADOW_CTRL;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DBI_UDMA_BASE_ADDR_0;
		*(tmp_addr+(i++)) = MT6991_DISP_ODDMR_REG_DBI_UDMA_BASE_ADDR_1;

		share_mem->backup.size = i;
		share_mem->unused_offset += i * sizeof(unsigned int);

		share_mem->backup.backup_value_pa = get_mem_phys(SCP_DBI_MEM_ID) + share_mem->unused_offset;
		tmp_addr1 = (unsigned int *)(get_mem_virt(SCP_DBI_MEM_ID) + share_mem->unused_offset);

		share_mem->unused_offset += share_mem->backup.size * sizeof(unsigned int);
		for(i = 0;i < share_mem->backup.size; i++) {
			*(tmp_addr1 + i) = mtk_oddmr_read(comp,*(tmp_addr + i));
			DDPMSG("dbi-scp rg backup 0x%x/0x%x\n", *(tmp_addr + i), *(tmp_addr1 + i));
		}
	}

	if (oddmr_data->dbi_data.load_scp_param) {
		DDPMSG("dbi-scp scp_param_size %d\n", oddmr_data->dbi_data.scp_param_size);
		share_mem->counting_info.size = oddmr_data->dbi_data.scp_param_size;
		share_mem->counting_info.addr_pa = get_mem_phys(SCP_DBI_MEM_ID) + share_mem->unused_offset;
		tmp_addr1 = (unsigned int *)(get_mem_virt(SCP_DBI_MEM_ID) + share_mem->unused_offset);
		memcpy(tmp_addr1,
			oddmr_data->dbi_data.scp_param,
			oddmr_data->dbi_data.scp_param_size);
		share_mem->unused_offset += oddmr_data->dbi_data.scp_param_size;
	}

	DDPMSG("dbi-scp hw enable %d/%d\n", share_mem->dbi_hw_enable, share_mem->unused_offset);
	return true;
#else
	return false;
#endif
}
EXPORT_SYMBOL(mtk_drm_dbi_backup);

bool mtk_drm_dmr_backup(struct drm_crtc *crtc, void *get_phys,
	void *get_virt, unsigned int offset, unsigned int size)
{
	struct mtk_drm_crtc *mtk_crtc = NULL;
	struct mtk_ddp_comp *comp = NULL;
	struct mtk_disp_oddmr *oddmr_data = NULL;
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data = NULL;
	struct mtk_drm_dmr_share_info *share_info;
	unsigned int *reg_addr_backup;
	unsigned int *reg_value_backup;
	unsigned int i, j;
	int cur_bin_idx = 0;
	char *dmr_scp_sh_mem = NULL;

	if (!crtc)
		return false;

	mtk_crtc = to_mtk_crtc(crtc);
	comp = mtk_ddp_comp_sel_in_cur_crtc_path(mtk_crtc, MTK_DISP_ODDMR, 0);
	if (!comp)
		return false;

	oddmr_data = comp_to_oddmr(comp);
	if (oddmr_data->primary_data->dmr_support == false ||
		oddmr_data->primary_data->dmr_state != ODDMR_INIT_DONE)
		return false;

	//memory init
	get_mem_phys = get_phys;
	get_mem_virt = get_virt;
	ODDMRFLOW_LOG("%s: scp-aod:%d scp rsv mem:0x%llx(0x%llx)\n", __func__,
		SCP_AOD_MEM_ID, get_mem_virt(SCP_AOD_MEM_ID), get_mem_phys(SCP_AOD_MEM_ID));
	dmr_scp_sh_mem = (char *)get_mem_virt(SCP_AOD_MEM_ID) + offset;
	if (!dmr_scp_sh_mem)
		return false;
	memset((void *)dmr_scp_sh_mem, 0, size);

	ODDMRFLOW_LOG("%s: scp dmr rsv mem:0x%s offset:0x%x size:0x%x\n",
		__func__, dmr_scp_sh_mem, offset, size);
	share_info = (struct mtk_drm_dmr_share_info *)dmr_scp_sh_mem;
	share_info->backup_reg_pa = get_mem_phys(SCP_AOD_MEM_ID) + offset +
		sizeof(struct mtk_drm_dmr_share_info);
	share_info->dmr_hw_enable = oddmr_data->dmr_enable;
	share_info->panel_width =
		oddmr_data->primary_data->dmr_multi_bin[0].basic_info.panel_width;
	share_info->panel_height =
		oddmr_data->primary_data->dmr_multi_bin[0].basic_info.panel_height;
	reg_addr_backup = (unsigned int *)(dmr_scp_sh_mem + sizeof(struct mtk_drm_dmr_share_info));
	if (oddmr_data->dmr_enable) {
		cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
		i = 0;
		*(reg_addr_backup+(i++)) = DISP_ODDMR_TOP_CLK_GATING;
		/* spr2rgb */
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_DMR_SPR_MODE;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_2X2;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_0;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_1;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_2;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_3;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_4;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_MASK_5;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_X_INIT;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_PANEL_WIDTH;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_REMAP_GAIN;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_SPR_REMAP_EN;
		*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS;
		if (cur_bin_idx != -1) {
			/* static cfg */
			dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
			memcpy(reg_addr_backup + i,
				dmr_cfg_data->static_cfg.reg_offset,
				dmr_cfg_data->static_cfg.reg_num * sizeof(unsigned int));
				i += dmr_cfg_data->static_cfg.reg_num;
			/* dmr table which is decided by current fps and dbv */
			memcpy(reg_addr_backup + i,
				dmr_cfg_data->fps_dbv_change_cfg.reg_offset,
				dmr_cfg_data->fps_dbv_change_cfg.reg_num * sizeof(unsigned int));
			i += dmr_cfg_data->fps_dbv_change_cfg.reg_num;
			/* dmr table address */
			*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_0;
			*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_DMR_UDMA_BASE_ADDR_1;
			/* DMR control */
			*(reg_addr_backup+(i++)) = MT6993_DISP_ODDMR_REG_DMR_CLK_EN;
			*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_UDMA_DMR_CTRL70;
			*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_DMR_EN;
			*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_REG_DMR_UDMA_EN;
			*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_TOP_DMR_BYPASS;
			*(reg_addr_backup+(i++)) = DISP_ODDMR_DDREN_CTRL_DMR;
			*(reg_addr_backup+(i++)) = MT6991_DISP_ODDMR_UDMA_DMR_CTRL30;
			*(reg_addr_backup+(i++)) = MT6993_DISP_ODDMR_SMI_SB_FLG_DMR;
		}
		share_info->backup_reg_size = i;
		share_info->backup_value_pa = share_info->backup_reg_pa + i * sizeof(unsigned int);
		reg_value_backup = reg_addr_backup + i;
		/* copy dmr reg value to scp */
		for(j = 0; j < i; j++)
			*(reg_value_backup + j) = mtk_oddmr_read(comp, *(reg_addr_backup + j));
	}

	return true;
}
EXPORT_SYMBOL(mtk_drm_dmr_backup);

static void mtk_oddmr_dmr_change_remap_gain(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_cus_setting_info *cus_setting_info = NULL;
	struct mtk_drm_dmr_fps_dbv_node *fps_dbv_node = NULL;
	uint32_t frac_bit = 0;
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data = NULL;
	struct mtk_drm_dmr_fps_dbv_node *remap_params = NULL;
	unsigned int setting_state, binset_state;
	uint32_t cur_dbv;
	uint32_t cur_dbv_mode;
	uint32_t cur_offset = 0;
	uint32_t cur_dbv_gain = 0;
	uint32_t remap_gain_target_code = 0;
	uint32_t dmr_remap_gain;
	uint32_t dbi_remap_gain;
	int dbi_remap_enable;
	int cur_bin_idx;

	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("%s: dmr loading not finished\n", __func__);
		return;
	}

	mutex_lock(&oddmr_data->primary_data->timing_lock);
	cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
	cur_dbv_mode = oddmr_data->primary_data->current_timing.dbv_mode;
	mutex_unlock(&oddmr_data->primary_data->timing_lock);
	setting_state = atomic_read(&oddmr_data->dmr_data.cus_setting_state);
	binset_state = atomic_read(&oddmr_data->dmr_data.cus_binset_state);
	cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
	if (cur_bin_idx == -1) {
		if (binset_state == 1)
			remap_params = &oddmr_data->primary_data->dmr_cus_binset_info.remap_params;
		else
			remap_params = &oddmr_data->primary_data->dmr_binset_cfg_info.remap_params;
		if (remap_params->remap_reduce_offset_num == 0)
			cur_offset = 0;
		else
			cur_offset = remap_params->remap_reduce_offset_value[0];
		if (remap_params->remap_dbv_gain_num == 0)
			cur_dbv_gain = 0;
		else
			cur_dbv_gain = mtk_oddmr_dbi_alpha_blend_int(remap_params->remap_dbv_gain_num,
				remap_params->remap_dbv_gain_node,
				remap_params->remap_dbv_gain_value, cur_dbv, frac_bit);
		remap_gain_target_code = (remap_params->remap_gain_target_code << 16);
	} else {
		dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
		cus_setting_info = &oddmr_data->primary_data->dmr_cus_setting_info;
		if (setting_state == 1) {
			if(cur_dbv_mode >= cus_setting_info->dbv_mode_num) {
				ODDMRFLOW_LOG("dbv_mode out of range\n");
				return;
			}
			fps_dbv_node = &cus_setting_info->fps_dbv_node[cur_dbv_mode];
		} else {
			fps_dbv_node = &dmr_cfg_data->fps_dbv_node;
		}
		if (fps_dbv_node->remap_reduce_offset_num == 0)
			cur_offset = 0;
		else
			cur_offset = fps_dbv_node->remap_reduce_offset_value[0];
		if (fps_dbv_node->remap_dbv_gain_num == 0)
			cur_dbv_gain = 0;
		else
			cur_dbv_gain = mtk_oddmr_dbi_alpha_blend_int(fps_dbv_node->remap_dbv_gain_num,
				fps_dbv_node->remap_dbv_gain_node, fps_dbv_node->remap_dbv_gain_value,
				cur_dbv, frac_bit);
		remap_gain_target_code = (fps_dbv_node->remap_gain_target_code<<16);
	}
	dmr_remap_gain = MIN((((remap_gain_target_code - (cur_offset * cur_dbv_gain)) / 255) >> 4), 4096);
	ODDMRLOW_LOG("dmr remap gain:0x%x, remap offset:0x%x, remap DBV gain:0x%x remap target code:0x%x\n",
		dmr_remap_gain, cur_offset, cur_dbv_gain, remap_gain_target_code);
	atomic_set(&oddmr_data->dmr_data.remap_gain, dmr_remap_gain);
	dbi_remap_enable = atomic_read(&oddmr_data->dbi_data.remap_enable);
	if (dbi_remap_enable == 1)
		dbi_remap_gain = atomic_read(&oddmr_data->dbi_data.remap_gain);
	else
		dbi_remap_gain = 4096;
	mtk_oddmr_write(comp, ((dmr_remap_gain * dbi_remap_gain) / 4096),
		MT6991_DISP_ODDMR_REG_SPR_REMAP_GAIN, pkg);
}

static void mtk_oddmr_dbi_change_remap_gain(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, uint32_t cur_max_time)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t frac_bit = 0;
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data = &oddmr_data->primary_data->dbi_cfg_info;
	uint32_t cur_dbv;
	uint32_t cur_offset;
	uint32_t cur_dbv_gain;
	uint32_t remap_gain_target_code;
	uint32_t remap_gain;
	uint32_t dmr_remap_gain;
	int dmr_remap_en;

	if (oddmr_data->primary_data->dbi_state < ODDMR_INIT_DONE) {
		ODDMRLOW_LOG("dbi off remap_gain_target_code %u\n", dbi_cfg_data->fps_dbv_node.remap_gain_target_code);
		remap_gain_target_code = (dbi_cfg_data->fps_dbv_node.remap_gain_target_code<<16);
		remap_gain = MIN(((remap_gain_target_code  / 255) >> 4), 4096);
	} else {
		ODDMRLOW_LOG("cur_max_time %u\n", cur_max_time);
		ODDMRLOW_LOG("remap_gain_target_code %u\n", dbi_cfg_data->fps_dbv_node.remap_gain_target_code);

		mutex_lock(&oddmr_data->primary_data->timing_lock);
		cur_dbv = oddmr_data->primary_data->current_timing.bl_level;
		mutex_unlock(&oddmr_data->primary_data->timing_lock);

		cur_offset = mtk_oddmr_dbi_alpha_blend_int(dbi_cfg_data->fps_dbv_node.remap_reduce_offset_num,
			dbi_cfg_data->fps_dbv_node.remap_reduce_offset_node,
			dbi_cfg_data->fps_dbv_node.remap_reduce_offset_value, cur_max_time, frac_bit);
		cur_dbv_gain = mtk_oddmr_dbi_alpha_blend_int(dbi_cfg_data->fps_dbv_node.remap_dbv_gain_num,
			dbi_cfg_data->fps_dbv_node.remap_dbv_gain_node,
			dbi_cfg_data->fps_dbv_node.remap_dbv_gain_value, cur_dbv, frac_bit);

		remap_gain_target_code = (dbi_cfg_data->fps_dbv_node.remap_gain_target_code<<16);
		remap_gain = MIN((((remap_gain_target_code - (cur_offset * cur_dbv_gain)) / 255) >> 4), 4096);

		ODDMRLOW_LOG("remap gain:0x%x, remap offset:0x%x, remap DBV gain:0x%x\n",
			remap_gain, cur_offset, cur_dbv_gain);
	}

	if (oddmr_data->data->dbi_version == MTK_DBI_V2 || oddmr_data->data->dbi_version == MTK_DBI_V3) {
		atomic_set(&oddmr_data->dbi_data.remap_gain, remap_gain);
		dmr_remap_en = atomic_read(&oddmr_data->dmr_data.remap_enable);
		if (dmr_remap_en == 1)
			dmr_remap_gain = atomic_read(&oddmr_data->dmr_data.remap_gain);
		else
			dmr_remap_gain = 4096;
		mtk_oddmr_write_mask(comp, ((remap_gain * dmr_remap_gain) / 4096),
			MT6991_DISP_ODDMR_REG_SPR_REMAP_GAIN, 0xffffffff, pkg);
	} else {
		mtk_oddmr_write_mask(comp, remap_gain,
			DISP_ODDMR_REG_SPR_REMAP_GAIN, 0xffffffff, pkg);
	}
}

static int mtk_oddmr_dbi_enable(struct mtk_ddp_comp *comp, bool en)
{
	int ret = 0, enable = en;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);

	ODDMRAPI_LOG("%d\n", enable);
	if (oddmr_data->primary_data->dbi_state < ODDMR_INIT_DONE) {
		ODDMRFLOW_LOG("can not enable, state %d\n", oddmr_data->primary_data->dbi_state);
		return -EFAULT;
	}
	if (en && oddmr_data->use_slc[DBI_SLC]) {
		int ret;

		ret = disp_oddmr_slc_request(comp, DBI_SLC);
		if (!ret)
			disp_oddmr_slc_valid(comp, DBI_SLC);
	}
	oddmr_data->dbi_enable_req = enable;
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;
		struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

		oddmr1_data->dbi_enable_req = enable;
	}
	atomic_set(&oddmr_data->primary_data->dbi_hrt_done, 2);
	drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
	ret = wait_event_interruptible_timeout(g_oddmr_hrt_wq,
			atomic_read(&oddmr_data->primary_data->dbi_hrt_done) == 1, msecs_to_jiffies(200));
	if (ret <= 0) {
		atomic_set(&oddmr_data->primary_data->dbi_hrt_done, 0);
		ODDMRFLOW_LOG("enable %d repaint timeout %d\n", enable, ret);
		ret = -EAGAIN;
	}
	return ret;
}

static int mtk_oddmr_remap_update(struct mtk_ddp_comp *comp)
{
	int ret = 0;

	ODDMRAPI_LOG("+\n");

	ret = mtk_crtc_user_cmd(&comp->mtk_crtc->base, comp,
					ODDMR_CMD_ODDMR_REMAP_CHG, NULL);
	return ret;
}


static int mtk_oddmr_dmr_enable(struct mtk_ddp_comp *comp, bool en)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	int ret = 0, enable = en;

	ODDMRAPI_LOG("%d\n", enable);
	if (oddmr_data->primary_data->dmr_state < ODDMR_INIT_DONE) {
		PC_ERR("can not enable, state %d\n", oddmr_data->primary_data->dmr_state);
		return -1;
	}
	if (atomic_read(&oddmr_data->primary_data->dmr_hrt_done) == 2) {
		PC_ERR("previous layering rule for dmr enable not finished\n");
		drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
		ret = wait_event_interruptible_timeout(g_oddmr_hrt_wq,
			atomic_read(&oddmr_data->primary_data->dmr_hrt_done) == 1,
			msecs_to_jiffies(200));
		if (ret <= 0) {
			PC_ERR("previous dmr enable repaint timeout %d\n", ret);
			return -1;
		}
	}
	if (atomic_read(&oddmr_data->dmr_data.dmr_cfg_done) == 2) {
		PC_ERR("previous layering rule for dmr enable not finished\n");
		drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
		ret = wait_event_interruptible_timeout(oddmr_data->primary_data->dmr_enable_wq,
				atomic_read(&oddmr_data->dmr_data.dmr_cfg_done) == 1,
				msecs_to_jiffies(200));
		if (ret <= 0) {
			PC_ERR("previous dmr enable:%d timeout\n");
			return -1;
		}
	}
	CRTC_MMP_EVENT_START(0, oddmr_dmr_enable, 0, 0);
	if (en && oddmr_data->use_slc[DMR_SLC]) {
		int ret;

		ret = disp_oddmr_slc_request(comp, DMR_SLC);
		if (!ret)
			disp_oddmr_slc_valid(comp, DMR_SLC);
	}
	oddmr_data->dmr_enable_req = enable;
	if (comp->mtk_crtc->is_dual_pipe) {
		struct mtk_ddp_comp *comp1 = oddmr_data->companion;
		struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

		oddmr1_data->dmr_enable_req = enable;
	}
	atomic_set(&oddmr_data->primary_data->dmr_hrt_done, 2);
	atomic_set(&oddmr_data->dmr_data.dmr_cfg_done, 2);
	drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
	if (oddmr_data->primary_data->dmr_first_en == 0) {
		oddmr_data->primary_data->dmr_first_en = 1;
		CRTC_MMP_MARK(0, oddmr_dmr_enable, 0, 0);
		return 0;
	}
	ret = wait_event_interruptible_timeout(g_oddmr_hrt_wq,
			atomic_read(&oddmr_data->primary_data->dmr_hrt_done) == 1,
			msecs_to_jiffies(200));
	if (ret <= 0) {
		PC_ERR("enable %d repaint timeout %d\n", enable, ret);
		CRTC_MMP_MARK(0, oddmr_dmr_enable, 9, 1);
		return -1;
	}
	atomic_set(&oddmr_data->primary_data->dmr_hrt_done, 0);

	ret = wait_event_interruptible_timeout(oddmr_data->primary_data->dmr_enable_wq,
				atomic_read(&oddmr_data->dmr_data.dmr_cfg_done) == 1,
				msecs_to_jiffies(200));
	if (ret <= 0) {
		PC_ERR("dmr enable:%d timeout\n", en);
		CRTC_MMP_MARK(0, oddmr_dmr_enable, 9, 2);
		return -1;
	}
	atomic_set(&oddmr_data->dmr_data.dmr_cfg_done, 0);
	CRTC_MMP_EVENT_END(0, oddmr_dmr_enable, 0, 0);
	return 0;
}

static int mtk_oddmr_tuning_od_set_sram_data(uint32_t map_id,
	struct mtk_oddmr_od_tuning_sram *tuning_data)
{
	ODDMRAPI_LOG("+\n");
	/* B:0-bit1, G:1-bit2, R:2-bit3*/
	if (map_id >= OD_TABLE_B_SRAM1_START && map_id <= OD_TABLE_B_SRAM1_END) {
		tuning_data->channel = 0;
		tuning_data->sram = 1;
		tuning_data->idx = map_id - OD_TABLE_B_SRAM1_START;
	} else if (map_id >= OD_TABLE_B_SRAM2_START && map_id <= OD_TABLE_B_SRAM2_END) {
		tuning_data->channel = 0;
		tuning_data->sram = 2;
		tuning_data->idx = map_id - OD_TABLE_B_SRAM2_START;
	} else if (map_id >= OD_TABLE_B_SRAM3_START && map_id <= OD_TABLE_B_SRAM3_END) {
		tuning_data->channel = 0;
		tuning_data->sram = 3;
		tuning_data->idx = map_id - OD_TABLE_B_SRAM3_START;
	} else if (map_id >= OD_TABLE_B_SRAM4_START && map_id <= OD_TABLE_B_SRAM4_END) {
		tuning_data->channel = 0;
		tuning_data->sram = 4;
		tuning_data->idx = map_id - OD_TABLE_B_SRAM4_START;
	} else if (map_id >= OD_TABLE_G_SRAM1_START && map_id <= OD_TABLE_G_SRAM1_END) {
		tuning_data->channel = 1;
		tuning_data->sram = 1;
		tuning_data->idx = map_id - OD_TABLE_G_SRAM1_START;
	} else if (map_id >= OD_TABLE_G_SRAM2_START && map_id <= OD_TABLE_G_SRAM2_END) {
		tuning_data->channel = 1;
		tuning_data->sram = 2;
		tuning_data->idx = map_id - OD_TABLE_G_SRAM2_START;
	} else if (map_id >= OD_TABLE_G_SRAM3_START && map_id <= OD_TABLE_G_SRAM3_END) {
		tuning_data->channel = 1;
		tuning_data->sram = 3;
		tuning_data->idx = map_id - OD_TABLE_G_SRAM3_START;
	} else if (map_id >= OD_TABLE_G_SRAM4_START && map_id <= OD_TABLE_G_SRAM4_END) {
		tuning_data->channel = 1;
		tuning_data->sram = 4;
		tuning_data->idx = map_id - OD_TABLE_G_SRAM4_START;
	} else if (map_id >= OD_TABLE_R_SRAM1_START && map_id <= OD_TABLE_R_SRAM1_END) {
		tuning_data->channel = 2;
		tuning_data->sram = 1;
		tuning_data->idx = map_id - OD_TABLE_R_SRAM1_START;
	} else if (map_id >= OD_TABLE_R_SRAM2_START && map_id <= OD_TABLE_R_SRAM2_END) {
		tuning_data->channel = 2;
		tuning_data->sram = 2;
		tuning_data->idx = map_id - OD_TABLE_R_SRAM2_START;
	} else if (map_id >= OD_TABLE_R_SRAM3_START && map_id <= OD_TABLE_R_SRAM3_END) {
		tuning_data->channel = 2;
		tuning_data->sram = 3;
		tuning_data->idx = map_id - OD_TABLE_R_SRAM3_START;
	} else if (map_id >= OD_TABLE_R_SRAM4_START && map_id <= OD_TABLE_R_SRAM4_END) {
		tuning_data->channel = 2;
		tuning_data->sram = 4;
		tuning_data->idx = map_id - OD_TABLE_R_SRAM4_START;
	} else {
		ODDMRFLOW_LOG("map_id 0x%x outof bound\n", map_id);
		return -EFAULT;
	}
	return 0;
}

static int mtk_oddmr_od_sram_read(struct mtk_ddp_comp *comp, int table_idx,
			struct mtk_oddmr_sw_reg *sw_reg, struct mtk_oddmr_od_param *pparam)
{
	struct mtk_oddmr_od_table *table;
	uint8_t *raw_table;
	uint32_t table_size, map_id, *val;
	int idx;
	struct mtk_oddmr_od_tuning_sram tuning_data = {0};

	ODDMRAPI_LOG("+\n");
	if (!IS_TABLE_VALID(table_idx, pparam->valid_table)) {
		ODDMRFLOW_LOG("table %d is invalid\n", table_idx);
		return -EFAULT;
	}
	table = pparam->od_tables[table_idx];
	raw_table = table->raw_table.value;
	table_size = table->raw_table.size;

	map_id = (sw_reg->reg & 0xFFFF) / 4;
	val = &sw_reg->val;
	idx = map_id - OD_TABLE_B_SRAM1_START;
	if (idx >= table_size) {
		ODDMRFLOW_LOG("table%d idx %d outof size %d\n", table_idx, idx, table_size);
		return -EFAULT;
	}
	mtk_oddmr_tuning_od_set_sram_data(map_id, &tuning_data);
	mtk_oddmr_od_tuning_read_sram(comp, &tuning_data);
	*val = tuning_data.value;
	ODDMRAPI_LOG("map_id 0x%x table_idx %d, idx %d val %u\n", map_id, table_idx, idx, *val);
	return 0;
}

static int mtk_oddmr_od_sram_write(struct mtk_ddp_comp *comp, int table_idx,
			struct mtk_oddmr_sw_reg *sw_reg, struct mtk_oddmr_od_param *pparam)
{
	struct mtk_oddmr_od_table *table;
	uint8_t *raw_table;
	uint32_t table_size, map_id, val;
	int idx, ret = 0;
	struct mtk_oddmr_od_tuning_sram tuning_data = {0};

	ODDMRAPI_LOG("+\n");
	if (!IS_TABLE_VALID(table_idx, pparam->valid_table)) {
		ODDMRFLOW_LOG("table %d is invalid\n", table_idx);
		return -EFAULT;
	}
	table = pparam->od_tables[table_idx];
	raw_table = table->raw_table.value;
	table_size = table->raw_table.size;

	map_id = (sw_reg->reg & 0xFFFF) / 4;
	val = sw_reg->val;
	idx = map_id - OD_TABLE_B_SRAM1_START;
	if (idx >= table_size) {
		ODDMRFLOW_LOG("table%d idx %d outof size %d\n", table_idx, idx, table_size);
		return -EFAULT;
	}
	//raw_table[idx] = val;
	mtk_oddmr_tuning_od_set_sram_data(map_id, &tuning_data);
	tuning_data.value = val;

	ret = mtk_crtc_user_cmd(&comp->mtk_crtc->base, comp,
		ODDMR_CMD_OD_TUNING_WRITE_SRAM, &tuning_data);
	if (ret == 1)
		ret = -EFAULT;
	ODDMRAPI_LOG("ret %d map_id:0x%x(%u,%u,%u,%u)\n", ret, map_id,
		tuning_data.channel, tuning_data.sram, tuning_data.idx, tuning_data.value);
	return ret;
}

static int mtk_oddmr_od_status_read(struct mtk_ddp_comp *comp, int table_idx,
			struct mtk_oddmr_sw_reg *sw_reg, struct mtk_oddmr_timing *timing)
{
	uint32_t map_id, *val;
	int ret = 0;

	ODDMRAPI_LOG("+\n");
	map_id = (sw_reg->reg & 0xFFFF) / 4;
	val = &sw_reg->val;
	switch (map_id) {
	case OD_CURRENT_TABLE:
		*val = table_idx;
		break;
	case OD_CURRENT_BL:
		*val = timing->bl_level;
		break;
	case OD_CURRENT_FPS:
		*val = timing->vrefresh;
		break;
	case OD_CURRENT_HDISPLAY:
		*val = timing->hdisplay;
		break;
	case OD_CURRENT_VDISPLAY:
		*val = timing->vdisplay;
		break;
	default:
		ret = -EFAULT;
		break;
	}
	ODDMRAPI_LOG("map_id 0x%x, %d\n", map_id, *val);
	return ret;
}

static int mtk_oddmr_od_read_sw_reg(struct mtk_ddp_comp *comp, void* data,
			struct mtk_oddmr_od_param *pparam)
{
	int ret, table_idx, tmp_sram_idx;
	struct mtk_oddmr_sw_reg *sw_reg = (struct mtk_oddmr_sw_reg *)data;
	uint32_t map_id;
	struct mtk_disp_oddmr *oddmr_data;

	ODDMRAPI_LOG("+\n");
	if (!comp || !data || pparam == NULL) {
		ODDMRFLOW_LOG("params is invalid\n");
		return -EFAULT;
	}
	oddmr_data = comp_to_oddmr(comp);
	if (oddmr_data->od_enable == 0 || comp->mtk_crtc->sec_on) {
		ODDMRFLOW_LOG("od not enabled\n");
		return -EFAULT;
	}
	tmp_sram_idx = oddmr_data->od_data.od_sram_read_sel;
	table_idx = oddmr_data->od_data.od_dram_sel[oddmr_data->od_data.od_sram_table_idx[!!tmp_sram_idx]];
	if (!IS_TABLE_VALID(table_idx, pparam->valid_table)) {
		ODDMRFLOW_LOG("table %d is invalid\n", table_idx);
		return -EFAULT;
	}
	map_id = (sw_reg->reg & 0xFFFF) / 4;
	if (map_id >= OD_TABLE_B_SRAM1_START && map_id <= OD_TABLE_R_SRAM4_END)
		ret = mtk_oddmr_od_sram_read(comp, table_idx, sw_reg, pparam);
	else if (map_id <= OD_CURRENT_VDISPLAY)
		ret = mtk_oddmr_od_status_read(comp, table_idx, sw_reg, &oddmr_data->primary_data->current_timing);
	else
		ret = mtk_oddmr_od_tuning_read(comp, table_idx, sw_reg, pparam); 
	ODDMRFLOW_LOG("reg 0x%x 0x%x+\n", sw_reg->reg, sw_reg->val);
	return ret;
}

static int mtk_oddmr_od_write_sw_reg(struct mtk_ddp_comp *comp, void* data,
			struct mtk_oddmr_od_param *pparam)
{
	int ret, table_idx, tmp_sram_idx;
	struct mtk_oddmr_sw_reg *sw_reg = (struct mtk_oddmr_sw_reg *)data;
	uint32_t map_id;
	struct mtk_disp_oddmr *oddmr_data;

	ODDMRAPI_LOG("+\n");
	if (!comp || !data || pparam == NULL) {
		ODDMRFLOW_LOG("params is invalid\n");
		return -EFAULT;
	}
	oddmr_data = comp_to_oddmr(comp);
	if (oddmr_data->od_enable == 0 || comp->mtk_crtc->sec_on) {
		ODDMRFLOW_LOG("od not enabled\n");
		return -EFAULT;
	}
	ODDMRFLOW_LOG("reg 0x%x val 0x%x+\n", sw_reg->reg, sw_reg->val);
	tmp_sram_idx = oddmr_data->od_data.od_sram_read_sel;
	table_idx = oddmr_data->od_data.od_dram_sel[oddmr_data->od_data.od_sram_table_idx[!!tmp_sram_idx]];
	if (!IS_TABLE_VALID(table_idx, pparam->valid_table)) {
		ODDMRFLOW_LOG("table %d is invalid\n", table_idx);
		return -EFAULT;
	}
	map_id = (sw_reg->reg & 0xFFFF) / 4;
	if (map_id >= OD_TABLE_B_SRAM1_START && map_id <= OD_TABLE_R_SRAM4_END)
		ret = mtk_oddmr_od_sram_write(comp, table_idx, sw_reg, pparam);
	else
		ret = mtk_oddmr_od_tuning_write(comp, table_idx, sw_reg, pparam);
	return ret;
}

int disp_oddmr_act_od_load_param(struct mtk_ddp_comp *comp, void *data)
{
	int ret;
	struct mtk_drm_oddmr_param *param = data;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool od_support = oddmr_data->primary_data->od_support;

	ODDMRAPI_LOG("+\n");
	if (param == NULL) {
		ODDMRFLOW_LOG("param is NULL\n");
		return -EFAULT;
	}
	ret = 0;
	switch (param->head_id >> 24) {
	case ODDMR_OD_BASIC_INFO:
	case ODDMR_OD_TABLE:
		if (!od_support) {
			ODDMRFLOW_LOG("od not support\n");
			ret = -EFAULT;
		}
		break;
	default:
		ret = -EFAULT;
		break;
	}
	if (ret < 0)
		return ret;
	/*
	 * If any section is loaded, set all to loading,
	 * set loading done in init to support partial loading.
	 */
	mutex_lock(&oddmr_data->primary_data->od_load_param_lock);
	ret = mtk_oddmr_load_param(oddmr_data, data);
	mutex_unlock(&oddmr_data->primary_data->od_load_param_lock);
	return ret;
}

static void mtk_oddmr_odr_get_status(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	const u16 reg_jump = CMDQ_THR_SPR_IDX1;
	const u16 var1 = CMDQ_THR_SPR_IDX2;
	struct cmdq_operand lop, rop;
	u32 inst_condi_jump;
	u64 *inst, jump_pa;

	ODDMRAPI_LOG("+\n");
	/* 1. get od status */
	lop.reg = true;
	lop.idx = CMDQ_THR_SPR_IDX2;
	rop.reg = false;
	rop.value = 1;

	if (oddmr_data->data->od_version >= MTK_OD_V2)
		cmdq_pkt_read(handle, NULL,
					comp->regs_pa + MT6991_DISP_ODDMR_OD_CTRL_EN, var1);
	else
		cmdq_pkt_read(handle, NULL,
					comp->regs_pa + DISP_ODDMR_OD_CTRL_EN, var1);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_AND, var1, &lop, &rop);
	/* 2. read odr cnts if od is enabled */
	lop.reg = true;
	lop.idx = CMDQ_THR_SPR_IDX2;
	rop.reg = false;
	rop.value = 1;

	/*mark condition jump */
	inst_condi_jump = handle->cmd_buf_size;
	cmdq_pkt_assign_command(handle, reg_jump, 0);

	cmdq_pkt_cond_jump_abs(handle, reg_jump, &lop, &rop,
		CMDQ_NOT_EQUAL);

	/* if condition false, here is nop jump, od enable */
	{
		if (oddmr_data->data->od_version >= MTK_OD_V2) {
			cmdq_pkt_mem_move(handle, NULL, comp->regs_pa + MT6991_DISP_ODDMR_UDMA_R_CTRL84_0,
				comp->regs_pa + DISP_ODDMR_ODR_H,
				CMDQ_THR_SPR_IDX3);
			cmdq_pkt_mem_move(handle, NULL, comp->regs_pa + MT6991_DISP_ODDMR_UDMA_R_CTRL86_0,
				comp->regs_pa + DISP_ODDMR_ODR_V,
				CMDQ_THR_SPR_IDX3);
		} else {
			cmdq_pkt_mem_move(handle, NULL, comp->regs_pa + DISP_ODDMR_UDMA_R_CTRL84_0,
				comp->regs_pa + DISP_ODDMR_ODR_H,
				CMDQ_THR_SPR_IDX3);
			cmdq_pkt_mem_move(handle, NULL, comp->regs_pa + DISP_ODDMR_UDMA_R_CTRL86_0,
				comp->regs_pa + DISP_ODDMR_ODR_V,
				CMDQ_THR_SPR_IDX3);
		}
	}

	/* end condition */
	inst = cmdq_pkt_get_va_by_offset(handle, inst_condi_jump);
	jump_pa = cmdq_pkt_get_pa_by_offset(handle,
				handle->cmd_buf_size);
	*inst = *inst | CMDQ_REG_SHIFT_ADDR(jump_pa);
}

static void mtk_oddmr_dmr_ddren_en(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, unsigned int en)
{
	GCE_COND_DECLARE;
	struct cmdq_operand lop, rop;
	const u16 var1 = CMDQ_THR_SPR_IDX2;
	const u16 var2 = 0;

	if (en == 1) {
		GCE_COND_ASSIGN(handle, CMDQ_THR_SPR_IDX1, CMDQ_GPR_R07);
		/* get dbi status */
		lop.reg = true;
		lop.idx = var1;
		rop.reg = false;
		rop.value = 1;
		cmdq_pkt_read(handle, NULL,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_DMR_EN, var1);
		cmdq_pkt_logic_command(handle, CMDQ_LOGIC_AND, var1, &lop, &rop);

		lop.reg = true;
		lop.idx = var1;
		rop.reg = false;
		rop.idx = var2;
		rop.value = 1;
		GCE_IF(lop, R_CMDQ_EQUAL, rop);
		/* condition true: DMR enabled, enable dmr ddren */
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_DMR_DDREN_CTRL, 4, ~0);
		GCE_FI;
	} else {
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_DMR_DDREN_CTRL, 9, ~0);
	}
}

static void mtk_oddmr_dbi_ddren_en(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, unsigned int en)
{
	GCE_COND_DECLARE;
	struct cmdq_operand lop, rop;
	const u16 var1 = CMDQ_THR_SPR_IDX2;
	const u16 var2 = 0;

	if (en == 1) {
		GCE_COND_ASSIGN(handle, CMDQ_THR_SPR_IDX1, CMDQ_GPR_R07);
		/* get dbi status */
		lop.reg = true;
		lop.idx = var1;
		rop.reg = false;
		rop.value = 2;
		cmdq_pkt_read(handle, NULL,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_DMR_EN, var1);
		cmdq_pkt_logic_command(handle, CMDQ_LOGIC_AND, var1, &lop, &rop);

		lop.reg = true;
		lop.idx = var1;
		rop.reg = false;
		rop.idx = var2;
		rop.value = 2;
		GCE_IF(lop, R_CMDQ_EQUAL, rop);
		/* condition true: DBI enabled, enable dbi ddren */
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_DBI_DDREN_CTRL, 4, ~0);
		GCE_FI;
	} else {
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_DBI_DDREN_CTRL, 9, ~0);
	}
}

/* OD MT6991 DDREN */
static void mtk_oddmr_od_ddren_en(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, unsigned int en)
{
	GCE_COND_DECLARE;
	struct cmdq_operand lop, rop;
	const u16 var1 = CMDQ_THR_SPR_IDX2;
	const u16 var2 = 0;

	if (en == 1) {
		GCE_COND_ASSIGN(handle, CMDQ_THR_SPR_IDX1, CMDQ_GPR_R07);
		/* get od status */
		lop.reg = true;
		lop.idx = var1;
		rop.reg = false;
		rop.value = 1;
		cmdq_pkt_read(handle, NULL,
			comp->regs_pa + MT6991_DISP_ODDMR_OD_CTRL_EN, var1);
		cmdq_pkt_logic_command(handle, CMDQ_LOGIC_AND, var1, &lop, &rop);

		lop.reg = true;
		lop.idx = var1;
		rop.reg = false;
		rop.idx = var2;
		rop.value = 1;
		GCE_IF(lop, R_CMDQ_EQUAL, rop);
		/* condition true: OD enabled, enable OD ddren */
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_ODW_DDREN_CTRL, 4, ~0);
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_ODR_DDREN_CTRL, 4, ~0);
		GCE_FI;
	} else {
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_ODW_DDREN_CTRL, 9, ~0);
		cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_ODR_DDREN_CTRL, 9, ~0);
	}
}

static void mtk_oddmr_config_trigger(struct mtk_ddp_comp *comp,
				   struct cmdq_pkt *handle,
				   enum mtk_ddp_comp_trigger_flag flag)
{
	struct mtk_drm_crtc *mtk_crtc = comp->mtk_crtc;
	struct mtk_drm_private *priv = NULL;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	bool dmr_support, dbi_support, od_support;

	if (!mtk_crtc) {
		PC_ERR("%s oddmr comp not configure CRTC yet\n", __func__);
		return;
	}
	if (!mtk_crtc->base.dev)
		return;
	priv = mtk_crtc->base.dev->dev_private;
	dmr_support = oddmr_data->primary_data->dmr_support;
	dbi_support = oddmr_data->primary_data->dbi_support;
	od_support = oddmr_data->primary_data->od_support;
	ODDMRFLOW_LOG("%d\n", flag);
	switch (flag) {
	case MTK_TRIG_FLAG_TRIGGER:
	{
		if (priv && (priv->data->mmsys_id == MMSYS_MT6991)) {
			if(dbi_support)
				mtk_oddmr_dbi_ddren_en(comp, handle, 1);
			if(dmr_support)
				mtk_oddmr_dmr_ddren_en(comp, handle, 1);
			if (od_support)
				mtk_oddmr_od_ddren_en(comp, handle, 1);
		}
	}
		break;
	case MTK_TRIG_FLAG_EOF:
	{
		if (priv && (priv->data->mmsys_id == MMSYS_MT6991)) {
			if (dbi_support)
				mtk_oddmr_dbi_ddren_en(comp, handle, 0);
			if(dmr_support)
				mtk_oddmr_dmr_ddren_en(comp, handle, 0);
			if (od_support)
				mtk_oddmr_od_ddren_en(comp, handle, 0);
		}

		if(oddmr_data->data->dbi_version >= MTK_DBI_V3)
			mtk_oddmr_dbi_read_ir_drop(comp, handle);

		if (priv && (!mtk_drm_helper_get_opt(priv->helper_opt,
				MTK_DRM_OPT_ODDMR_OD_AEE)))
			break;
		mtk_oddmr_odr_get_status(comp, handle);
	}
		break;
	default:
		break;
	}
}

void mtk_oddmr_dbi_trigger_ir_drop(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle, uint32_t height)
{
	cmdq_pkt_write(handle, comp->cmdq_base,
		comp->regs_pa + REG_DBI_IR_DROP_EN, 1, ~0);
	mtk_oddmr_write(comp, height + 1,
			MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
}

static void mtk_oddmr_dbi_read_ir_drop(struct mtk_ddp_comp *comp,
	struct cmdq_pkt *handle)
{
	uint32_t value = 0, mask = 0;

	GCE_COND_DECLARE;
	struct cmdq_operand lop, rop;
	const u16 var1 = CMDQ_THR_SPR_IDX2;
	const u16 var2 = 0;

	GCE_COND_ASSIGN(handle, CMDQ_THR_SPR_IDX1, CMDQ_GPR_R07);
	/* get dbi status */
	lop.reg = true;
	lop.idx = var1;
	rop.reg = false;
	rop.value = 1;

	cmdq_pkt_read(handle, NULL, comp->regs_pa + REG_DBI_IR_DROP_EN, var1);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_AND, var1, &lop, &rop);
	lop.reg = true;
	lop.idx = var1;
	rop.reg = false;
	rop.idx = var2;
	rop.value = 1;
	GCE_IF(lop, R_CMDQ_EQUAL, rop);
	/* condition true: DBI enabled, enable dbi ddren */

	cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + REG_DBI_IR_DROP_STST_FORCE_UPDATE, 1, ~0);

	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_ACC_R,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_STAT_R),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_ACC_G,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_STAT_G),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_ACC_B,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_STAT_B),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_SQUA_ACC_R_0,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_R_0),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_SQUA_ACC_R_1,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_R_1),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_SQUA_ACC_G_0,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_G_0),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_SQUA_ACC_G_1,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_G_1),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_SQUA_ACC_B_0,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_B_0),
		CMDQ_THR_SPR_IDX3);
	cmdq_pkt_mem_move(handle, NULL,
		comp->regs_pa + REG_DBI_IR_DROP_STST_SQUA_ACC_B_1,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_B_1),
		CMDQ_THR_SPR_IDX3);


	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_STAT_R), var1);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_STAT_G), CMDQ_THR_SPR_IDX3);
	lop.reg = true;
	lop.idx = var1;
	rop.reg = true;
	rop.value = CMDQ_THR_SPR_IDX3;
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_STAT_B), CMDQ_THR_SPR_IDX3);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_R_0), CMDQ_THR_SPR_IDX3);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_R_1), CMDQ_THR_SPR_IDX3);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_G_0), CMDQ_THR_SPR_IDX3);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_G_1), CMDQ_THR_SPR_IDX3);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_B_0), CMDQ_THR_SPR_IDX3);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);
	cmdq_pkt_read(handle, NULL, mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_SQUA_B_1), CMDQ_THR_SPR_IDX3);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_ADD, var1, &lop, &rop);

	cmdq_pkt_write_indriect(handle, comp->cmdq_base,
		mtk_get_gce_backup_slot_pa(comp->mtk_crtc,
		DISP_SLOT_DBI_IR_DROP_CHECK_SUM), var1, ~0);

	cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + REG_DBI_IR_DROP_STST_CLEAR, 1, ~0);
	cmdq_pkt_write(handle, comp->cmdq_base,
			comp->regs_pa + REG_DBI_IR_DROP_EN, 0, ~0);

	lop.reg = true;
	lop.idx = var1;
	rop.reg = false;
	rop.value = 1;
	cmdq_pkt_read(handle, NULL, comp->regs_pa + MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, var1);
	cmdq_pkt_logic_command(handle, CMDQ_LOGIC_SUBTRACT, var1, &lop, &rop);
	cmdq_pkt_write_indriect(handle, comp->cmdq_base,
			comp->regs_pa + MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, var1, ~0);
	GCE_FI;
}




static void mtk_oddmr_remap_set_enable(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *pkg, bool en)
{
	int enable = en;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	uint32_t value = 0, mask = 0;

	ODDMRAPI_LOG("%d\n", enable);
	if (oddmr_data->data->dbi_version == MTK_DBI_V2 || oddmr_data->data->dbi_version == MTK_DBI_V3 ||
		oddmr_data->data->dmr_version== MTK_DMR_V1) {
		if (en) {
			mtk_oddmr_write(comp, 1,
				MT6991_DISP_ODDMR_REG_SPR_REMAP_EN, pkg);
			SET_VAL_MASK(value, mask, 4, MT6991_REG_SPR2RGB_BYPASS);
			if (oddmr_data->data->od_version >= MTK_OD_V2)
				SET_VAL_MASK(value, mask, 0, MT6991_REG_OD_SPR2RGB_BYPASS);
			mtk_oddmr_write_mask(comp, 0,
				MT6991_DISP_ODDMR_TOP_OD_S2R_BYPASS,
				mask, pkg);
		} else
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_REG_SPR_REMAP_EN, pkg);
		return;
	}

	if (en) {
		mtk_oddmr_write_mask(comp, 1,
			DISP_ODDMR_REG_SPR_REMAP_EN, 0xffffffff, pkg);
		mtk_oddmr_write_mask(comp, 0,
			DISP_ODDMR_TOP_S2R_BYPASS, 0xffffffff, pkg);
	} else
		mtk_oddmr_write_mask(comp, 0,
			DISP_ODDMR_REG_SPR_REMAP_EN, 0xffffffff, pkg);
}

static int mtk_oddmr_remap_enable(struct mtk_ddp_comp *comp, bool en)
{
	int ret = 0, enable = en;

	ODDMRAPI_LOG("%d\n", enable);

	if (en)
		ret = mtk_crtc_user_cmd(&comp->mtk_crtc->base, comp,
			ODDMR_CMD_ODDMR_REMAP_EN, NULL);
	else
		ret = mtk_crtc_user_cmd(&comp->mtk_crtc->base, comp,
			ODDMR_CMD_ODDMR_REMAP_OFF, NULL);

	drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);

	return ret;
}

static int mtk_oddmr_pq_ioctl_transact(struct mtk_ddp_comp *comp,
	unsigned int cmd, void *params, unsigned int size)
{
	int ret = -1;
	struct bitstream_buffer *stream_buffer;
	struct drm_mtk_dbi_caps *caps;
	void *ptr;
	unsigned int *cur_max_time;
	unsigned int *target_code;
	unsigned int *gain_ratio;
	struct mtk_drm_private *priv = NULL;
	unsigned int temp;
	unsigned int cur_dbv;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	unsigned int dmr_remap_en;
	unsigned int reg_tuning_en = 0;

	switch (cmd) {
	case PQ_ODDMR_DMR_INIT:
		ret = mtk_oddmr_dmr_init(comp, params);
		DDPMSG("%s, PQ_DMR_INIT ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DMR_ENABLE:
		ret = mtk_oddmr_dmr_enable(comp, true);
		DDPMSG("%s, PQ_DMR_ENABLE ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DMR_DISABLE:
		ret = mtk_oddmr_dmr_enable(comp, false);
		DDPMSG("%s, PQ_DMR_DISABLE ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DMR_BINSET_INIT:
		ret = mtk_oddmr_dmr_binset_init(comp, params);
		DDPMSG("%s, PQ_DMR_BINSET_INIT ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DMR_BINSET_CHG:
	{
		mtk_oddmr_binset_chg(comp, *(unsigned int *)params, NULL);
		if (oddmr_data->dmr_enable) {
			drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
			ret = wait_event_interruptible_timeout(oddmr_data->primary_data->dmr_switch_wq,
				atomic_read(&oddmr_data->dmr_data.dmr_timing_state) == 0,
				msecs_to_jiffies(200));
			if (ret <= 0) {
				PC_ERR("repaint timeout\n");
				return -1;
			}
		}
		ret = 0;
		DDPMSG("%s, PQ_DMR_BINSET_CHG ret:%d\n", __func__, ret);
	}
		break;
	case PQ_ODDMR_DMR_CUS_BINSET_INIT:
		ret = mtk_oddmr_dmr_cus_binset_init(comp, params);
		DDPMSG("%s, PQ_ODDMR_DMR_CUS_BINSET_INIT ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DMR_CUS_SETTING_INIT:
		ret = mtk_oddmr_dmr_cus_setting_init(comp, params);
		DDPMSG("%s, PQ_ODDMR_DMR_CUS_SETTING_INIT ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DMR_CUS_OWN_DATA_INIT:
		ret = mtk_oddmr_dmr_cus_own_data_init(comp, params);
		DDPMSG("%s, PQ_ODDMR_DMR_CUS_OWN_DATA_INIT ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DMR_REG_TUNING_ENABLE:
		ret = 0;
		reg_tuning_en = *(unsigned int *)params;
		mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
		atomic_set(&oddmr_data->reg_tuning_en, reg_tuning_en);
		atomic_set(&oddmr_data->dmr_data.reg_tuning_chg, 1);
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		if (oddmr_data->dmr_enable)
			drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
		DDPMSG("%s, PQ_ODDMR_DMR_REG_TUNING_ENABLE\n", __func__);
		break;
	case PQ_ODDMR_DMR_REG_TUNING_INIT:
		mutex_lock(&oddmr_data->primary_data->dmr_data_lock);
		ret = mtk_oddmr_reg_tuning_init(comp, params);
		mutex_unlock(&oddmr_data->primary_data->dmr_data_lock);
		if (ret == 0)
			drm_trigger_repaint(DRM_REPAINT_FOR_IDLE, comp->mtk_crtc->base.dev);
		DDPMSG("%s, PQ_ODDMR_DMR_REG_TUNING_INIT ret:%d\n", __func__, ret);
		break;
	case PQ_ODDMR_DBI_LOAD_PARAM:
		ret = mtk_oddmr_dbi_init(comp, params);
		DDPMSG("%s, PQ_DBI_LOAD_PARAM\n", __func__);
		break;
	case PQ_ODDMR_DBI_LOAD_TB:
	{
		ret = 0;
		if (oddmr_data->primary_data->dbi_state < ODDMR_INIT_DONE) {
			ODDMRFLOW_LOG("can not load table, state %d\n", oddmr_data->primary_data->dbi_state);
			return -EFAULT;
		}
		if(oddmr_data->data->dbi_version == MTK_DBI_V3) {
			kernel_dbi_table_update_V3(comp, (struct mtk_dbi_alg_comp_hw_param *)params);
			DDPMSG("%s, PQ_DBI_LOAD_TB\n", __func__);
			break;
		}

		stream_buffer = params;
		size = stream_buffer->size;
		ptr = vmalloc(size);
		if (!ptr) {
			DDPMSG("%s:%d, param buffer alloc fail\n",
				__func__, __LINE__);
			return -1;
		}
		if (copy_from_user(ptr,
			stream_buffer->_buffer, size)) {
			DDPMSG("%s:%d, copy_from_user fail\n", __func__, __LINE__);
			if (ptr)
				vfree(ptr);
			return -1;
		}
		stream_buffer->_buffer = ptr;

		if (oddmr_data->data->dbi_version == MTK_DBI_V2)
			kernel_dbi_table_update_V2(comp, stream_buffer);
		else
			kernel_dbi_table_update(comp, stream_buffer);
		if (ptr)
			vfree(ptr);
		DDPMSG("%s, PQ_DBI_LOAD_TB\n", __func__);
	}
		break;
	case PQ_ODDMR_DBI_ENABLE:
		ret = 0;
		mtk_oddmr_dbi_enable(comp, true);
		DDPMSG("%s, PQ_DBI_ENABLE\n", __func__);
		break;
	case PQ_ODDMR_DBI_DISABLE:
		ret = 0;
		mtk_oddmr_dbi_enable(comp, false);
		DDPMSG("%s, PQ_DBI_DISABLE\n", __func__);
		break;
	case PQ_ODDMR_DBI_REMAP_TARGET:
		ret = 0;
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		target_code = params;
		oddmr_data->primary_data->dbi_cfg_info.fps_dbv_node.remap_gain_target_code = *target_code;
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		mtk_oddmr_remap_update(comp);
		DDPMSG("%s, PQ_DBI_REMAP_TARGET remap_gain_target_code:%d\n",
			__func__, oddmr_data->primary_data->dbi_cfg_info.fps_dbv_node.remap_gain_target_code);
		break;
	case PQ_ODDMR_DBI_REMAP_CHG:
		ret = 0;
		mutex_lock(&oddmr_data->primary_data->dbi_data_lock);
		cur_max_time = params;
		oddmr_data->dbi_data.cur_max_time = *cur_max_time;
		atomic_set(&oddmr_data->dbi_data.max_time_set_done, 1);
		mutex_unlock(&oddmr_data->primary_data->dbi_data_lock);
		DDPMSG("%s, PQ_DBI_REMAP cur_max_time:%d\n", __func__, oddmr_data->dbi_data.cur_max_time);
		break;
	case PQ_ODDMR_DBI_REMAP_ENABLE:
		ret = 0;
		atomic_set(&oddmr_data->dbi_data.remap_enable, 1);
		mtk_oddmr_remap_enable(comp, true);
		break;
	case PQ_ODDMR_DBI_REMAP_DISABLE:
		ret = 0;
		atomic_set(&oddmr_data->dbi_data.remap_enable, 0);
		dmr_remap_en = atomic_read(&oddmr_data->dmr_data.remap_enable);
		if (dmr_remap_en == 0)
			mtk_oddmr_remap_enable(comp, false);
		break;
	case PQ_ODDMR_DBI_GET_HW_ID:
		ret = 0;
		DDP_MUTEX_LOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		priv = comp->mtk_crtc->base.dev->dev_private;
		*(unsigned int *)params = priv->data->mmsys_id;
		DDP_MUTEX_UNLOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		break;
	case PQ_ODDMR_DBI_GET_WIDTH:
		ret = 0;
		DDP_MUTEX_LOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		*(unsigned int *)params = mtk_crtc_get_width_by_comp(__func__,
			&comp->mtk_crtc->base, comp, false);
		DDP_MUTEX_UNLOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		break;
	case PQ_ODDMR_DBI_GET_HEIGHT:
		ret = 0;
		DDP_MUTEX_LOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		*(unsigned int *)params = mtk_crtc_get_height_by_comp(__func__,
			&comp->mtk_crtc->base, comp, false);
		DDP_MUTEX_UNLOCK_CONDITION(&comp->mtk_crtc->lock, __func__, __LINE__, false);
		break;
	case PQ_ODDMR_DBI_GET_DBV:
		ret = 0;
		mutex_lock(&oddmr_data->primary_data->timing_lock);
		*(unsigned int *)params = oddmr_data->primary_data->current_timing.bl_level;
		mutex_unlock(&oddmr_data->primary_data->timing_lock);
		break;
	case PQ_ODDMR_DBI_GET_FPS:
		ret = 0;
		mutex_lock(&oddmr_data->primary_data->timing_lock);
		*(unsigned int *)params = oddmr_data->primary_data->current_timing.vrefresh;
		mutex_unlock(&oddmr_data->primary_data->timing_lock);
		break;
	case PQ_ODDMR_DBI_GET_SCP:
		ret = 0;
		temp = atomic_read(&oddmr_data->dbi_data.enter_scp);
		*(unsigned int *)params = temp;
		if(temp)
			atomic_set(&oddmr_data->dbi_data.enter_scp, 0);
		break;
	case PQ_ODDMR_DBI_GET_SCP_LIFECYCLE:
#if !IS_ENABLED(CONFIG_MTK_TINYSYS_SCP_CM4_SUPPORT)
		ret = 0;
		DDPMSG("%s, %lx\n", __func__, (unsigned long)(oddmr_data->dbi_data.spm_base));
		DDPMSG("%s, %lx\n", __func__, (unsigned long)(oddmr_data->dbi_data.scp_lifecycle));
		DDPMSG("%s, %lx\n", __func__, (unsigned long)(oddmr_data->dbi_data.scp_lifecycle_size));
		DDPMSG("%s, %lx\n", __func__, (unsigned long)(oddmr_data->dbi_data.support_scp));
		if(!oddmr_data->dbi_data.scp_lifecycle_size){
			DDPMSG("%s, scp_lifecycle_size is null\n", __func__);
			return -1;
		}
		if(!get_mem_virt) {
			DDPMSG("%s, get_mem_virt is null\n", __func__);
			return -1;
		}

		if(mtk_dbi_scp_set_semaphore_noirq(comp, 1)) {
			DDPMSG("%s, get semaphore\n", __func__);
			oddmr_data->dbi_data.scp_lifecycle =
				(void *)(share_lifecycle_offset + get_mem_virt(SCP_DBI_MEM_ID));

			DDPMSG("%s, get semaphore %lx\n", __func__, (unsigned long)(*((void **)params)));
			if (copy_to_user(*((void **)params),
				oddmr_data->dbi_data.scp_lifecycle, oddmr_data->dbi_data.scp_lifecycle_size)) {
				PC_ERR("%s:%d, copy_to_user fail\n", __func__, __LINE__);
				mtk_dbi_scp_set_semaphore_noirq(comp, 0);
				return -1;
			}
			memset(oddmr_data->dbi_data.scp_lifecycle, 0,oddmr_data->dbi_data.scp_lifecycle_size);
			mtk_dbi_scp_set_semaphore_noirq(comp, 0);
		} else {
			DDPMSG("%s, get semaphore fail\n", __func__);
			return -1;
		}
#else
		return -1;
#endif
		break;
	case PQ_ODDMR_DBI_SET_GAIN_RATIO:
		ret = 0;
		gain_ratio = params;
		atomic_set(&oddmr_data->dbi_data.gain_ratio, *gain_ratio);
		break;
	case PQ_ODDMR_DBI_LOAD_SCP_PARAM:
		ret = 0;
		DDPMSG("%s, PQ_DBI_LOAD_SCP_PARAM\n", __func__);
		if(!oddmr_data->dbi_data.load_scp_param){
			ptr = vmalloc(size);
			if (!ptr) {
				DDPMSG("%s:%d, param buffer alloc fail\n", __func__, __LINE__);
				return -1;
			}
			memcpy(ptr, params, size);
			oddmr_data->dbi_data.scp_param_size = size;
			oddmr_data->dbi_data.scp_param = ptr;
			oddmr_data->dbi_data.load_scp_param =1;
			DDPMSG("PQ_DBI_LOAD_SCP_PARAM %d size\n", size);
		} else {
			DDPMSG("%s scp dbi already inited, state %d\n", __func__, oddmr_data->primary_data->dmr_state);
			return 0;
		}
		break;
	case PQ_ODDMR_OD_INIT:
		ret = mtk_oddmr_od_init(comp, params);
		break;
	case PQ_ODDMR_OD_ENABLE:
		ret = mtk_oddmr_od_enable(comp, 1);
		break;
	case PQ_ODDMR_OD_DISABLE:
		ret = mtk_oddmr_od_enable(comp, 0);
		break;
	case PQ_ODDMR_OD_DEINIT:
		ret = mtk_oddmr_od_deinit(comp, params);
		break;
	case PQ_ODDMR_OD_READ_SW_REG:
	{
		struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;

		ret = mtk_oddmr_od_read_sw_reg(comp, params, od_param);
	}
		break;
	case PQ_ODDMR_OD_WRITE_SW_REG:
	{
		struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;

		ret = mtk_oddmr_od_write_sw_reg(comp, params, od_param);
	}
		break;
	case PQ_ODDMR_OD_USER_GAIN:
		ret = mtk_oddmr_od_user_gain(comp, params);
		break;
	case PQ_ODDMR_OD_LOAD_PARAM:
		ret = disp_oddmr_act_od_load_param(comp, params);
		break;
	case PQ_ODDMR_DBI_GET_CAPS:
		priv = comp->mtk_crtc->base.dev->dev_private;
		if((priv->sw_ver == A0_CHIP)&& (priv->data->mmsys_id == MMSYS_MT6993))
			oddmr_data->primary_data->dbi_caps.compress_support = 0;
		caps = (struct drm_mtk_dbi_caps *)params;
		memcpy(caps, &oddmr_data->primary_data->dbi_caps,sizeof(struct drm_mtk_dbi_caps));
		ret = 0;
	default:
		break;
	}
	return ret;
}

/*
 * When od changes from disable to enable, od needs full frame.
 * OD vsize and base address setting for full height,
 * if mtk_oddmr_od_set_partial_update isn't called.
 */
static void mtk_oddmr_od_set_full_height(struct mtk_ddp_comp *comp, struct cmdq_pkt *handle)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	dma_addr_t addr = 0;
	uint32_t hsk_1, merge_lines;
	unsigned int full_height = mtk_crtc_get_height_by_comp(__func__,
		&comp->mtk_crtc->base, comp, true);

	//OD UDMA vsize
	mtk_oddmr_write(comp, full_height,
		MT6991_DISP_ODDMR_OD_UMDA_CTRL_3, handle);
	//OD base address
	if (oddmr_data->od_data.channel != NULL) {
		addr = oddmr_data->od_data.channel->dma_addr;
		mtk_oddmr_write_mask(comp, addr >> 4, MT6991_DISP_ODDMR_OD_BASE_ADDR_LSB,
			REG_FLD_MASK(REG_OD_BASE_ADDR), handle);
		mtk_oddmr_write_mask(comp, addr >> 20, MT6991_DISP_ODDMR_OD_BASE_ADDR_MSB,
			REG_FLD_MASK(REG_OD_BASE_ADDR), handle);
	}
	//OD HSK vsize
	merge_lines = oddmr_data->od_data.merge_lines;
	hsk_1 = full_height / merge_lines;
	mtk_oddmr_write(comp, hsk_1, DISP_ODDMR_OD_HSK_1, handle);
	ODDMRAPI_LOG("full height %d, merge_lines %d, hsk_1 %d\n", full_height, merge_lines, hsk_1);
}

/* OD vsize and base address setting for PU */
static int mtk_oddmr_od_set_partial_update(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *handle, unsigned int top_overhead_v,
		unsigned int bot_overhead_v, unsigned int full_height)
{
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_oddmr_od_param *od_param = &oddmr_data->primary_data->od_param;
	dma_addr_t addr = 0;
	uint32_t hsk_1, merge_lines;

	ODDMRAPI_LOG("set_partial_update %d +\n", oddmr_data->set_partial_update);
	ODDMRAPI_LOG("roi_height %d, overhead_v T %d B %d, full_height %d\n",
		oddmr_data->roi_height, top_overhead_v, bot_overhead_v, full_height);
	/* oddmr reg config */
	if (oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {
		//OD UDMA vsize
		mtk_oddmr_write(comp, (oddmr_data->roi_height + top_overhead_v +
		bot_overhead_v),MT6991_DISP_ODDMR_OD_UMDA_CTRL_3, handle);
		//OD base address
		if (oddmr_data->od_data.channel != NULL) {
			if (oddmr_data->od_data.base_line_jump == 0)
				mtk_oddmr_od_get_dram_size(comp, oddmr_data->cfg.width, oddmr_data->cfg.height,
						od_param->od_basic_info.basic_param.scaling_mode,
						od_param->od_basic_info.basic_param.od_mode, 0, 1);
			ODDMRAPI_LOG("PU=1: base_line_jump %d, roi_y %d\n",
					oddmr_data->od_data.base_line_jump, oddmr_data->roi_y);
			addr = oddmr_data->od_data.channel->dma_addr;
			addr += (dma_addr_t)(oddmr_data->od_data.base_line_jump) * (dma_addr_t)(oddmr_data->roi_y);
			mtk_oddmr_write_mask(comp, addr >> 4, MT6991_DISP_ODDMR_OD_BASE_ADDR_LSB,
				REG_FLD_MASK(REG_OD_BASE_ADDR), handle);
			mtk_oddmr_write_mask(comp, addr >> 20, MT6991_DISP_ODDMR_OD_BASE_ADDR_MSB,
				REG_FLD_MASK(REG_OD_BASE_ADDR), handle);
		}
		//OD HSK vhsize
		merge_lines = oddmr_data->od_data.merge_lines;
		hsk_1 = (oddmr_data->roi_height + top_overhead_v + bot_overhead_v) /
				merge_lines;
		mtk_oddmr_write(comp, hsk_1, DISP_ODDMR_OD_HSK_1, handle);
		ODDMRAPI_LOG("PU=1: merge_lines %d, hsk_1 %d\n", merge_lines, hsk_1);
	} else {
		//OD UDMA vsize
		mtk_oddmr_write(comp, full_height,
			MT6991_DISP_ODDMR_OD_UMDA_CTRL_3, handle);
		//OD base address
		if (oddmr_data->od_data.channel != NULL) {
			addr = oddmr_data->od_data.channel->dma_addr;
			mtk_oddmr_write_mask(comp, addr >> 4, MT6991_DISP_ODDMR_OD_BASE_ADDR_LSB,
				REG_FLD_MASK(REG_OD_BASE_ADDR), handle);
			mtk_oddmr_write_mask(comp, addr >> 20, MT6991_DISP_ODDMR_OD_BASE_ADDR_MSB,
				REG_FLD_MASK(REG_OD_BASE_ADDR), handle);
		}
		//OD HSK vsize
		merge_lines = oddmr_data->od_data.merge_lines;
		hsk_1 = full_height / merge_lines;
		mtk_oddmr_write(comp, hsk_1, DISP_ODDMR_OD_HSK_1, handle);
		ODDMRAPI_LOG("PU=0: merge_lines %d, hsk_1 %d\n", merge_lines, hsk_1);
	}
	oddmr_data->od_data.od_set_pu_done = 1;
	return 0;
}

static int mtk_oddmr_set_partial_update(struct mtk_ddp_comp *comp,
		struct cmdq_pkt *handle, struct mtk_rect partial_roi, unsigned int enable)
{
	struct mtk_drm_private *priv = comp->mtk_crtc->base.dev->dev_private;
	struct mtk_disp_oddmr *oddmr_data = comp_to_oddmr(comp);
	struct mtk_drm_dbi_cfg_info *dbi_cfg_data = &oddmr_data->primary_data->dbi_cfg_info;
	unsigned int scale_factor_v = dbi_cfg_data->basic_info.partial_update_scale_factor_v;
	uint32_t value = 0, mask = 0;
	unsigned int pu_y_ini,pu_height,start_slice_idx,start_slice_offset;

	uint32_t dbi_table_size;
	uint32_t dbi_udma_width;
	uint32_t dbi_udma_height;

	unsigned int full_height = mtk_crtc_get_height_by_comp(__func__,
				&comp->mtk_crtc->base, comp, true);
	unsigned int crop_voffset = 0;
	unsigned int crop_height;
	unsigned int top_overhead_v, bot_overhead_v;
	unsigned int top_comp_overhead_v, bot_comp_overhead_v;

	unsigned int dbi_y_ini, dbi_udma_y_ini;
	unsigned int block_size;
	unsigned int y_idx2_ini, y_remain2_ini;
	unsigned int reg_val;

	// DMR V2 partial update
	struct mtk_drm_dmr_cfg_info *dmr_cfg_data = NULL;
	unsigned int dmr_y_ini, dmr_y_offset = 0;
	unsigned int dmr_input_height; //pixel base
	unsigned int is_compression_mode;
	int cur_bin_idx;
	bool dmr_support, od_support, dbi_support;

	unsigned int i = 0;
	unsigned int dmr_udma_height = 0; //byte base
	unsigned int dmr_udma_y_ini = 0; //byte base
	unsigned int slice_height_sum = 0;
	unsigned int slice_size_sum = 0;

	DDPDBG("%s, %s set partial update, height:%d, enable:%d\n",
		__func__, mtk_dump_comp_str(comp), partial_roi.height, enable);
	dmr_support = oddmr_data->primary_data->dmr_support;
	od_support = oddmr_data->primary_data->od_support;
	dbi_support = oddmr_data->primary_data->dbi_support;

	if (od_support && oddmr_data->data->od_version < MTK_OD_V2)
		mtk_oddmr_bypass(comp, (enable == 1) ? 1 : 0, PQ_FEATURE_KRN_PU, handle);

	/* oddmr crop offset set*/
	oddmr_data->set_partial_update = enable;
	top_overhead_v = (!comp->mtk_crtc->tile_overhead_v.top_overhead_v)
			? 0 : oddmr_data->tile_overhead_v.top_overhead_v;
	bot_overhead_v = (!comp->mtk_crtc->tile_overhead_v.bot_overhead_v)
			? 0 : oddmr_data->tile_overhead_v.bot_overhead_v;
	top_comp_overhead_v = (!top_overhead_v)
			? 0 : oddmr_data->tile_overhead_v.comp_overhead_v;
	bot_comp_overhead_v = (!bot_overhead_v)
			? 0 : oddmr_data->tile_overhead_v.comp_overhead_v;
	oddmr_data->roi_height = partial_roi.height;
	oddmr_data->roi_y = partial_roi.y;
	crop_voffset = top_comp_overhead_v;
	crop_height = oddmr_data->roi_height +
					(top_overhead_v - top_comp_overhead_v) +
					(bot_overhead_v - bot_comp_overhead_v);
	dmr_input_height = partial_roi.height + top_overhead_v + bot_overhead_v;

	DDPDBG("%s, %s total overhead_v T:%d, oddmr overhead_v T:%d\n",
		__func__, mtk_dump_comp_str(comp), top_overhead_v, top_comp_overhead_v);
	DDPDBG("%s, %s total overhead_v T:%d, oddmr overhead_v B:%d, scale_factor_v:%d\n",
		__func__, mtk_dump_comp_str(comp), bot_overhead_v,
		bot_comp_overhead_v, scale_factor_v);

	/* update y ini */
	if (oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {
		dbi_y_ini = partial_roi.y - top_overhead_v;
		dmr_y_ini = partial_roi.y - top_overhead_v;
	} else {
		dbi_y_ini = 0;
		dmr_y_ini = 0;
	}
	/* update udma y ini */
	dbi_udma_y_ini = dbi_y_ini / scale_factor_v;
	/* update idx/remain y ini */
	block_size = (full_height + 3) / 4;
	if (block_size) {
		y_idx2_ini = dbi_y_ini / block_size;
		y_remain2_ini = dbi_y_ini - block_size * y_idx2_ini;
	} else {
		DDPMSG("%s block_size = 0", __func__);
		y_idx2_ini = 0;
		y_remain2_ini = 0;
	}

	/* record dbi partial data */
	oddmr_data->dbi_pu_data.dbi_y_ini = dbi_y_ini;
	oddmr_data->dbi_pu_data.dbi_udma_y_ini = dbi_udma_y_ini;
	oddmr_data->dbi_pu_data.y_idx2_ini = y_idx2_ini;
	oddmr_data->dbi_pu_data.y_remain2_ini = y_remain2_ini;

	cur_bin_idx = atomic_read(&oddmr_data->dmr_data.cur_bin_idx);
	if (cur_bin_idx == -1) {
		is_compression_mode = 0;
	} else {
		dmr_cfg_data = &oddmr_data->primary_data->dmr_multi_bin[cur_bin_idx];
		is_compression_mode =
			dmr_cfg_data->dmr_pu_info.is_compression_mode;
	}
	/* oddmr reg config */
	if (oddmr_data->set_partial_update == MTK_PARTIAL_UPDATE_SISO) {
		if (priv->data->mmsys_id == MMSYS_MT6989) {
			/* ODDMR on MT6989 not support V crop */
			mtk_oddmr_write(comp, dbi_y_ini,
					DISP_ODDMR_REG_DMR_Y_INI, handle);
			mtk_oddmr_write(comp, (oddmr_data->roi_height +
					top_overhead_v + bot_overhead_v),
					DISP_ODDMR_FMT_CTR_1, handle); // oddmr input height
			mtk_oddmr_write(comp, dbi_udma_y_ini,
					DISP_ODDMR_DMR_UDMA_CTR_7, handle);
			mtk_oddmr_write(comp, y_idx2_ini,
					DISP_ODDMR_REG_Y_IDX2_INI, handle);
			mtk_oddmr_write(comp, y_remain2_ini,
					DISP_ODDMR_REG_Y_REMAIN2_INI, handle);
		}
		if (oddmr_data->data->dbi_version == MTK_DBI_V2 || oddmr_data->data->dbi_version== MTK_DBI_V3 ||
			oddmr_data->data->dmr_version == MTK_DMR_V1) {
			//ODDMR input size
			mtk_oddmr_write(comp,
				(partial_roi.height + top_overhead_v + bot_overhead_v),
				MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
			//DBI&DMR input size and pos
			if (oddmr_data->data->dbi_version== MTK_DBI_V3) {
				mtk_oddmr_write(comp, dmr_input_height,
					DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
				mtk_oddmr_write(comp, dmr_y_ini,
					MT6993_DISP_ODDMR_REG_DMR_Y_INI, handle);
			} else {
				mtk_oddmr_write(comp, dmr_input_height,
					MT6991_DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
				mtk_oddmr_write(comp, dmr_y_ini,
					MT6991_DISP_ODDMR_REG_DMR_Y_INI, handle);
			}
			if (dbi_support && oddmr_data->dbi_enable) {
				if(oddmr_data->dbi_data.curr_table_format == DBI_COMP_TABLE_COMPRESSION){
					pu_y_ini = oddmr_data->dbi_pu_data.dbi_y_ini;
					pu_height = oddmr_data->roi_height + top_overhead_v + bot_overhead_v;
					start_slice_idx =
						mtk_oddmr_dbi_find_start_slice(oddmr_data->dbi_data.curr_slice_num,
						oddmr_data->dbi_data.curr_slice_height, pu_y_ini);

					dbi_table_size = oddmr_data->dbi_data.curr_used_entry;
					dbi_udma_width =
						oddmr_data->dbi_data.curr_used_entry >= (1<<24)?(1<<12):(1<<11);
					dbi_udma_height = (dbi_table_size + dbi_udma_width -1)/dbi_udma_width;
					start_slice_offset = oddmr_data->dbi_data.curr_slice_offset[start_slice_idx];

					mtk_oddmr_write(comp, start_slice_offset/dbi_udma_width,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);
					dbi_udma_height -= start_slice_offset/dbi_udma_width;
					mtk_oddmr_write(comp, dbi_udma_height,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
					mtk_oddmr_write(comp, start_slice_offset%dbi_udma_width,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_X_INI, handle);

					value = 0;mask = 0;
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_R);
					SET_VAL_MASK(value, mask,
						pu_y_ini -start_slice_idx*oddmr_data->dbi_data.curr_slice_height,
						MT6991_REG_DBI_V_ST_R);
					SET_VAL_MASK(value, mask,
						pu_height,
						MT6991_REG_DBI_V_LENGTH_R);
					mtk_oddmr_write(comp, value,
						MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R, handle);

					value = 0;mask = 0;
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_G);
					SET_VAL_MASK(value, mask,
						pu_y_ini -start_slice_idx*oddmr_data->dbi_data.curr_slice_height,
						MT6991_REG_DBI_V_ST_G);
					SET_VAL_MASK(value, mask,
						pu_height,
						MT6991_REG_DBI_V_LENGTH_G);
					mtk_oddmr_write(comp, value,
						MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G, handle);

					value = 0;mask = 0;
					SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_B);
					SET_VAL_MASK(value, mask,
						pu_y_ini -start_slice_idx*oddmr_data->dbi_data.curr_slice_height,
						MT6991_REG_DBI_V_ST_B);
					SET_VAL_MASK(value, mask,
						pu_height,
						MT6991_REG_DBI_V_LENGTH_B);
					mtk_oddmr_write(comp, value,
						MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B, handle);
				}else {
					mtk_oddmr_write(comp, dbi_udma_y_ini,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);
					//DBI table size as block
					reg_val = (partial_roi.height + top_overhead_v +
					bot_overhead_v + scale_factor_v -1)/ scale_factor_v;
					if ((reg_val < 0x10) && (oddmr_data->data->dbi_version == MTK_DBI_V2)) {
						reg_val = 0x10;
						mtk_oddmr_write(comp, reg_val,
							MT6991_DISP_ODDMR_REG_DBI_VSIZE, handle);
						mtk_oddmr_write(comp,
							reg_val * scale_factor_v,
							MT6991_DISP_ODDMR_REG_DBI_SCL_VSIZE, handle);
						mtk_oddmr_write(comp, reg_val,
							MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
						value = 0;
						mask = 0;
						SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_R);
						SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_V_ST_R);
						SET_VAL_MASK(value, mask, (partial_roi.height +
								top_overhead_v + bot_overhead_v),
							MT6991_REG_DBI_V_LENGTH_R);
						mtk_oddmr_write(comp, value,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R, handle);
						value = 0;
						mask = 0;
						SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_G);
						SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_V_ST_G);
						SET_VAL_MASK(value, mask, (partial_roi.height +
							top_overhead_v + bot_overhead_v),
							MT6991_REG_DBI_V_LENGTH_G);
						mtk_oddmr_write(comp, value,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G, handle);
						value = 0;
						mask = 0;
						SET_VAL_MASK(value, mask, 1, MT6991_REG_DBI_V_CROP_EN_B);
						SET_VAL_MASK(value, mask, 0, MT6991_REG_DBI_V_ST_B);
						SET_VAL_MASK(value, mask, (partial_roi.height +
							top_overhead_v + bot_overhead_v),
							MT6991_REG_DBI_V_LENGTH_B);
						mtk_oddmr_write(comp, value,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B, handle);
					} else {
						mtk_oddmr_write(comp, reg_val,
							MT6991_DISP_ODDMR_REG_DBI_VSIZE, handle);
						//DBI table size as pixel
						mtk_oddmr_write(comp,
							(partial_roi.height + top_overhead_v + bot_overhead_v),
							MT6991_DISP_ODDMR_REG_DBI_SCL_VSIZE, handle);
						reg_val = (partial_roi.height + top_overhead_v + bot_overhead_v
							+ scale_factor_v -1) / scale_factor_v;
						mtk_oddmr_write(comp, reg_val,
							MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
						mtk_oddmr_write(comp, 0,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R, handle);
						mtk_oddmr_write(comp, 0,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G, handle);
						mtk_oddmr_write(comp, 0,
							MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B, handle);
					}
				}
			}
			if (dmr_support && oddmr_data->dmr_enable && is_compression_mode) {
				// align dmr slice size
				for (i = 0; i < dmr_cfg_data->dmr_pu_info.slice_num; i++) {
					slice_size_sum += dmr_cfg_data->dmr_pu_info.slice_size[i];
					slice_height_sum += dmr_cfg_data->dmr_pu_info.slice_height[i];
					if (dmr_y_ini >= slice_height_sum)
						continue;
					if (i == 0) {
						dmr_y_offset = dmr_y_ini;
						dmr_udma_y_ini = 0;
					} else {
						dmr_y_offset = dmr_y_ini -
							(slice_height_sum - dmr_cfg_data->dmr_pu_info.slice_height[i]);
						dmr_udma_y_ini = slice_size_sum -
							dmr_cfg_data->dmr_pu_info.slice_size[i];
					}
					break;
				}
				slice_size_sum = 0;
				slice_height_sum = 0;
				for (i = 0; i < dmr_cfg_data->dmr_pu_info.slice_num; i++) {
					slice_size_sum += dmr_cfg_data->dmr_pu_info.slice_size[i];
					slice_height_sum += dmr_cfg_data->dmr_pu_info.slice_height[i];
					if (dmr_y_ini + dmr_input_height <= slice_height_sum) {
						dmr_udma_height = slice_size_sum - dmr_udma_y_ini;
						break;
					}
				}
				mtk_oddmr_write(comp, dmr_udma_height + 1,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_HEIGHT_OUT, handle);
				mtk_oddmr_write(comp, dmr_udma_y_ini,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_Y_INI, handle);
				mtk_oddmr_write(comp,
					((1 << 31) | (dmr_y_offset << 16) | crop_height),
					MT6991_DISP_ODDMR_REG_V_CROP_EN_R, handle);
				mtk_oddmr_write(comp,
					((1 << 31) | (dmr_y_offset << 16) | crop_height),
					MT6991_DISP_ODDMR_REG_V_CROP_EN_G, handle);
				mtk_oddmr_write(comp,
					((1 << 31) | (dmr_y_offset << 16) | crop_height),
					MT6991_DISP_ODDMR_REG_V_CROP_EN_B, handle);
			}
			//DBI&DMR output size
			mtk_oddmr_write(comp,
				(partial_roi.height + top_overhead_v + bot_overhead_v),
				MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
			mtk_oddmr_write(comp,
				(partial_roi.height + top_overhead_v + bot_overhead_v),
				MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);
		}
	} else {
		if (priv->data->mmsys_id == MMSYS_MT6989) {
			mtk_oddmr_write(comp, 0,
					DISP_ODDMR_REG_DMR_Y_INI, handle);
			mtk_oddmr_write(comp, full_height,
					DISP_ODDMR_FMT_CTR_1, handle); // oddmr input height
			mtk_oddmr_write(comp, 0,
					DISP_ODDMR_DMR_UDMA_CTR_7, handle);
			mtk_oddmr_write(comp, 0,
					DISP_ODDMR_REG_Y_IDX2_INI, handle);
			mtk_oddmr_write(comp, 0,
					DISP_ODDMR_REG_Y_REMAIN2_INI, handle);
		}
		if (oddmr_data->data->dbi_version == MTK_DBI_V2 || oddmr_data->data->dbi_version== MTK_DBI_V3 ||
			oddmr_data->data->dmr_version == MTK_DMR_V1) {
			//ODDMR input size
			mtk_oddmr_write(comp, full_height,
				MT6991_DISP_ODDMR_REG_ODDMR_FRAME_HEIGHT, handle);
			//DBI&DMR input size and pos
			if (oddmr_data->data->dbi_version== MTK_DBI_V3) {
				mtk_oddmr_write(comp, full_height,
					DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
				mtk_oddmr_write(comp, 0,
					MT6993_DISP_ODDMR_REG_DMR_Y_INI, handle);
			} else {
				mtk_oddmr_write(comp, full_height,
					MT6991_DISP_ODDMR_REG_DMR_FRAME_HEIGHT, handle);
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_REG_DMR_Y_INI, handle);
			}
			if (dbi_support && oddmr_data->dbi_enable) {
				if(oddmr_data->dbi_data.curr_table_format == DBI_COMP_TABLE_COMPRESSION){

					mtk_oddmr_write(comp,0,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_X_INI, handle);
					dbi_table_size = oddmr_data->dbi_data.curr_used_entry;
					dbi_udma_width =
						oddmr_data->dbi_data.curr_used_entry >= (1<<24)?(1<<12):(1<<11);
					dbi_udma_height = (dbi_table_size + dbi_udma_width -1)/dbi_udma_width;
					mtk_oddmr_write(comp, dbi_udma_height,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
				}else {
					//DBI table size as block
					reg_val = (full_height + scale_factor_v -1) / scale_factor_v;
					mtk_oddmr_write(comp, reg_val,
						MT6991_DISP_ODDMR_REG_DBI_VSIZE, handle);
					//DBI table size as pixel
					mtk_oddmr_write(comp, full_height,
						MT6991_DISP_ODDMR_REG_DBI_SCL_VSIZE, handle);
					//DBI udma size
					mtk_oddmr_write(comp, 0,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_Y_INI, handle);
					reg_val = (full_height + scale_factor_v -1) / scale_factor_v;
					mtk_oddmr_write(comp, reg_val,
						MT6991_DISP_ODDMR_REG_DBI_UDMA_HEIGHT, handle);
				}
			}
			if (dmr_support && oddmr_data->dmr_enable && is_compression_mode) {
				for (i = 0; i < dmr_cfg_data->dmr_pu_info.slice_num; i++)
					dmr_udma_height += dmr_cfg_data->dmr_pu_info.slice_size[i];
				mtk_oddmr_write(comp, dmr_udma_height + 1,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_HEIGHT_OUT, handle);
				mtk_oddmr_write(comp, 0,
					MT6991_DISP_ODDMR_REG_DMR_UDMA_Y_INI, handle);
				mtk_oddmr_write(comp,
					((0 << 31) | (0 << 16) | full_height),
					MT6991_DISP_ODDMR_REG_V_CROP_EN_R, handle);
				mtk_oddmr_write(comp,
					((0 << 31) | (0 << 16) | full_height),
					MT6991_DISP_ODDMR_REG_V_CROP_EN_G, handle);
				mtk_oddmr_write(comp,
					((0 << 31) | (0 << 16) | full_height),
					MT6991_DISP_ODDMR_REG_V_CROP_EN_B, handle);
			}
			//DBI&DMR output size
			mtk_oddmr_write(comp, full_height,
				MT6991_DISP_ODDMR_REG_ODDMR_OUTP_IN_VSIZE, handle);
			mtk_oddmr_write(comp, full_height,
				MT6991_DISP_ODDMR_REG_ODDMR_OUTP_OUT_VSIZE, handle);

			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_R, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_G, handle);
			mtk_oddmr_write(comp, 0,
				MT6991_DISP_ODDMR_REG_DBI_V_CROP_EN_B, handle);
		}
	}
	if (od_support && oddmr_data->data->od_version >= MTK_OD_V2 &&
		((oddmr_data->od_enable && !comp->mtk_crtc->sec_on) ||
		oddmr_data->od_data.od_sram_reading)) {
		mtk_oddmr_od_set_partial_update(comp, handle, top_overhead_v,
						bot_overhead_v, full_height);
	}
	return 0;
}

static const struct mtk_ddp_comp_funcs mtk_disp_oddmr_funcs = {
	.config = mtk_oddmr_config,
	.start = mtk_oddmr_start,
	.stop = mtk_oddmr_stop,
	.prepare = mtk_oddmr_prepare,
	.unprepare = mtk_oddmr_unprepare,
	.io_cmd = mtk_oddmr_io_cmd,
	.user_cmd = mtk_oddmr_user_cmd,
	.first_cfg = mtk_oddmr_first_cfg,
	.config_trigger = mtk_oddmr_config_trigger,
	.config_overhead = mtk_disp_oddmr_config_overhead,
	.mutex_sof_irq = disp_oddmr_on_start_of_frame,
	.pq_ioctl_transact = mtk_oddmr_pq_ioctl_transact,
	.bypass = mtk_oddmr_bypass,
	.config_overhead_v = mtk_disp_oddmr_config_overhead_v,
	.partial_update = mtk_oddmr_set_partial_update,
};

static int mtk_disp_oddmr_bind(struct device *dev, struct device *master,
		void *data)
{
	struct mtk_disp_oddmr *oddmr_data = dev_get_drvdata(dev);
	struct drm_device *drm_dev = data;
	struct mtk_drm_private *private = drm_dev->dev_private;
	int ret;
	char buf[50];

	pr_notice("%s+\n", __func__);
	ret = mtk_ddp_comp_register(drm_dev, &oddmr_data->ddp_comp);
	if (ret < 0) {
		dev_err(dev, "Failed to register component %s: %d\n",
				dev->of_node->full_name, ret);
		return ret;
	}
	if (mtk_drm_helper_get_opt(private->helper_opt,
			MTK_DRM_OPT_MMQOS_SUPPORT)) {
		oddmr_data = comp_to_oddmr(&oddmr_data->ddp_comp);
		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "DMRR");
		oddmr_data->qos_req_dmrr = of_mtk_icc_get(dev, buf);

		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "DBIR");
		oddmr_data->qos_req_dbir = of_mtk_icc_get(dev, buf);

		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "ODR");
		oddmr_data->qos_req_odr = of_mtk_icc_get(dev, buf);

		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "ODW");
		oddmr_data->qos_req_odw = of_mtk_icc_get(dev, buf);

		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "DMRR_HRT");
		oddmr_data->qos_req_dmrr_hrt = of_mtk_icc_get(dev, buf);

		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "DBIR_HRT");
		oddmr_data->qos_req_dbir_hrt = of_mtk_icc_get(dev, buf);

		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "ODR_HRT");
		oddmr_data->qos_req_odr_hrt = of_mtk_icc_get(dev, buf);

		mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "ODW_HRT");
		oddmr_data->qos_req_odw_hrt = of_mtk_icc_get(dev, buf);

		if (oddmr_data->data->dbi_version >= MTK_DBI_V3) {
			mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "DMRR_STASH");
			oddmr_data->qos_req_dmrr_stash_hrt = of_mtk_icc_get(dev, buf);
			mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
						&oddmr_data->ddp_comp, "DBIR_STASH");
			oddmr_data->qos_req_dbir_stash_hrt = of_mtk_icc_get(dev, buf);
		}

		if (oddmr_data->data->od_version >= MTK_OD_V3) {
			mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
							&oddmr_data->ddp_comp, "ODR_STASH");
			oddmr_data->qos_req_odr_stash_hrt = of_mtk_icc_get(dev, buf);

			mtk_disp_pmqos_get_icc_path_name(buf, sizeof(buf),
							&oddmr_data->ddp_comp, "ODW_STASH");
			oddmr_data->qos_req_odw_stash_hrt = of_mtk_icc_get(dev, buf);
		}

	}
	pr_notice("%s-\n", __func__);
	return 0;
}

static void mtk_disp_oddmr_unbind(struct device *dev, struct device *master,
		void *data)
{
	struct mtk_disp_oddmr *oddmr_data = dev_get_drvdata(dev);
	struct drm_device *drm_dev = data;

	pr_notice("%s+\n", __func__);
	mtk_ddp_comp_unregister(drm_dev, &oddmr_data->ddp_comp);
}

static const struct component_ops mtk_disp_oddmr_component_ops = {
	.bind = mtk_disp_oddmr_bind,
	.unbind = mtk_disp_oddmr_unbind,
};

unsigned int check_oddmr_err_event(void)
{
	return !!(oddmr_err_trigger & oddmr_err_trigger_mask);
}

void clear_oddmr_err_event(void)
{
	DDPMSG("%s, do clear underrun event\n", __func__);
	oddmr_err_trigger = 0;
}

#ifdef ODDMR_ENABLE_IRQ
/*
 * Check frame done status at sof.
 * It is a err detection with delay,
 * should be replaced when better ways come along.
 */
static irqreturn_t mtk_oddmr_check_framedone(int irq, void *dev_id)
{
	struct mtk_disp_oddmr *oddmr_data = dev_id;
	struct mtk_oddmr_od_param *od_param;
	struct mtk_ddp_comp *comp;
	unsigned int ret = 0;
	uint32_t status_raw, status, od_enable, oddmr_err = 0;
	bool dump_en_tmp;
	struct mtk_drm_private *priv = NULL;
	int od_opt = 0;

	if (IS_ERR_OR_NULL(oddmr_data))
		return IRQ_NONE;

	comp = &oddmr_data->ddp_comp;
	if (mtk_drm_top_clk_isr_get(comp) == false) {
		DDPIRQ("%s, top clk off\n", __func__);
		return IRQ_NONE;
	}
	od_param = &oddmr_data->primary_data->od_param;
	status_raw = mtk_oddmr_read(comp, DISP_ODDMR_IRQ_RAW_STATUS);
	status = mtk_oddmr_read(comp, DISP_ODDMR_IRQ_STATUS);
	mtk_oddmr_write(comp, status, DISP_ODDMR_IRQ_CLEAR, NULL);
	mtk_oddmr_write(comp, 0, DISP_ODDMR_IRQ_CLEAR, NULL);
	priv = comp->mtk_crtc->base.dev->dev_private;
	od_opt = mtk_drm_helper_get_opt(priv->helper_opt,
		MTK_DRM_OPT_ODDMR_OD_AEE);
	CRTC_MMP_MARK(0, oddmr_ctl, status_raw, status);
	DDPIRQ("%s %s irq, val:0x%x,0x%x\n", __func__, mtk_dump_comp_str(comp),
		status_raw, status);
	if (status &
		(DISP_ODDMR_IRQ_FRAME_DONE |
		DISP_ODDMR_IRQ_ODW_DONE |
		DISP_ODDMR_IRQ_I_FRM_DNE |
		DISP_ODDMR_IRQ_O_FRM_DNE)) {
		//only care eof follows sof
		if (oddmr_data->irq_status & DISP_ODDMR_IRQ_SOF)
			oddmr_data->irq_status |= status;
		if (status & DISP_ODDMR_IRQ_O_FRM_DNE) {
			uint32_t odr_h, odr_v, odr_h_exp, odr_v_exp;
			uint32_t scaling_mode, hscaling, vscaling;
			uint32_t comp_width, merge_width, merge_lines;

			odr_h = mtk_oddmr_read(comp, DISP_ODDMR_ODR_H);
			odr_v = mtk_oddmr_read(comp, DISP_ODDMR_ODR_V);
			scaling_mode = od_param->od_basic_info.basic_param.scaling_mode;
			mtk_oddmr_od_get_scaling(scaling_mode, &hscaling, &vscaling);
			comp_width = oddmr_data->cfg.comp_in_width;
			merge_lines = oddmr_data->od_data.merge_lines;
			merge_width = DIV_ROUND_UP(comp_width * merge_lines, 8) * 8;
			odr_h_exp = merge_width / hscaling;
			odr_v_exp = oddmr_data->cfg.height / vscaling / merge_lines;
			ODDMRLOW_LOG("%s o_frm_done UDMA_R (0x%x 0x%x) exp (0x%x 0x%x)\n",
				mtk_dump_comp_str(comp), odr_h, odr_v, odr_h_exp, odr_v_exp);
			if ((odr_v != odr_v_exp && odr_v != 0)
				|| (odr_h != odr_h_exp && odr_h != 0)) {
				oddmr_err |= ODDMR_OD_UDMA_R_ERR;
				oddmr_err_trigger |= oddmr_err;
#if IS_ENABLED(CONFIG_ARM64)
				PC_ERR("%s %s err UDMA_R(0x%x 0x%x) exp(0x%x 0x%x) TS:%08llx\n",
					__func__, mtk_dump_comp_str(comp),
					odr_h, odr_v, odr_h_exp, odr_v_exp,
					arch_timer_read_counter());
#else
				PC_ERR("%s %s err UDMA_R(0x%x 0x%x) exp(0x%x 0x%x)\n",
					__func__, mtk_dump_comp_str(comp),
					odr_h, odr_v, odr_h_exp, odr_v_exp);
#endif
			}
		}
		DDPIRQ("%s %s eof status:0x%x,0x%x\n", __func__, mtk_dump_comp_str(comp),
			status, oddmr_data->irq_status);
	}
	if (status & DISP_ODDMR_IRQ_SOF) {
		status = oddmr_data->irq_status | DISP_ODDMR_IRQ_SOF;

		/* reset irq status */
		if (oddmr_data->data->od_version >= MTK_OD_V2)
			od_enable = mtk_oddmr_read(comp, MT6991_DISP_ODDMR_OD_CTRL_EN) & 0x01;
		else
			od_enable = mtk_oddmr_read(comp, DISP_ODDMR_OD_CTRL_EN) & 0x01;
		oddmr_data->irq_status = DISP_ODDMR_IRQ_SOF;
		/* do not care eof status when disable */
		if (!od_enable)
			oddmr_data->irq_status = 0;
		DDPIRQ("%s %s sof status:0x%x,0x%x\n", __func__, mtk_dump_comp_str(comp),
			status, oddmr_data->irq_status);
		if ((status & DISP_ODDMR_IRQ_I_FRM_DNE) &&
			(status & DISP_ODDMR_IRQ_O_FRM_DNE) &&
			!(status & DISP_ODDMR_IRQ_FRAME_DONE) &&
			!(status & DISP_ODDMR_IRQ_ODW_DONE)) {
			if (od_enable) {
				oddmr_err |= ODDMR_OD_UDMA_W_ERR;
				oddmr_err_trigger |= oddmr_err;
#if IS_ENABLED(CONFIG_ARM64)
				PC_ERR("%s %s err UDMA_W status 0x%x, TS: 0x%08llx\n", __func__,
					mtk_dump_comp_str(comp), status, arch_timer_read_counter());
#else
				PC_ERR("%s %s err UDMA_W status 0x%x\n", __func__,
					mtk_dump_comp_str(comp), status);
#endif
			}
		}
	}
	if (od_opt && oddmr_err) {
#if IS_ENABLED(CONFIG_ARM64)
		DDPAEE("ODDMR err 0x%x. TS: 0x%08llx\n",
			oddmr_err, arch_timer_read_counter());
#else
		DDPAEE("ODDMR err 0x%x\n",
			oddmr_err);
#endif
		dump_en_tmp = g_oddmr_dump_en;
		g_oddmr_dump_en = true;
		mtk_drm_crtc_analysis(&(comp->mtk_crtc->base));
		mtk_drm_crtc_dump(&(comp->mtk_crtc->base));
		g_oddmr_dump_en = dump_en_tmp;
		mtk_smi_dbg_hang_detect("oddmr err");
	}
	ret = IRQ_HANDLED;
	mtk_drm_top_clk_isr_put(comp);

	return ret;
}
#endif

static void mtk_oddmr_update_table_handle(struct work_struct *work_item)
{
	struct mtk_disp_oddmr *oddmr_data = NULL;
	struct mtk_oddmr_od_param *od_param = NULL;
	struct mtk_ddp_comp *comp = NULL;
	struct cmdq_pkt *cmdq_handle0 = NULL;
	struct cmdq_pkt *cmdq_handle1 = NULL;
	struct mtk_drm_crtc *mtk_crtc = NULL;
	struct cmdq_client *client = NULL;
	uint32_t update_sram_idx, updata_dram_idx;
	int ret, pm_ret;
	struct work_struct_oddmr_data *work_data = container_of(work_item,
						struct work_struct_oddmr_data, task);

	if (!work_data->data)
		return;
	comp  = (struct mtk_ddp_comp *)work_data->data;
	oddmr_data = comp_to_oddmr(work_data->data);
	od_param = &oddmr_data->primary_data->od_param;
	mtk_crtc = comp->mtk_crtc;

	ODDMRFLOW_LOG("+\n");
	mtk_drm_idlemgr_kick(__func__,
			&comp->mtk_crtc->base, 1);
	ret = mtk_oddmr_acquire_clock(comp);
	if (ret == 0) {
		pm_ret = mtk_vidle_pq_power_get(__func__);
		if (pm_ret) {
			PC_ERR("%s pq_power_get failed %d, skip\n", __func__, pm_ret);
			mtk_oddmr_release_clock(comp);
			return;
		}
		CRTC_MMP_EVENT_START(0, oddmr_ctl,
			oddmr_data->od_data.od_dram_sel[0], oddmr_data->od_data.od_dram_sel[1]);
		ODDMRFLOW_LOG("ODDMR_TABLE_UPDATING\n");
		oddmr_data->primary_data->od_state = ODDMR_TABLE_UPDATING;
		/* In case hasn't yet enabled by mtk_oddmr_set_od_enable. */
		if (oddmr_data->data->od_version >= MTK_OD_V2)
			mtk_oddmr_set_top_clk_force(comp, 1, NULL);

		if (mtk_crtc->gce_obj.client[CLIENT_PQ])
			client = mtk_crtc->gce_obj.client[CLIENT_PQ];
		else
			client = mtk_crtc->gce_obj.client[CLIENT_CFG];
		cmdq_mbox_enable(client->chan);
		update_sram_idx = (uint32_t)!oddmr_data->od_data.od_sram_read_sel;
		updata_dram_idx = (uint32_t)od_param->updata_dram_table;
		CRTC_MMP_MARK(0, oddmr_ctl, 10, 0);
		cmdq_handle0 =
			oddmr_data->od_data.od_sram_pkgs[updata_dram_idx][update_sram_idx];
		cmdq_pkt_refinalize(cmdq_handle0);
		CRTC_MMP_MARK(0, oddmr_ctl, (unsigned long)cmdq_handle0, updata_dram_idx);
		cmdq_pkt_flush(cmdq_handle0);
		CRTC_MMP_MARK(0, oddmr_ctl, 10, 2);
		ODDMRFLOW_LOG("now dram0 %d, now_dram1 %d\n",
			oddmr_data->od_data.od_dram_sel[0], oddmr_data->od_data.od_dram_sel[1]);
		oddmr_data->od_data.od_dram_sel[update_sram_idx] = updata_dram_idx;
		if (comp->mtk_crtc->is_dual_pipe) {
			struct mtk_ddp_comp *comp1 = oddmr_data->companion;
			struct mtk_disp_oddmr *oddmr1_data = comp_to_oddmr(comp1);

			cmdq_handle1 =
				oddmr1_data->od_data.od_sram_pkgs[updata_dram_idx][update_sram_idx];
			cmdq_pkt_refinalize(cmdq_handle1);
			CRTC_MMP_MARK(0, oddmr_ctl, 11, 0);
			CRTC_MMP_MARK(0, oddmr_ctl, (unsigned long)cmdq_handle1, updata_dram_idx);
			cmdq_pkt_flush(cmdq_handle1);
			CRTC_MMP_MARK(0, oddmr_ctl, 11, 2);
			oddmr1_data->od_data.od_dram_sel[update_sram_idx] = updata_dram_idx;
		}
		cmdq_mbox_disable(client->chan);
		ODDMRFLOW_LOG("now sram %d, update_sram %d, dram %d\n",
			oddmr_data->od_data.od_sram_read_sel,update_sram_idx, updata_dram_idx);
		if (!oddmr_data->od_data.od_sram_check) {
			oddmr_data->primary_data->od_state = ODDMR_INIT_DONE;
			ODDMRFLOW_LOG("ODDMR_INIT_DONE\n");
		}

		CRTC_MMP_EVENT_END(0, oddmr_ctl, update_sram_idx, updata_dram_idx);
		if (!pm_ret)
			mtk_vidle_pq_power_put(__func__);
		mtk_oddmr_release_clock(comp);

		if (oddmr_data->od_data.od_sram_check) {
			/* SRAM read back checking */
			ODDMRFLOW_LOG("od sram %d check\n", update_sram_idx);
			oddmr_data->od_data.od_sram_reading = true;
			mtk_oddmr_od_dump_sram(comp, update_sram_idx, 0,
				oddmr_data->od_data.od_sram_check);
			mtk_oddmr_od_dump_sram(comp, update_sram_idx, 1,
				oddmr_data->od_data.od_sram_check);
			mtk_oddmr_od_dump_sram(comp, update_sram_idx, 2,
				oddmr_data->od_data.od_sram_check);
			oddmr_data->od_data.od_sram_reading = false;
			oddmr_data->primary_data->od_state = ODDMR_INIT_DONE;
			ODDMRFLOW_LOG("ODDMR_INIT_DONE\n");
		}
	} else {
		ODDMRFLOW_LOG("clock not on %d\n", ret);
	}
}

static int mtk_oddmr_create_workqueue(struct mtk_disp_oddmr *oddmr_data)
{
	char thread_name[20] = "mtk_oddmr_wq_0";

	sprintf(thread_name, "mtk_oddmr_wq_%d", oddmr_data->ddp_comp.id);
	oddmr_data->primary_data->oddmr_wq = create_singlethread_workqueue(thread_name);
	if (!oddmr_data->primary_data->oddmr_wq) {
		DDPMSG("Failed to create oddmr workqueue\n");
		return -ENOMEM;
	}

	INIT_WORK(&oddmr_data->primary_data->update_table_work.task, mtk_oddmr_update_table_handle);

	return 0;
}

static int mtk_disp_oddmr_probe(struct platform_device *pdev)
{
	struct device *dev = &pdev->dev;
	struct mtk_disp_oddmr *oddmr_data;
	enum mtk_ddp_comp_id comp_id;
	int ret, irq_num, ret_scp;
	struct device_node *smp_node = NULL;
	struct platform_device *spm_pdev = NULL;
	struct resource *res = NULL;
	int count = 0;

	DDPMSG("%s+\n", __func__);
	oddmr_data = devm_kzalloc(dev, sizeof(*oddmr_data), GFP_KERNEL);
	if (!oddmr_data)
		return -ENOMEM;

	oddmr_data->primary_data = kzalloc(sizeof(*oddmr_data->primary_data), GFP_KERNEL);
	if (oddmr_data->primary_data == NULL) {
		ret = -ENOMEM;
		dev_err(dev, "%s failed to alloc primary_data %d\n", __func__, ret);
		goto error_dev_init;
	}

	comp_id = mtk_ddp_comp_get_id(dev->of_node, MTK_DISP_ODDMR);
	if ((int)comp_id < 0) {
		dev_err(dev, "%s failed to identify by alias: %d\n", __func__, comp_id);
		ret = comp_id;
		goto error_primary;
	}

	ret = mtk_ddp_comp_init(dev, dev->of_node, &oddmr_data->ddp_comp, comp_id,
			&mtk_disp_oddmr_funcs);
	if (ret) {
		dev_err(dev, "%s failed to initialize component: %d\n", __func__, ret);
		goto error_primary;
	}
	count = of_property_count_u32_elems(dev->of_node, "mediatek,oddmr-slc");
	if (count <= 0)
		memset(oddmr_data->use_slc, 0, sizeof(oddmr_data->use_slc));
	else
		of_property_read_u32_array(dev->of_node, "mediatek,oddmr-slc", oddmr_data->use_slc, count);

	count = of_property_count_u32_elems(dev->of_node, "mediatek,oddmr-slc-gid");
	if (count > 0)
		of_property_read_u32_array(dev->of_node, "mediatek,oddmr-slc-gid", (unsigned int *)g_slc_gid, count);

	ret = of_property_read_u32(dev->of_node, "mediatek,larb-oddmr-dmrr", &oddmr_data->larb_dmrr);
	if (ret) {
		dev_err(dev, "%s Failed to initialize oddmr-dmrr: %d\n", __func__, ret);
		oddmr_data->larb_dmrr = 0;
	}
	ret = of_property_read_u32(dev->of_node, "mediatek,larb-oddmr-dbir", &oddmr_data->larb_dbir);
	if (ret) {
		dev_err(dev, "%s failed to initialize oddmr-dbir: %d\n", __func__, ret);
		oddmr_data->larb_dbir = 0;
	}
	ret = of_property_read_u32(dev->of_node, "mediatek,larb-oddmr-odr", &oddmr_data->larb_odr);
	if (ret) {
		dev_err(dev, "%s failed to initialize oddmr-odr: %d\n", __func__, ret);
		oddmr_data->larb_odr = 0;
	}
	ret = of_property_read_u32(dev->of_node, "mediatek,larb-oddmr-odw", &oddmr_data->larb_odw);
	if (ret) {
		dev_err(dev, "%s failed to initialize oddmr-odw: %d\n", __func__, ret);
		oddmr_data->larb_odw = 0;
	}

	oddmr_data->data = of_device_get_match_data(dev);
	platform_set_drvdata(pdev, oddmr_data);
	//TODO: left for scp aod, remove later
	if (comp_id == DDP_COMPONENT_ODDMR0)
		g_oddmr_priv = oddmr_data;

#ifdef ODDMR_ENABLE_IRQ
	irq_num = platform_get_irq(pdev, 0);
	if (irq_num < 0 || !oddmr_data->data->irq_handler)
		dev_err(&pdev->dev, "%s failed to request oddmr irq resource\n", __func__);
	else {
		irq_set_status_flags(irq_num, IRQ_TYPE_LEVEL_HIGH);
		ret = devm_request_irq(
			&pdev->dev, irq_num, oddmr_data->data->irq_handler,
			IRQF_TRIGGER_NONE | IRQF_SHARED, dev_name(&pdev->dev), oddmr_data);
		if (ret) {
			DDPAEE("%s:%d, failed to request irq:%d ret:%d\n",
					__func__, __LINE__,
					irq_num, ret);
			ret = -EPROBE_DEFER;
			goto error_primary;
		}
	}
#endif

	mtk_ddp_comp_pm_enable(&oddmr_data->ddp_comp);

	ret = component_add(dev, &mtk_disp_oddmr_component_ops);
	if (ret) {
		dev_err(dev, "%s failed to add component: %d\n", __func__, ret);
		mtk_ddp_comp_pm_disable(&oddmr_data->ddp_comp);
		goto error_primary;
	}

	oddmr_data->od_data.od_sram_read_sel = -1;
	oddmr_data->od_data.od_sram_table_idx[0] = -1;
	oddmr_data->od_data.od_sram_table_idx[1] = -1;

	ret_scp = of_property_read_u32(dev->of_node, "dbi-support-scp-aod", &oddmr_data->dbi_data.support_scp);
	if ((!ret_scp) && oddmr_data->dbi_data.support_scp)
		DDPMSG("%s support scp-aod\n", __func__);
	else {
		DDPMSG("%s do not support scp-aod\n", __func__);
		oddmr_data->dbi_data.support_scp = 0;
	}

	if (oddmr_data->dbi_data.support_scp) {
		smp_node = of_find_compatible_node(NULL, NULL, "mediatek,sleep");
		if (smp_node) {
			spm_pdev = of_find_device_by_node(smp_node);
			of_node_put(smp_node);
			if (!spm_pdev) {
				PC_ERR("%s: invalid spm device\n", __func__);
				oddmr_data->dbi_data.support_scp = 0;
			}
			res = platform_get_resource(spm_pdev, IORESOURCE_MEM, 0);
			oddmr_data->dbi_data.spm_base = devm_ioremap(&spm_pdev->dev, res->start, resource_size(res));
			if (unlikely(!oddmr_data->dbi_data.spm_base )) {
				PC_ERR("%s: fail to ioremap SPM: 0x%llx\n", __func__, res->start);
				oddmr_data->dbi_data.support_scp = 0;
			}
		} else
			PC_ERR("%s: fail to get smp_node\n", __func__);
	}

	atomic_set(&oddmr_data->dbi_data.cur_table_idx, 0);
	atomic_set(&oddmr_data->dbi_data.update_table_idx, 0);
	atomic_set(&oddmr_data->dbi_data.update_table_done, 0);
	oddmr_data->primary_data->dbi_cfg_info.fps_dbv_node.remap_gain_target_code = 255;
	atomic_set(&oddmr_data->dbi_data.enter_scp, 0);
	atomic_set(&oddmr_data->dbi_data.max_time_set_done, 0);
	atomic_set(&oddmr_data->dbi_data.gain_ratio, 100);
	atomic_set(&oddmr_data->dbi_data.remap_enable, 0);
	oddmr_data->primary_data->dbi_caps.compress_support = oddmr_data->data->dbi_compress_support;

	DDPMSG("%s id %d, ret %d-\n", __func__, comp_id, ret);
	return ret;
error_primary:
	if (ret)
		kfree(oddmr_data->primary_data);
error_dev_init:
	if (ret)
		devm_kfree(dev, oddmr_data);
	return ret;
}

static void mtk_disp_oddmr_remove(struct platform_device *pdev)
{
	struct mtk_disp_oddmr *oddmr_data = dev_get_drvdata(&pdev->dev);

	component_del(&pdev->dev, &mtk_disp_oddmr_component_ops);
	mtk_ddp_comp_pm_disable(&oddmr_data->ddp_comp);
}

static const struct mtk_disp_oddmr_data mt6985_oddmr_driver_data = {
	.need_bypass_shadow = true,
	.is_od_support_table_update = false,
	.is_support_rtff = false,
	.is_od_support_hw_skip_first_frame = false,
	.is_od_need_crop_garbage = true,
	.is_od_need_force_clk = true,
	.is_od_support_sec = false,
	.is_od_merge_lines = true,
	.is_od_table_bl_chg = false,
	.tile_overhead = 8,
	.dmr_buffer_size = 458,
	.odr_buffer_size = 264,
	.odw_buffer_size = 264,
	.irq_handler = mtk_oddmr_check_framedone,
	.dbi_compress_support = false,
};

static const struct mtk_disp_oddmr_data mt6897_oddmr_driver_data = {
	.need_bypass_shadow = true,
	.is_od_support_table_update = false,
	.is_support_rtff = false,
	.is_od_support_hw_skip_first_frame = false,
	.is_od_need_crop_garbage = false,
	.is_od_need_force_clk = false,
	.is_od_support_sec = false,
	.is_od_merge_lines = true,
	.is_od_table_bl_chg = false,
	.tile_overhead = 0,
	.dmr_buffer_size = 458,
	.odr_buffer_size = 264,
	.odw_buffer_size = 264,
	.irq_handler = NULL,
	.dbi_compress_support = false,
};

static const struct mtk_disp_oddmr_data mt6989_oddmr_driver_data = {
	.need_bypass_shadow = true,
	.is_od_support_table_update = false,
	.is_support_rtff = false,
	.is_od_support_hw_skip_first_frame = false,
	.is_od_need_crop_garbage = false,
	.is_od_need_force_clk = false,
	.is_od_support_sec = false,
	.is_od_merge_lines = true,
	.is_od_table_bl_chg = true,
	.p_num = 2,
	.tile_overhead = 8,
	.dmr_buffer_size = 458,
	.odr_buffer_size = 960,
	.odw_buffer_size = 960,
	.irq_handler = NULL,
	.dbi_compress_support = false,
};

static const struct mtk_disp_oddmr_data mt6991_oddmr_driver_data = {
	.need_bypass_shadow = true,
	.is_od_support_table_update = false,
	.is_support_rtff = false,
	.is_od_support_hw_skip_first_frame = false,
	.is_od_need_crop_garbage = false,
	.is_od_need_force_clk = false,
	.is_od_support_sec = false,
	.is_od_merge_lines = false,
	.is_od_table_bl_chg = true,
	.tile_overhead = 8,
	.dmr_buffer_size = 102,
	.dbir_buffer_size = 72,
	.irq_handler = NULL,
	.dbi_version = MTK_DBI_V2,
	.dmr_version = MTK_DMR_V1,
	.od_version = MTK_OD_V2,
	.is_dmr_support_stash = true,
	.stash_lead_time = 24,
	.is_dbi_support_stash = true,
	.is_od_support_stash = false,
	.min_stash_port_bw = 17,
	.dbi_compress_support = false,
};

static const struct mtk_disp_oddmr_data mt6993_oddmr_driver_data = {
	.need_bypass_shadow = true,
	.is_od_support_table_update = false,
	.is_support_rtff = false,
	.is_od_support_hw_skip_first_frame = false,
	.is_od_need_crop_garbage = false,
	.is_od_need_force_clk = false,
	.is_od_support_sec = false,
	.is_od_merge_lines = false,
	.is_od_table_bl_chg = true,
	.tile_overhead = 8,
	.dmr_buffer_size = 102,
	.dbir_buffer_size = 72,
	.irq_handler = NULL,
	.dbi_version = MTK_DBI_V3,
	.dmr_version = MTK_DMR_V1,
	.od_version = MTK_OD_V3,
	.is_dmr_support_stash = true,
	.stash_lead_time = 20,
	.is_dbi_support_stash = true,
	.is_od_support_stash = true,
	.min_stash_port_bw = 49,
	.slc_read_alloc = 1,
	.slc_period = 1,
	.sodi_config = mt6993_mtk_sodi_config,
	.dbi_compress_support = true,
};

static const struct of_device_id mtk_disp_oddmr_driver_dt_match[] = {
	{ .compatible = "mediatek,mt6985-disp-oddmr",
	  .data = &mt6985_oddmr_driver_data},
	{ .compatible = "mediatek,mt6897-disp-oddmr",
	  .data = &mt6897_oddmr_driver_data},
	{ .compatible = "mediatek,mt6989-disp-oddmr",
	  .data = &mt6989_oddmr_driver_data},
	{ .compatible = "mediatek,mt6991-disp-oddmr",
	  .data = &mt6991_oddmr_driver_data},
	{ .compatible = "mediatek,mt6993-disp-oddmr",
	  .data = &mt6993_oddmr_driver_data},
	{},
};

MODULE_DEVICE_TABLE(of, mtk_disp_oddmr_driver_dt_match);

struct platform_driver mtk_disp_oddmr_driver = {
	.probe = mtk_disp_oddmr_probe,
	.remove = mtk_disp_oddmr_remove,
	.driver = {
		.name = "mediatek-disp-oddmr",
		.owner = THIS_MODULE,
		.of_match_table = mtk_disp_oddmr_driver_dt_match,
	},
};
